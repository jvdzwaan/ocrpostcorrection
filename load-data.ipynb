{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlp4dutch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1fa962b3271c92d5bbb9f388fd57cca0da7673b4fedc1b84f54d72b9319215d1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Get corresponding Loguru level if it exists\n",
    "        try:\n",
    "            level = logger.level(record.levelname).name\n",
    "        except ValueError:\n",
    "            level = record.levelno\n",
    "\n",
    "        # Find caller from where originated the logged message\n",
    "        frame, depth = logging.currentframe(), 2\n",
    "        while frame.f_code.co_filename == logging.__file__:\n",
    "            frame = frame.f_back\n",
    "            depth += 1\n",
    "\n",
    "        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n",
    "\n",
    "logging.basicConfig(handlers=[InterceptHandler()], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "in_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(in_dir/'NL'/'NL1'/'17.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_label_and_nl(line):\n",
    "    return line.strip()[14:]\n",
    "\n",
    "ocr_aligned = remove_label_and_nl(lines[1])\n",
    "gs_aligned = remove_label_and_nl(lines[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    ocr: str\n",
    "    gs: str\n",
    "    ocr_aligned: str\n",
    "    gs_aligned: str\n",
    "    start: int\n",
    "\n",
    "\n",
    "def tokenize_aligned(ocr_aligned, gs_aligned):\n",
    "\n",
    "    ocr_cursor = 0\n",
    "\n",
    "    ocr_token_chars = []\n",
    "    gs_token_chars = []\n",
    "    ocr_token_chars_aligned = []\n",
    "    gs_token_chars_aligned = []\n",
    "    start_char = 0\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for ocr_aligned_char, gs_aligned_char in zip(ocr_aligned, gs_aligned):\n",
    "        #print(ocr_aligned_char, gs_aligned_char, ocr_cursor)\n",
    "        if ocr_aligned_char != '@':\n",
    "            ocr_cursor += 1\n",
    "\n",
    "        if ocr_aligned_char == ' ' and gs_aligned_char == ' ':\n",
    "            #print('TOKEN')\n",
    "            #print('OCR:', repr(''.join(ocr_token_chars)))\n",
    "            #print(' GS:', repr(''.join(gs_token_chars)))\n",
    "            #print('start:', start_char)\n",
    "\n",
    "            tokens.append(Token(''.join(ocr_token_chars), \n",
    "                                ''.join(gs_token_chars), \n",
    "                                ''.join(ocr_token_chars_aligned), \n",
    "                                ''.join(gs_token_chars_aligned), \n",
    "                                start_char))\n",
    "\n",
    "            ocr_token_chars = []\n",
    "            gs_token_chars = []\n",
    "            ocr_token_chars_aligned = []\n",
    "            gs_token_chars_aligned = []\n",
    "            start_char = ocr_cursor\n",
    "        else:\n",
    "            ocr_token_chars_aligned.append(ocr_aligned_char)\n",
    "            gs_token_chars_aligned.append(gs_aligned_char)\n",
    "            if ocr_aligned_char != '@':\n",
    "                ocr_token_chars.append(ocr_aligned_char)\n",
    "            if gs_aligned_char != '@':\n",
    "                gs_token_chars.append(gs_aligned_char)\n",
    "    tokens.append(Token(''.join(ocr_token_chars), \n",
    "                        ''.join(gs_token_chars), \n",
    "                        ''.join(ocr_token_chars_aligned), \n",
    "                        ''.join(gs_token_chars_aligned), \n",
    "                        start_char))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokens = tokenize_aligned(ocr_aligned, gs_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Token(ocr='Europijcbe', gs=' Europische', ocr_aligned='@Europijcbe', gs_aligned=' Europische', start=0)\n"
     ]
    }
   ],
   "source": [
    "for t in tokens:\n",
    "    print(t)\n",
    "    break"
   ]
  },
  {
   "source": [
    "To test whether the tokenization is correct, we compare the extracted token strings with the unaligned OCR input text. Sometimes, this text contains alignment characters, and if we remove those, the alignment is correct."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ocr_unaligned = remove_label_and_nl(lines[0])\n",
    "ocr_unaligned = ocr_unaligned.replace('@', '')\n",
    "\n",
    "for t in tokens:\n",
    "    try:\n",
    "        assert t.ocr == ocr_unaligned[t.start:t.start+len(t.ocr)]\n",
    "    except AssertionError:\n",
    "        print(t)\n",
    "        print(ocr_unaligned[t.start:t.start+len(t.ocr)])"
   ]
  }
 ]
}