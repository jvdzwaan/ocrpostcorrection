{
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOGURU_LEVEL'] = 'INFO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Get corresponding Loguru level if it exists\n",
    "        try:\n",
    "            level = logger.level(record.levelname).name\n",
    "        except ValueError:\n",
    "            level = record.levelno\n",
    "\n",
    "        # Find caller from where originated the logged message\n",
    "        frame, depth = logging.currentframe(), 2\n",
    "        while frame.f_code.co_filename == logging.__file__:\n",
    "            frame = frame.f_back\n",
    "            depth += 1\n",
    "\n",
    "        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n",
    "\n",
    "logging.basicConfig(handlers=[InterceptHandler()], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "in_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(in_dir/'NL'/'NL1'/'17.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_label_and_nl(line):\n",
    "    return line.strip()[14:]\n",
    "\n",
    "ocr_aligned = remove_label_and_nl(lines[1])\n",
    "gs_aligned = remove_label_and_nl(lines[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import edlib\n",
    "\n",
    "def normalized_ed(ed, ocr, gs):\n",
    "    score = 0.0\n",
    "    l = max(len(ocr), len(gs))\n",
    "    if l > 0:\n",
    "        score = ed / l\n",
    "    return score\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    ocr: str\n",
    "    gs: str\n",
    "    ocr_aligned: str\n",
    "    gs_aligned: str\n",
    "    start: int\n",
    "    ed: int\n",
    "    score: float = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.score = normalized_ed(self.ed, self.ocr_aligned, self.gs_aligned)\n",
    "        \n",
    "\n",
    "\n",
    "def tokenize_aligned(ocr_aligned, gs_aligned, sentence_start=0):\n",
    "\n",
    "    ocr_cursor = 0\n",
    "\n",
    "    ocr_token_chars = []\n",
    "    gs_token_chars = []\n",
    "    ocr_token_chars_aligned = []\n",
    "    gs_token_chars_aligned = []\n",
    "    start_char = 0\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for ocr_aligned_char, gs_aligned_char in zip(ocr_aligned, gs_aligned):\n",
    "        #print(ocr_aligned_char, gs_aligned_char, ocr_cursor)\n",
    "        if ocr_aligned_char != '@':\n",
    "            ocr_cursor += 1\n",
    "\n",
    "        if ocr_aligned_char == ' ' and gs_aligned_char == ' ':\n",
    "            #print('TOKEN')\n",
    "            #print('OCR:', repr(''.join(ocr_token_chars)))\n",
    "            #print(' GS:', repr(''.join(gs_token_chars)))\n",
    "            #print('start:', start_char)\n",
    "\n",
    "            ed = edlib.align(''.join(ocr_token_chars_aligned), ''.join(gs_token_chars_aligned))\n",
    "\n",
    "            tokens.append(Token(''.join(ocr_token_chars), \n",
    "                                ''.join(gs_token_chars), \n",
    "                                ''.join(ocr_token_chars_aligned), \n",
    "                                ''.join(gs_token_chars_aligned), \n",
    "                                sentence_start+start_char,\n",
    "                                ed['editDistance']))\n",
    "\n",
    "            ocr_token_chars = []\n",
    "            gs_token_chars = []\n",
    "            ocr_token_chars_aligned = []\n",
    "            gs_token_chars_aligned = []\n",
    "            start_char = ocr_cursor\n",
    "        else:\n",
    "            # TODO: handle # in gs(?)\n",
    "            ocr_token_chars_aligned.append(ocr_aligned_char)\n",
    "            gs_token_chars_aligned.append(gs_aligned_char)\n",
    "            if ocr_aligned_char != '@':\n",
    "                ocr_token_chars.append(ocr_aligned_char)\n",
    "            if gs_aligned_char != '@':\n",
    "                gs_token_chars.append(gs_aligned_char)\n",
    "    ed = edlib.align(''.join(ocr_token_chars_aligned), ''.join(gs_token_chars_aligned))\n",
    "    tokens.append(Token(''.join(ocr_token_chars), \n",
    "                        ''.join(gs_token_chars), \n",
    "                        ''.join(ocr_token_chars_aligned), \n",
    "                        ''.join(gs_token_chars_aligned), \n",
    "                        sentence_start+start_char,\n",
    "                        ed['editDistance']))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokens = tokenize_aligned(ocr_aligned, gs_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import edlib\n",
    "\n",
    "@dataclass\n",
    "class Sentence:\n",
    "    ocr: str\n",
    "    gs: str\n",
    "    ocr_aligned: str\n",
    "    gs_aligned: str\n",
    "    start: int\n",
    "    tokens: list\n",
    "    ed: int\n",
    "    score: float = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.score = normalized_ed(self.ed, self.ocr_aligned, self.gs_aligned)\n",
    "\n",
    "\n",
    "def clean(string):\n",
    "    string = string.replace('@', '')\n",
    "    string = string.replace('#', '')\n",
    "\n",
    "    return string\n",
    "\n",
    "def extract_sentences(in_file):\n",
    "    with open(in_file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    ocr_aligned = remove_label_and_nl(lines[1])\n",
    "    gs_aligned = remove_label_and_nl(lines[2])\n",
    "\n",
    "    sentences = []\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "    for i, (start, end) in enumerate(sent_detector.span_tokenize(gs_aligned)):\n",
    "        gs_sentence = gs_aligned[start: end]\n",
    "        ocr_sentence = ocr_aligned[start: end]\n",
    "        #print(start, end)\n",
    "        #print(gs_sentence)\n",
    "        #print(ocr_sentence)\n",
    "\n",
    "        ed = edlib.align(ocr_sentence, gs_sentence)\n",
    "        \n",
    "\n",
    "        tokens = tokenize_aligned(ocr_sentence, gs_sentence, sentence_start=start)\n",
    "        sent = Sentence(clean(ocr_sentence), clean(gs_sentence), ocr_sentence, gs_sentence, start, tokens, ed['editDistance'])\n",
    "        sentences.append(sent)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = extract_sentences(in_dir/'NL'/'NL1'/'17.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "\n",
    "data = {}\n",
    "# df of sentence scores\n",
    "scores = []\n",
    "languages = []\n",
    "\n",
    "subsets = []\n",
    "file_languages = []\n",
    "file_names = []\n",
    "\n",
    "for language_dir in in_dir.iterdir():\n",
    "    #print(language_dir.stem)\n",
    "    language = language_dir.stem\n",
    "    \n",
    "    for text_file in tqdm(language_dir.rglob('*.txt'), desc=language):\n",
    "        #print(text_file)\n",
    "        #print(text_file.relative_to(in_dir))\n",
    "        key = str(text_file.relative_to(in_dir))\n",
    "        data[key] = extract_sentences(text_file)\n",
    "        parts = key.split(os.path.sep)\n",
    "        subsets.append(parts[1])\n",
    "        file_languages.append(language)\n",
    "        file_names.append(key)\n",
    "        for s in data[key]:\n",
    "            scores.append(s.score)\n",
    "            languages.append(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "with open('train.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'score': scores,\n",
    "                   'language': languages})\n",
    "df.to_csv('train-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-scores.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.score.hist(figsize=(10, 5))"
   ]
  },
  {
   "source": [
    "To test whether the tokenization is correct, we compare the extracted token strings with the unaligned OCR input text. Sometimes, this text contains alignment characters, and if we remove those, the alignment is correct."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_unaligned = remove_label_and_nl(lines[0])\n",
    "ocr_unaligned = ocr_unaligned.replace('@', '')\n",
    "\n",
    "for t in tokens:\n",
    "    try:\n",
    "        assert t.ocr == ocr_unaligned[t.start:t.start+len(t.ocr)]\n",
    "    except AssertionError:\n",
    "        print(t)\n",
    "        print(ocr_unaligned[t.start:t.start+len(t.ocr)])"
   ]
  },
  {
   "source": [
    "Export to flair corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train and dev set\n",
    "files = pd.DataFrame.from_dict({'file_name': file_names,\n",
    "                                'subset': subsets,\n",
    "                                'language': file_languages})\n",
    "files.to_csv('train-file-data.csv')\n",
    "files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('train-file-data.csv', index_col=0)\n",
    "print(files.shape)\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, dev_files = train_test_split(files, test_size=0.1, random_state=42, stratify=files['subset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_evaluation_4M_without_Finnish')\n",
    "\n",
    "test_data = {}\n",
    "\n",
    "subsets = []\n",
    "file_languages = []\n",
    "file_names = []\n",
    "\n",
    "for language_dir in in_dir.iterdir():\n",
    "    language = language_dir.stem    \n",
    "    for text_file in tqdm(language_dir.rglob('*.txt'), desc=language):\n",
    "        key = str(text_file.relative_to(in_dir))\n",
    "        test_data[key] = extract_sentences(text_file)\n",
    "        parts = key.split(os.path.sep)\n",
    "        subsets.append(parts[1])\n",
    "        file_languages.append(language)\n",
    "        file_names.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test.pickle', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "with open('test.pickle', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = pd.DataFrame.from_dict({'file_name': file_names,\n",
    "                                     'subset': subsets,\n",
    "                                     'language': file_languages})\n",
    "files.to_csv('test-file-data.csv')\n",
    "files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = pd.read_csv('test-file-data.csv', index_col=0)\n",
    "test_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: count sentences (to compare with dataset)\n",
    "def text2columns(text, threshold=1.0):\n",
    "    output = []\n",
    "    for sentence in text:\n",
    "        if sentence.score <= threshold:\n",
    "            for token in sentence.tokens:\n",
    "                if token.ed == 0:\n",
    "                    annotation = 0\n",
    "                else:\n",
    "                    annotation = 1\n",
    "                if token.ocr != '':\n",
    "                    output.append(f'{token.ocr}\\t{annotation}\\n')\n",
    "            # Separate sentences with an empty line\n",
    "            if len(output) > 0 and output[-1] != '\\n':\n",
    "                output.append('\\n')\n",
    "    return ''.join(output)\n",
    "\n",
    "print(text2columns(data['NL/NL1/17.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_column_data(file_df, data, out_file, threshold=1.0):\n",
    "    with open(out_file, 'w') as f:\n",
    "        for key in tqdm(file_df['file_name']):\n",
    "            f.write(text2columns(data[key], threshold=threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "\n",
    "save_column_data(train_files, data, 'train.txt')\n",
    "save_column_data(dev_files, data, 'dev.txt')\n",
    "save_column_data(test_files, test_data, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high quality data\n",
    "\n",
    "save_column_data(train_files, data, 'train-0.4.txt', threshold=0.4)\n",
    "save_column_data(dev_files, data, 'dev-0.4.txt', threshold=0.4)\n",
    "save_column_data(test_files, test_data, 'test-0.4.txt', threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# French only\n",
    "\n",
    "save_column_data(train_files.query('language == \"FR\"'), data, 'train-french.txt')\n",
    "save_column_data(dev_files.query('language == \"FR\"'), data, 'dev-french.txt')\n",
    "save_column_data(test_files.query('language == \"FR\"'), test_data, 'test-french.txt')"
   ]
  },
  {
   "source": [
    "Create competition result"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for i, t in enumerate(tokens):\n",
    "    if t.ocr != t.gs:\n",
    "        #print(t)\n",
    "        #print(t.start)\n",
    "        #print(len(t.ocr.split()))\n",
    "        task1_result = f'{t.start}:{len(t.ocr.split())}'\n",
    "        #print(task1_result)\n",
    "        result[task1_result] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'NL/NL1/17.txt': result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)"
   ]
  }
 ]
}
