{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Error correction using T5\n",
    "output-file: error_correction_t5.html\n",
    "description: Functionality for error correction with T5.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp error_correction_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from ocrpostcorrection.error_correction import get_tokens_with_OCR_mistakes, get_context_for_dataset\n",
    "from ocrpostcorrection.icdar_data import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 690.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 528.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>gs</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "      <th>start</th>\n",
       "      <th>len_ocr</th>\n",
       "      <th>key</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "      <th>dataset</th>\n",
       "      <th>len_gs</th>\n",
       "      <th>diff</th>\n",
       "      <th>context_before</th>\n",
       "      <th>context_after</th>\n",
       "      <th>len_mistake_in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In</td>\n",
       "      <td></td>\n",
       "      <td>In</td>\n",
       "      <td>##</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>en/eng_sample/1.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>eng_sample</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>botany, a troe is a</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>troe</td>\n",
       "      <td>tree</td>\n",
       "      <td>troe</td>\n",
       "      <td>tree</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>en/eng_sample/1.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>eng_sample</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>In botany, a</td>\n",
       "      <td>is a peremial plant</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peremial</td>\n",
       "      <td>perennial</td>\n",
       "      <td>perem@ial</td>\n",
       "      <td>perennial</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>en/eng_sample/1.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>eng_sample</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>botany, a troe is a</td>\n",
       "      <td>plant with an eLngated</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eLngated</td>\n",
       "      <td>elongated</td>\n",
       "      <td>eL@ngated</td>\n",
       "      <td>elongated</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>en/eng_sample/1.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>eng_sample</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>peremial plant with an</td>\n",
       "      <td>stein, or trunk,</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stein,</td>\n",
       "      <td>stem,</td>\n",
       "      <td>stein,</td>\n",
       "      <td>stem@,</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>en/eng_sample/1.txt</td>\n",
       "      <td>en</td>\n",
       "      <td>eng_sample</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>plant with an eLngated</td>\n",
       "      <td>or trunk, suppor ing</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ocr         gs ocr_aligned gs_aligned  start  len_ocr  \\\n",
       "0        In                     In         ##      0        2   \n",
       "1      troe       tree        troe       tree     13        4   \n",
       "2  peremial  perennial   perem@ial  perennial     23        8   \n",
       "3  eLngated  elongated   eL@ngated  elongated     46        8   \n",
       "4    stein,      stem,      stein,     stem@,     55        6   \n",
       "\n",
       "                   key language      subset dataset  len_gs  diff  \\\n",
       "0  en/eng_sample/1.txt       en  eng_sample    test       0     2   \n",
       "1  en/eng_sample/1.txt       en  eng_sample    test       4     0   \n",
       "2  en/eng_sample/1.txt       en  eng_sample    test       9    -1   \n",
       "3  en/eng_sample/1.txt       en  eng_sample    test       9    -1   \n",
       "4  en/eng_sample/1.txt       en  eng_sample    test       5     1   \n",
       "\n",
       "            context_before            context_after  len_mistake_in_context  \n",
       "0                               botany, a troe is a                      22  \n",
       "1            In botany, a       is a peremial plant                      37  \n",
       "2     botany, a troe is a    plant with an eLngated                      51  \n",
       "3  peremial plant with an          stein, or trunk,                      48  \n",
       "4  plant with an eLngated      or trunk, suppor ing                      50  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "data_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\n",
    "\n",
    "data, md = generate_data(data_dir)\n",
    "\n",
    "val_files = ['fr/fr_sample/2.txt']\n",
    "\n",
    "tdata = get_tokens_with_OCR_mistakes(data, data, val_files)\n",
    "tdata = get_context_for_dataset(data, tdata, 20)\n",
    "tdata.drop_duplicates(subset=[\"ocr\", \"gs\", \"dataset\", \"language\", \"context_before\", \"context_after\"], inplace=True)\n",
    "tdata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(tdata.shape)\n",
    "tdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def filter_len_ocr_mistake_in_context(data: pd.DataFrame, context_offset: int) -> pd.DataFrame:\n",
    "    if context_offset:\n",
    "        # Filter samples on length (to prevent using too much GPU memory)\n",
    "        data = data.query(f\"len_mistake_in_context <= {context_offset * 10}\").copy()\n",
    "        logger.info(f\"Max length of input samples: {data.len_mistake_in_context.max()}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 22:09:57.075 | INFO     | __main__:filter_len_ocr_mistake_in_context:7 - Max length of input samples: 50\n"
     ]
    }
   ],
   "source": [
    "context_offset=5\n",
    "\n",
    "data_context = filter_len_ocr_mistake_in_context(tdata, context_offset=context_offset)\n",
    "\n",
    "assert tdata.len_mistake_in_context.max() > 10*context_offset\n",
    "assert data_context.len_mistake_in_context.max() <= 10*context_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ocr': 'troe',\n",
       " 'gs': 'tree',\n",
       " 'ocr_aligned': 'troe',\n",
       " 'gs_aligned': 'tree',\n",
       " 'start': 13,\n",
       " 'len_ocr': 4,\n",
       " 'key': 'en/eng_sample/1.txt',\n",
       " 'language': 'en',\n",
       " 'subset': 'eng_sample',\n",
       " 'dataset': 'train',\n",
       " 'len_gs': 4,\n",
       " 'diff': 0,\n",
       " 'context_before': 'In botany, a ',\n",
       " 'context_after': ' is a peremial plant',\n",
       " 'len_mistake_in_context': 37,\n",
       " '__index_level_0__': 14}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict(\n",
    "        {\n",
    "            \"train\": Dataset.from_pandas(tdata.query('dataset == \"train\"')),\n",
    "            \"val\": Dataset.from_pandas(tdata.query('dataset == \"val\"')),\n",
    "            \"test\": Dataset.from_pandas(tdata.query('dataset == \"test\"')),\n",
    "        }\n",
    "    )\n",
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def filter_max_len(example: Dict, max_len: int):\n",
    "    if example[\"len_ocr\"] <= max_len and example[\"len_gs\"] <= max_len:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc21d1f6712846e198a59cb450e9454d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ad6b0cc5ea4e6eafc89aa260921afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fae545db27e46888409b2b7720cc5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 5\n",
    "dataset_max_len = dataset.filter(\n",
    "        filter_max_len, fn_kwargs={\"max_len\": max_len}, batched=False\n",
    "    )\n",
    "\n",
    "for subset, expected in {'train': 9, 'val': 2, 'test': 11}.items():\n",
    "    assert len(dataset_max_len[subset]) == expected, f\"Expected len of {expected} for '{subset}', got {len(dataset_max_len[subset])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/byt5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def preprocess_function(examples, tokenizer, add_task_prefix: bool=False, context_marker: str=\"\"):\n",
    "    if context_marker:\n",
    "        input = [\n",
    "            f\"{before}<{context_marker}>{ocr_str}</{context_marker}>{after}\"\n",
    "            for before, ocr_str, after in zip(examples[\"context_before\"], examples[\"ocr\"], examples[\"context_after\"])\n",
    "        ]\n",
    "    else:\n",
    "        input = examples[\"ocr\"]\n",
    "\n",
    "    if add_task_prefix:\n",
    "        input = [f\"{language}: {ocr_str}\" for ocr_str, language in zip(input, examples['language'])]\n",
    "\n",
    "    model_inputs = tokenizer(input)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"gs\"])\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644102d9d33e417bae63c0b0b102d3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1abf71990d4ca29781c6f99bc6b654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598d72d693694317bc7fc84524e03124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer}, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'troe</s>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4ee19f68484bd398d0a531806ff246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c2072237a047a691d6bffc732726f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e429f0d80fa4aed98813a0a3e4b1004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer, \"add_task_prefix\": True}, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en: troe</s>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10b312489af482ab707900e1f3c0407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b9629a19d846dfa7aa0043c1511084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a952c1bf3e248eaa3c90735567abee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer, \"add_task_prefix\": True, \"context_marker\": \"mistake\"}, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en: In botany, a <mistake>troe</mistake> is a peremial plant</s>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
