{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Results\n",
    "output-file: results.html\n",
    "description: Experimental results for the different tasks\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Results for the 2019 ICDAR competition on Post-OCR Text correction can be found \n",
    "in [this paper](https://hal.archives-ouvertes.fr/hal-02304334/document). The best\n",
    "results are repeated in the tables below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Token Classification\n",
    "\n",
    "### Summarized results (F-measure)\n",
    "\n",
    "Best results in **bold**.\n",
    "\n",
    "| Method | BG | CZ | DE | EN | ES | FI | FR | NL | PL | SL |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| CCC (2019 competition winner) |  **0.77** | **0.70** | 0.95 | **0.67** | **0.69** | **0.84** | **0.67** | **0.71** | **0.82** | **0.69** |\n",
    "| Token classification with Huggingface BERT 07-02-2022 (experiment 1) | 0.74 | 0.64 | 0.93 | 0.62 | 0.59 | 0.82 | 0.59 | 0.66 | 0.77 | 0.63 | \n",
    "| Token classification with Huggingface BERT long sequences (experiment 2) | 0.74 | 0.69 | **0.96** | **0.67** | 0.63 | 0.83 | 0.65 | 0.69 |  0.8 | **0.69** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token classification with Huggingface BERT 07-02-2022 (experiment 1)\n",
    "\n",
    "* Validation set: 10% of texts (stratified on language)\n",
    "* Dataset 07-02-2022\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) lenght: 35, step: 30 (overlap of 5 tokens)\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.253900\n",
    "    * Val: 0.290570\n",
    "    * Test: \n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|:---------------|:------------|:-------------|\n",
    "| BG         |       0.875714 |    0.665102 |     0.73898  |\n",
    "| CZ         |       0.81     |    0.548696 |     0.635217 |\n",
    "| DE         |       0.975809 |    0.88539  |     0.927579 |\n",
    "| EN         |       0.850833 |    0.535625 |     0.623125 |\n",
    "| ES         |       0.9068   |    0.464    |     0.591    |\n",
    "| FI         |       0.895    |    0.770125 |     0.8235   |\n",
    "| FR         |       0.806301 |    0.48875  |     0.592939 |\n",
    "| NL         |       0.870816 |    0.596939 |     0.662449 |\n",
    "| PL         |       0.8894   |    0.6982   |     0.7738   |\n",
    "| SL         |       0.805    |    0.575833 |     0.63875  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token classification with Huggingface BERT long sequences (experiment 2)\n",
    "\n",
    "* Validation set: 10% of texts (stratified on language)\n",
    "* Dataset 07-02-2022\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) lenght: 150, step: 150\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.224500\n",
    "    * Val: 0.285791\n",
    "    * Test: 0.4178357720375061\n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|---------------:|------------:|-------------:|\n",
    "| BG         |       0.85     |    0.693673 |     0.744286 |\n",
    "| CZ         |       0.808043 |    0.623261 |     0.685652 |\n",
    "| DE         |       0.971874 |    0.954152 |     0.962806 |\n",
    "| EN         |       0.823333 |    0.618125 |     0.668333 |\n",
    "| ES         |       0.8722   |    0.52     |     0.6254   |\n",
    "| FI         |       0.896625 |    0.785625 |     0.833375 |\n",
    "| FR         |       0.797703 |    0.571588 |     0.651368 |\n",
    "| NL         |       0.875102 |    0.634286 |     0.690204 |\n",
    "| PL         |       0.8872   |    0.7466   |     0.8026   |\n",
    "| SL         |       0.806667 |    0.653333 |     0.692917 |\n",
    "\n",
    "#### Remarks\n",
    "\n",
    "For some texts the sequences of length 150 have to be truncated to fit into the 512 input \n",
    "tokens for BERT. Consequently, we are missing predictions for these truncated tokens. Maybe \n",
    "it is a good idea to decrease the 'step' size, so we'll have predictions for every \n",
    "token. However, this would also mean that we'll have more repetition in the training set.\n",
    "This might impact the results in a negative way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Error Correction - Task 1 Perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Error Correction - Task 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
