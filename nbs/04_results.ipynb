{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Results\n",
    "output-file: results.html\n",
    "description: Experimental results for the different tasks\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for the 2019 ICDAR competition on Post-OCR Text correction can be found \n",
    "in [this paper](https://hal.archives-ouvertes.fr/hal-02304334/document). The best\n",
    "results are repeated in the tables below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Token Classification\n",
    "\n",
    "### Summarized results (F-measure)\n",
    "\n",
    "Best results in **bold**.\n",
    "\n",
    "| Method | BG | CZ | DE | EN | ES | FI | FR | NL | PL | SL |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| CCC (2019 competition winner) |  **0.77** | **0.70** | 0.95 | **0.67** | **0.69** | **0.84** | 0.67 | **0.71** | **0.82** | **0.69** |\n",
    "| [Experiment 1](#sec-experiment-detection-exp-1) | 0.74 | 0.64 | 0.93 | 0.62 | 0.59 | 0.82 | 0.59 | 0.66 | 0.77 | 0.63 | \n",
    "| [Experiment 2 (long sequences)](#sec-experiment-detection-exp-2-long-sequences) | 0.74 | 0.69 | **0.96** | **0.67** | 0.63 | 0.83 | 0.65 | 0.69 |  0.8 | **0.69** |\n",
    "| [Experiment 1 reproduced with DVC](#sec-experiment-detection-exp-1-dvc-stratified-language) | 0.75 | 0.68 | **0.96** | 0.66 | 0.64 | 0.83 | **0.69** | 0.69 | 0.81 | 0.67 |\n",
    "| Experiment 1 reproduced with DVC - evaluation with old eval script | 0.75 | 0.68 | **0.96** | 0.66 | 0.64 | 0.83 | 0.66 | 0.69 | 0.81 | 0.67 |\n",
    "| [Experiment 1 reproduced with DVC - stratified on subset](#sec-experiment-detection-exp-1-dvc-stratified-subset) | 0.75 | 0.69 | **0.96** | **0.67** | 0.63 | 0.83 | **0.69** | 0.69 | 0.81 | 0.68 |\n",
    "| [Experiment 1 (code refactor, training batch size 32) ](#sec-experiment-detection-exp1-training-batch-size-32)  | 0.74 | 0.68 | **0.96** | 0.66 | 0.63 | 0.83 | 0.67 | 0.69 |  0.80 | 0.68 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: token classification with Huggingface BERT 07-02-2022 { #sec-experiment-detection-exp-1 }\n",
    "\n",
    "* Validation set: 10% of texts (stratified on language)\n",
    "* Dataset 07-02-2022\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) lenght: 35, step: 30 (overlap of 5 tokens)\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.253900\n",
    "    * Val: 0.290570\n",
    "    * Test: \n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|:---------------|:------------|:-------------|\n",
    "| BG         |       0.875714 |    0.665102 |     0.73898  |\n",
    "| CZ         |       0.81     |    0.548696 |     0.635217 |\n",
    "| DE         |       0.975809 |    0.88539  |     0.927579 |\n",
    "| EN         |       0.850833 |    0.535625 |     0.623125 |\n",
    "| ES         |       0.9068   |    0.464    |     0.591    |\n",
    "| FI         |       0.895    |    0.770125 |     0.8235   |\n",
    "| FR         |       0.806301 |    0.48875  |     0.592939 |\n",
    "| NL         |       0.870816 |    0.596939 |     0.662449 |\n",
    "| PL         |       0.8894   |    0.6982   |     0.7738   |\n",
    "| SL         |       0.805    |    0.575833 |     0.63875  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: token classification with Huggingface BERT long sequences { #sec-experiment-detection-exp-2-long-sequences }\n",
    "\n",
    "* Validation set: 10% of texts (stratified on language)\n",
    "* Dataset 07-02-2022\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) lenght: 150, step: 150\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.224500\n",
    "    * Val: 0.285791\n",
    "    * Test: 0.4178357720375061\n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|---------------:|------------:|-------------:|\n",
    "| BG         |       0.85     |    0.693673 |     0.744286 |\n",
    "| CZ         |       0.808043 |    0.623261 |     0.685652 |\n",
    "| DE         |       0.971874 |    0.954152 |     0.962806 |\n",
    "| EN         |       0.823333 |    0.618125 |     0.668333 |\n",
    "| ES         |       0.8722   |    0.52     |     0.6254   |\n",
    "| FI         |       0.896625 |    0.785625 |     0.833375 |\n",
    "| FR         |       0.797703 |    0.571588 |     0.651368 |\n",
    "| NL         |       0.875102 |    0.634286 |     0.690204 |\n",
    "| PL         |       0.8872   |    0.7466   |     0.8026   |\n",
    "| SL         |       0.806667 |    0.653333 |     0.692917 |\n",
    "\n",
    "#### Remarks\n",
    "\n",
    "For some texts the sequences of length 150 have to be truncated to fit into the 512 input \n",
    "tokens for BERT. Consequently, we are missing predictions for these truncated tokens. Maybe \n",
    "it is a good idea to decrease the 'step' size, so we'll have predictions for every \n",
    "token. However, this would also mean that we'll have more repetition in the training set.\n",
    "This might impact the results in a negative way. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 reproduced with DVC { #sec-experiment-detection-exp-1-dvc-stratified-language }\n",
    "\n",
    "* ocrpostcorrection-notebooks commit: [430d228](https://github.com/jvdzwaan/ocrpostcorrection-notebooks/blob/430d22850a4cf00320e8dd62f0d78e4d5aa71c60/reports/detection/experiment_results.md)\n",
    "* Dataset\n",
    "    * Split seed: 8232\n",
    "    * Validation set: 10.0%\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) length: size: 35, step: 30\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.2398\n",
    "    * Val: 0.2871749699115753\n",
    "    * Test: 0.4474944472312927\n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|---------------:|------------:|-------------:|\n",
    "| BG         |           0.85 |        0.71 |         0.75 |\n",
    "| CZ         |           0.82 |        0.6  |         0.68 |\n",
    "| DE         |           0.97 |        0.96 |         0.96 |\n",
    "| EN         |           0.81 |        0.6  |         0.66 |\n",
    "| ES         |           0.87 |        0.54 |         0.64 |\n",
    "| FI         |           0.91 |        0.78 |         0.83 |\n",
    "| FR         |           0.8  |        0.63 |         0.69 |\n",
    "| NL         |           0.86 |        0.63 |         0.69 |\n",
    "| PL         |           0.89 |        0.75 |         0.81 |\n",
    "| SL         |           0.81 |        0.62 |         0.67 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 reproduced with DVC, stratified on subset { #sec-experiment-detection-exp-1-dvc-stratified-subset }\n",
    "\n",
    "* ocrpostcorrection-notebooks commit: [6231bca](https://github.com/jvdzwaan/ocrpostcorrection-notebooks/tree/6231bcae0e20a2182a90892e7184c86f67a2b74f)\n",
    "* Dataset\n",
    "    * Split seed: 8232\n",
    "    * Validation set: 10.0%\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) length: size: 35, step: 30\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.2439\n",
    "    * Val: 0.2839458584785461\n",
    "    * Test: 0.4422231018543243\n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|---------------:|------------:|-------------:|\n",
    "| BG         |           0.86 |        0.7  |         0.75 |\n",
    "| CZ         |           0.85 |        0.6  |         0.69 |\n",
    "| DE         |           0.97 |        0.95 |         0.96 |\n",
    "| EN         |           0.82 |        0.61 |         0.67 |\n",
    "| ES         |           0.89 |        0.53 |         0.63 |\n",
    "| FI         |           0.89 |        0.79 |         0.83 |\n",
    "| FR         |           0.81 |        0.62 |         0.69 |\n",
    "| NL         |           0.87 |        0.64 |         0.69 |\n",
    "| PL         |           0.89 |        0.75 |         0.81 |\n",
    "| SL         |           0.81 |        0.64 |         0.68 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 with training batch size 32 (2023-07-28) { #sec-experiment-detection-exp1-training-batch-size-32 }\n",
    "\n",
    "* ocrpostcorrection-notebooks commit: [8f7329e](https://github.com/jvdzwaan/ocrpostcorrection-notebooks/commit/8f7329e95652a0e3df717844a8edb08054faf075)\n",
    "* Dataset\n",
    "    * Split seed: 8232\n",
    "    * Validation set: 10.0%\n",
    "    * Normalized editdistance threshold for 'sentences': 0.3 (only for train and val)\n",
    "    * Sequence (sentence) length: size: 35, step: 30\n",
    "* Pretrained model: [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "* Loss\n",
    "    * Train: 0.2625\n",
    "    * Val: 0.2949527204036712\n",
    "    * Test: 0.4553228318691253\n",
    "\n",
    "| language   |   T1_Precision |   T1_Recall |   T1_Fmesure |\n",
    "|:-----------|---------------:|------------:|-------------:|\n",
    "| BG         |           0.86 |        0.69 |         0.74 |\n",
    "| CZ         |           0.85 |        0.59 |         0.68 |\n",
    "| DE         |           0.97 |        0.95 |         0.96 |\n",
    "| EN         |           0.83 |        0.59 |         0.66 |\n",
    "| ES         |           0.88 |        0.53 |         0.63 |\n",
    "| FI         |           0.89 |        0.79 |         0.83 |\n",
    "| FR         |           0.8  |        0.61 |         0.67 |\n",
    "| NL         |           0.86 |        0.64 |         0.69 |\n",
    "| PL         |           0.89 |        0.75 |         0.8  |\n",
    "| SL         |           0.82 |        0.63 |         0.68 |\n",
    "\n",
    "#### Remarks\n",
    "\n",
    "Training batch size was set to 32.\n",
    "Trained on Google Colab T4 High RAM.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Error Correction - Task 1 Perfect\n",
    "\n",
    "### Summarized results (average % of improvement in edit distance between original and corrected)\n",
    "\n",
    "The input is the 'perfect' results for error detection.\n",
    "\n",
    "| Method | BG | CZ | DE | EN | ES | FI | FR | NL | PL | SL |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| CCC (2019 competition winner) | n/a | n/a | n/a | n/a | n/a | n/a | n/a | n/a | n/a | n/a |\n",
    "| Experiment 1 |  -38 |  -64 |   47 |  -13 |   -1 |   14 |   -8 |   -4 |  -14 |  -34 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Error Correction - Task 1 Results\n",
    "\n",
    "### Summarized results (average % of improvement in edit distance between original and corrected)\n",
    "\n",
    "The input is the errors detected by a model.\n",
    "\n",
    "| Method | BG | CZ | DE | EN | ES | FI | FR | NL | PL | SL |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| CCC (2019 competition winner) | 9 | 6 | 24 | 11 | 11 | 8 | 5 | 12 | 17 | 14 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
