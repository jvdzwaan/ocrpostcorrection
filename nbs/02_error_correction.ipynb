{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Error Correction\n",
    "output-file: error_correction.html\n",
    "description: Functionality for error correction (task 2)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp error_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import dataclasses\n",
    "import random\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ocrpostcorrection.icdar_data import Text, normalized_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import edlib\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ocrpostcorrection.icdar_data import generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "A dataset for token correction consists of the OCR text and gold standard of AlignedTokens. \n",
    "These can be extracted from the Text objects using the `get_tokens_with_OCR_mistakes` function.\n",
    "This function also adds data properties that can be used for calculating statistics \n",
    "about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_tokens_with_OCR_mistakes(\n",
    "    data: Dict[str, Text], data_test: Dict[str, Text], val_files: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return pandas dataframe with all OCR mistakes from train, val, and test\"\"\"\n",
    "    tokens = []\n",
    "    # Train and val\n",
    "    for key, d in data.items():\n",
    "        for token in d.tokens:\n",
    "            if token.ocr.strip() != token.gs.strip():\n",
    "                r = dataclasses.asdict(token)\n",
    "                r[\"language\"] = key[:2]\n",
    "                r[\"subset\"] = key.split(\"/\")[1]\n",
    "\n",
    "                if key in val_files:\n",
    "                    r[\"dataset\"] = \"val\"\n",
    "                else:\n",
    "                    r[\"dataset\"] = \"train\"\n",
    "\n",
    "                tokens.append(r)\n",
    "    # Test\n",
    "    for key, d in data_test.items():\n",
    "        for token in d.tokens:\n",
    "            if token.ocr.strip() != token.gs.strip():\n",
    "                r = dataclasses.asdict(token)\n",
    "                r[\"language\"] = key[:2]\n",
    "                r[\"subset\"] = key.split(\"/\")[1]\n",
    "                r[\"dataset\"] = \"test\"\n",
    "\n",
    "                tokens.append(r)\n",
    "    tdata = pd.DataFrame(tokens)\n",
    "    tdata = _add_update_data_properties(tdata)\n",
    "\n",
    "    return tdata\n",
    "\n",
    "\n",
    "def _add_update_data_properties(tdata: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add and update data properties for calculating statistics\"\"\"\n",
    "    tdata[\"ocr\"] = tdata[\"ocr\"].apply(lambda x: x.strip())\n",
    "    tdata[\"gs\"] = tdata[\"gs\"].apply(lambda x: x.strip())\n",
    "    tdata[\"len_ocr\"] = tdata.apply(lambda row: len(row.ocr), axis=1)\n",
    "    tdata[\"len_gs\"] = tdata.apply(lambda row: len(row.gs), axis=1)\n",
    "    tdata[\"diff\"] = tdata.len_ocr - tdata.len_gs\n",
    "    return tdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code example shows how use this function. \n",
    "For simplicity, in the example below, the `data` dictionary (which contain \n",
    "`<file name>: Text` pairs) is used both as train/val and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 906.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>gs</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "      <th>start</th>\n",
       "      <th>len_ocr</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "      <th>dataset</th>\n",
       "      <th>len_gs</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test- AAA</td>\n",
       "      <td>test-.AAA</td>\n",
       "      <td>test- AAA</td>\n",
       "      <td>test-.AAA</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr_sample</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-BBB</td>\n",
       "      <td>test- BBB</td>\n",
       "      <td>test@-BBB</td>\n",
       "      <td>test- BBB</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr_sample</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-CCC</td>\n",
       "      <td>test- CCC</td>\n",
       "      <td>test-@CCC</td>\n",
       "      <td>test- CCC</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr_sample</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-DDD</td>\n",
       "      <td>DDD</td>\n",
       "      <td>-DDD</td>\n",
       "      <td>DDD</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr_sample</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test- EEE</td>\n",
       "      <td>test-EEE</td>\n",
       "      <td>test- EEE</td>\n",
       "      <td>test-@EEE</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr_sample</td>\n",
       "      <td>train</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ocr         gs ocr_aligned gs_aligned  start  len_ocr language  \\\n",
       "0  test- AAA  test-.AAA   test- AAA  test-.AAA      0        9       fr   \n",
       "1   test-BBB  test- BBB   test@-BBB  test- BBB     10        8       fr   \n",
       "2   test-CCC  test- CCC   test-@CCC  test- CCC     19        8       fr   \n",
       "3       -DDD        DDD        -DDD        DDD     33        4       fr   \n",
       "4  test- EEE   test-EEE   test- EEE  test-@EEE     38        9       fr   \n",
       "\n",
       "      subset dataset  len_gs  diff  \n",
       "0  fr_sample   train       9     0  \n",
       "1  fr_sample   train       9    -1  \n",
       "2  fr_sample   train       9    -1  \n",
       "3  fr_sample   train       3     1  \n",
       "4  fr_sample   train       8     1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\n",
    "data, md = generate_data(data_dir)\n",
    "val_files = [\"en/eng_sample/2.txt\"]\n",
    "\n",
    "token_data = get_tokens_with_OCR_mistakes(data, data, val_files)\n",
    "token_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabularies\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/translation_transformer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define special symbols and indices and make sure the tokens are in order of their indices to properly insert them in vocababulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def yield_tokens(data, col):\n",
    "    \"\"\"Helper function to create vocabulary containing characters\"\"\"\n",
    "    for token in data[col].to_list():\n",
    "        for char in token:\n",
    "            yield char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def generate_vocabs(train):\n",
    "    \"\"\"Generate ocr and gs vocabularies from the train set\"\"\"\n",
    "    vocab_transform = {}\n",
    "    for name in (\"ocr\", \"gs\"):\n",
    "        vocab_transform[name] = build_vocab_from_iterator(\n",
    "            yield_tokens(train, name),\n",
    "            min_freq=1,\n",
    "            specials=special_symbols,\n",
    "            special_first=True,\n",
    "        )\n",
    "    # Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
    "    # If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
    "    for name in (\"ocr\", \"gs\"):\n",
    "        vocab_transform[name].set_default_index(UNK_IDX)\n",
    "\n",
    "    return vocab_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trainset to create the ocr and gs vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transform = generate_vocabs(token_data.query('dataset == \"train\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 44)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_transform[\"ocr\"]), len(vocab_transform[\"gs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SimpleCorrectionDataset(Dataset):\n",
    "    def __init__(self, data, max_len=10):\n",
    "        self.ds = (\n",
    "            data.query(f\"len_ocr <= {max_len}\").query(f\"len_gs <= {max_len}\").copy()\n",
    "        )\n",
    "        self.ds = self.ds.reset_index(drop=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ds.loc[idx]\n",
    "\n",
    "        return [char for char in sample.ocr], [char for char in sample.gs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `SimpleCorrectionDataset` with a maximum token length of 10, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleCorrectionDataset(token_data.query('dataset == \"train\"'), max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first sample look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['t', 'e', 's', 't', '-', ' ', 'A', 'A', 'A'],\n",
       " ['t', 'e', 's', 't', '-', '.', 'A', 'A', 'A'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These character sequences need to be transformed into vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BertVectorsCorrectionDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, bert_vectors_file: Path, split_name: str, max_len: int=11):\n",
    "        ds = data.copy()\n",
    "        ds.reset_index(drop=True, inplace=True)\n",
    "        ds = ds.query(f'len_ocr < {max_len}').query(f'len_gs < {max_len}').copy()\n",
    "        ds.reset_index(drop=False, inplace=True)\n",
    "        self.ds = ds\n",
    "\n",
    "        f = h5py.File(bert_vectors_file, \"r\")\n",
    "        self.bert_vectors = f.get(split_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ds.loc[idx]\n",
    "        original_idx = sample[\"index\"]\n",
    "        bert_vector = torch.as_tensor(np.array(self.bert_vectors[original_idx]))\n",
    "\n",
    "        return sample.ocr, sample.gs, bert_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample bert vectors have been generated using `python src/stages/create-bert-vectors.py --seed 1234 --dataset-in ../ocrpostcorrection/nbs/data/correction/dataset.csv --model-dir models/error-detection/ --model-name bert-base-multilingual-cased --batch-size 1 --out-file ../ocrpostcorrection/nbs/data/correction/bert-vectors.hdf5` (from ocrpostcorrection-notebooks, model from [9099e78](https://github.com/jvdzwaan/ocrpostcorrection-notebooks/commit/9099e785177a5c5207d01d80422e68d30f39636d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = Path(os.getcwd()) / \"data\" / \"correction\" / \"dataset.csv\"\n",
    "data = pd.read_csv(data_csv, index_col=0)\n",
    "bert_vectors_file = Path(os.getcwd()) / \"data\" / \"correction\" / \"bert-vectors.hdf5\"\n",
    "split_name = \"test\"\n",
    "\n",
    "dataset = BertVectorsCorrectionDataset(\n",
    "    data=data.query(f\"dataset == '{split_name}'\"), \n",
    "    bert_vectors_file=bert_vectors_file, \n",
    "    split_name=split_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://pytorch.org/tutorials/beginner/translation_transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def sequential_transforms(*transforms):\n",
    "    \"\"\"Helper function to club together sequential operations\"\"\"\n",
    "\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    \"\"\"Function to add BOS/EOS and create tensor for input sequence indices\"\"\"\n",
    "    return torch.cat((torch.tensor(token_ids), torch.tensor([EOS_IDX])))\n",
    "\n",
    "\n",
    "def get_text_transform(vocab_transform):\n",
    "    \"\"\"Returns text transforms to convert raw strings into tensors indices\"\"\"\n",
    "    text_transform = {}\n",
    "    for name in (\"ocr\", \"gs\"):\n",
    "        text_transform[name] = sequential_transforms(\n",
    "            vocab_transform[name], tensor_transform  # Numericalization (char -> idx)\n",
    "        )  # Add BOS/EOS and create tensor\n",
    "    return text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  5,  6,  4,  7, 10, 13, 13, 13,  3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_transform = get_text_transform(vocab_transform)\n",
    "\n",
    "text_transform[\"ocr\"]([\"t\", \"e\", \"s\", \"t\", \"-\", \" \", \"A\", \"A\", \"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  0, 21, 34, 22, 33,  5,  3])\n",
      "tensor([ 5,  0, 21, 27, 23, 26,  5,  3])\n"
     ]
    }
   ],
   "source": [
    "text_transform = get_text_transform(vocab_transform)\n",
    "\n",
    "print(text_transform[\"ocr\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))\n",
    "print(text_transform[\"gs\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def collate_fn_with_text_transform(text_transform, batch):\n",
    "    \"\"\"Function to collate data samples into batch tensors, to be used as partial with instatiated text_transform\"\"\"\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample, *_ in batch:\n",
    "        src_batch.append(text_transform[\"ocr\"](src_sample))\n",
    "        tgt_batch.append(text_transform[\"gs\"](tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "\n",
    "    return src_batch.to(torch.int64), tgt_batch.to(torch.int64)\n",
    "\n",
    "\n",
    "def collate_fn(text_transform):\n",
    "    \"\"\"Function to collate data samples into batch tensors\"\"\"\n",
    "    return partial(collate_fn_with_text_transform, text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = SimpleCorrectionDataset(token_data.query('dataset == \"train\"'), max_len=10)\n",
    "train_dataloader = DataLoader(\n",
    "    train, batch_size=5, collate_fn=collate_fn(text_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Can we loop over the entire dataset?\n",
    "num_samples = 0\n",
    "for batch in train_dataloader:\n",
    "    num_samples += batch[0].shape[1]\n",
    "assert num_samples == len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Can we loop over the entire dataset?\n",
    "data_csv = Path(os.getcwd()) / \"data\" / \"correction\" / \"dataset.csv\"\n",
    "data = pd.read_csv(data_csv, index_col=0)\n",
    "bert_vectors_file = Path(os.getcwd()) / \"data\" / \"correction\" / \"bert-vectors.hdf5\"\n",
    "split_name = \"test\"\n",
    "\n",
    "dataset = BertVectorsCorrectionDataset(\n",
    "    data=data.query(f\"dataset == '{split_name}'\"), \n",
    "    bert_vectors_file=bert_vectors_file, \n",
    "    split_name=split_name\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=5, collate_fn=collate_fn(text_transform)\n",
    ")\n",
    "\n",
    "num_samples = 0\n",
    "for batch in train_dataloader:\n",
    "    num_samples += batch[0].shape[1]\n",
    "assert num_samples == len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # print('Encoder')\n",
    "        # print('input size', input.size())\n",
    "        # print('hidden size', hidden.size())\n",
    "        embedded = self.embedding(input)\n",
    "        # print('embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "        # print('embedded size met view', embedded.view(1, 1, -1).size())\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size, device):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # print('embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "        embedded = torch.permute(embedded, (1, 0, 2))\n",
    "        # print('permuted embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "\n",
    "        # print('hidden size', hidden.size())\n",
    "        # print(hidden)\n",
    "\n",
    "        # print('permuted embedded[0] size', embedded[0].size())\n",
    "        # print('hidden[0] size', hidden[0].size())\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1\n",
    "        )\n",
    "\n",
    "        # print('attn_weights', attn_weights.size())\n",
    "        # print('attn_weights unsqueeze(1)', attn_weights.unsqueeze(1).size())\n",
    "        # print('encoder outputs', encoder_outputs.size())\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "\n",
    "        # print('embedded[0]', embedded[0].size())\n",
    "        # print('attn_applied', attn_applied.size())\n",
    "        # print('attn_applied squeeze', attn_applied.squeeze().size())\n",
    "        output = torch.cat((embedded[0], attn_applied.squeeze(1)), 1)\n",
    "        # print('output', output.size())\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # print('output', output.size())\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "\n",
    "        # print(f'output: {output.size()}; hidden: {hidden.size()}; attn_weigts: {attn_weights.size()}')\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size, device):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SimpleCorrectionSeq2seq(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        dropout,\n",
    "        max_length,\n",
    "        teacher_forcing_ratio,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super(SimpleCorrectionSeq2seq, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "        self.max_length = max_length + 1\n",
    "\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size)\n",
    "        self.decoder = AttnDecoderRNN(\n",
    "            hidden_size, output_size, dropout_p=dropout, max_length=self.max_length\n",
    "        )\n",
    "\n",
    "    def forward(self, input, encoder_hidden, target):\n",
    "        # input is src seq len x batch size\n",
    "        # input voor de encoder (1 stap) moet zijn input seq len x batch size x 1\n",
    "        input_tensor = input.unsqueeze(2)\n",
    "        # print('input tensor size', input_tensor.size())\n",
    "\n",
    "        input_length = input.size(0)\n",
    "\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        # Encoder part\n",
    "        encoder_outputs = torch.zeros(\n",
    "            batch_size, self.max_length, self.encoder.hidden_size, device=self.device\n",
    "        )\n",
    "        # print('encoder outputs size', encoder_outputs.size())\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            # print(f'Index {ei}; input size: {input_tensor[ei].size()}; encoder hidden size: {encoder_hidden.size()}')\n",
    "            encoder_output, encoder_hidden = self.encoder(\n",
    "                input_tensor[ei], encoder_hidden\n",
    "            )\n",
    "            # print('Index', ei)\n",
    "            # print('encoder output size', encoder_output.size())\n",
    "            # print('encoder outputs size', encoder_outputs.size())\n",
    "            # print('output selection size', encoder_output[:, 0].size())\n",
    "            # print('ouput to save', encoder_outputs[:,ei].size())\n",
    "            encoder_outputs[:, ei] = encoder_output[0, 0]\n",
    "\n",
    "        # print('encoder outputs', encoder_outputs)\n",
    "        # print('encoder hidden', encoder_hidden)\n",
    "\n",
    "        # Decoder part\n",
    "        # Target = seq len x batch size\n",
    "        # Decoder input moet zijn: batch_size x 1 (van het eerste token = BOS)\n",
    "        target_length = target.size(0)\n",
    "\n",
    "        decoder_input = torch.tensor(\n",
    "            [[BOS_IDX] for _ in range(batch_size)], device=self.device\n",
    "        )\n",
    "        # print('decoder input size', decoder_input.size())\n",
    "\n",
    "        decoder_outputs = torch.zeros(\n",
    "            batch_size, self.max_length, self.decoder.output_size, device=self.device\n",
    "        )\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        use_teacher_forcing = (\n",
    "            True if random.random() < self.teacher_forcing_ratio else False\n",
    "        )\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            if use_teacher_forcing:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target[di, :].unsqueeze(1)  # Teacher forcing\n",
    "                # print('decoder input size:', decoder_input.size())\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.detach()  # detach from history as input\n",
    "                # print('decoder input size:', decoder_input.size())\n",
    "\n",
    "            # print(f'Index {di}; decoder output size: {decoder_output.size()}; decoder input size: {decoder_input.size()}')\n",
    "            decoder_outputs[:, di] = decoder_output\n",
    "\n",
    "        # Zero out probabilities for padded chars\n",
    "        target_masks = (target != PAD_IDX).float()\n",
    "\n",
    "        # Compute log probability of generating true target words\n",
    "        # print('P (decoder_outputs)', decoder_outputs.size())\n",
    "        # print(target.transpose(0, 1))\n",
    "        # print('Index', target.size(), target.transpose(0, 1).unsqueeze(-1))\n",
    "        target_gold_std_log_prob = torch.gather(\n",
    "            decoder_outputs, index=target.transpose(0, 1).unsqueeze(-1), dim=-1\n",
    "        ).squeeze(-1) * target_masks.transpose(0, 1)\n",
    "        # print(target_gold_std_log_prob)\n",
    "        scores = target_gold_std_log_prob.sum(dim=1)\n",
    "\n",
    "        # print(scores)\n",
    "\n",
    "        return scores, encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-22.0969, -19.2172], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 2\n",
    "hidden_size = 5\n",
    "dropout = 0.1\n",
    "max_token_len = 10\n",
    "\n",
    "model = SimpleCorrectionSeq2seq(\n",
    "    len(vocab_transform[\"ocr\"]),\n",
    "    hidden_size,\n",
    "    len(vocab_transform[\"gs\"]),\n",
    "    dropout,\n",
    "    max_token_len,\n",
    "    teacher_forcing_ratio=0.5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "input = torch.tensor([[6, 4], [22, 30], [0, 6], [18, 4], [11, 3], [3, 1]])\n",
    "encoder_hidden = model.encoder.initHidden(batch_size=batch_size, device=device)\n",
    "\n",
    "target = torch.tensor([[6, 4], [23, 5], [16, 6], [16, 4], [11, 4], [3, 1]])\n",
    "\n",
    "losses, _ = model(input, encoder_hidden, target)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def validate_model(model, dataloader, device):\n",
    "    cum_loss = 0\n",
    "    cum_examples = 0\n",
    "\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            batch_size = src.size(1)\n",
    "\n",
    "            encoder_hidden = model.encoder.initHidden(\n",
    "                batch_size=batch_size, device=device\n",
    "            )\n",
    "\n",
    "            example_losses, decoder_ouputs = model(src, encoder_hidden, tgt)\n",
    "            example_losses = -example_losses\n",
    "            batch_loss = example_losses.sum()\n",
    "\n",
    "            bl = batch_loss.item()\n",
    "            cum_loss += bl\n",
    "            cum_examples += batch_size\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return cum_loss / cum_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.570460001627605"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = SimpleCorrectionDataset(token_data.query('dataset == \"val\"'), max_len=10)\n",
    "val_dataloader = DataLoader(val, batch_size=5, collate_fn=collate_fn(text_transform))\n",
    "\n",
    "loss = validate_model(model, val_dataloader, device)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    model=None,\n",
    "    optimizer=None,\n",
    "    num_epochs=5,\n",
    "    valid_niter=5000,\n",
    "    model_save_path=\"model.rar\",\n",
    "    max_num_patience=5,\n",
    "    max_num_trial=5,\n",
    "    lr_decay=0.5,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    num_iter = 0\n",
    "    report_loss = 0\n",
    "    report_examples = 0\n",
    "    val_loss_hist = []\n",
    "    num_trial = 0\n",
    "    patience = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        cum_loss = 0\n",
    "        cum_examples = 0\n",
    "\n",
    "        for src, tgt in train_dl:\n",
    "            # print(f'src: {src.size()}; tgt: {tgt.size()}')\n",
    "            num_iter += 1\n",
    "\n",
    "            batch_size = src.size(1)\n",
    "\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            encoder_hidden = model.encoder.initHidden(\n",
    "                batch_size=batch_size, device=device\n",
    "            )\n",
    "\n",
    "            # print(input_hidden.size())\n",
    "\n",
    "            example_losses, _ = model(src, encoder_hidden, tgt)\n",
    "            example_losses = -example_losses\n",
    "            batch_loss = example_losses.sum()\n",
    "            loss = batch_loss / batch_size\n",
    "\n",
    "            bl = batch_loss.item()\n",
    "            report_loss += bl\n",
    "            report_examples += batch_size\n",
    "\n",
    "            cum_loss += bl\n",
    "            cum_examples += batch_size\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # clip gradient\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if num_iter % valid_niter == 0:\n",
    "                val_loss = validate_model(model, val_dl, device)\n",
    "                print(\n",
    "                    f\"Epoch {epoch}, iter {num_iter}, avg. train loss {report_loss/report_examples}, avg. val loss {val_loss}\"\n",
    "                )\n",
    "\n",
    "                report_loss = 0\n",
    "                report_examples = 0\n",
    "\n",
    "                better_model = len(val_loss_hist) == 0 or val_loss < min(val_loss_hist)\n",
    "                if better_model:\n",
    "                    print(f\"Saving model and optimizer to {model_save_path}\")\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"model_state_dict\": model.state_dict(),\n",
    "                            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        },\n",
    "                        model_save_path,\n",
    "                    )\n",
    "                elif patience < max_num_patience:\n",
    "                    patience += 1\n",
    "                    print(f\"hit patience {patience}\")\n",
    "\n",
    "                    if patience == max_num_patience:\n",
    "                        num_trial += 1\n",
    "                        print(f\"hit #{num_trial} trial\")\n",
    "                        if num_trial == max_num_trial:\n",
    "                            print(\"early stop!\")\n",
    "                            exit(0)\n",
    "\n",
    "                        # decay lr, and restore from previously best checkpoint\n",
    "                        lr = optimizer.param_groups[0][\"lr\"] * lr_decay\n",
    "                        print(\n",
    "                            f\"load previously best model and decay learning rate to {lr}\"\n",
    "                        )\n",
    "\n",
    "                        # load model\n",
    "                        checkpoint = torch.load(model_save_path)\n",
    "                        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "                        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "                        model = model.to(device)\n",
    "\n",
    "                        # set new lr\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group[\"lr\"] = lr\n",
    "\n",
    "                        # reset patience\n",
    "                        patience = 0\n",
    "\n",
    "                val_loss_hist.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 5, avg. train loss 24.269323539733886, avg. val loss 25.217035081651474\n",
      "Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\n",
      "Epoch 1, iter 10, avg. train loss 24.12647247314453, avg. val loss 25.133172776963974\n",
      "Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\n",
      "Epoch 2, iter 15, avg. train loss 25.964556884765624, avg. val loss 25.080279880099827\n",
      "Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\n",
      "Epoch 2, iter 20, avg. train loss 28.973776626586915, avg. val loss 25.027193705240887\n",
      "Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\n",
      "Epoch 2, iter 25, avg. train loss 29.202961349487303, avg. val loss 24.984923468695747\n",
      "Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\n"
     ]
    }
   ],
   "source": [
    "train = SimpleCorrectionDataset(token_data.query('dataset == \"train\"'), max_len=10)\n",
    "train_dataloader = DataLoader(\n",
    "    train, batch_size=2, collate_fn=collate_fn(text_transform), shuffle=True\n",
    ")\n",
    "\n",
    "val = SimpleCorrectionDataset(token_data.query('dataset == \"val\"'), max_len=10)\n",
    "val_dataloader = DataLoader(val, batch_size=3, collate_fn=collate_fn(text_transform))\n",
    "\n",
    "hidden_size = 5\n",
    "model = SimpleCorrectionSeq2seq(\n",
    "    len(vocab_transform[\"ocr\"]),\n",
    "    hidden_size,\n",
    "    len(vocab_transform[\"gs\"]),\n",
    "    0.1,\n",
    "    10,\n",
    "    teacher_forcing_ratio=0.0,\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "msp = Path(os.getcwd()) / \"data\" / \"model.rar\"\n",
    "\n",
    "train_model(\n",
    "    train_dl=train_dataloader,\n",
    "    val_dl=val_dataloader,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    model_save_path=msp,\n",
    "    num_epochs=2,\n",
    "    valid_niter=5,\n",
    "    max_num_patience=5,\n",
    "    max_num_trial=5,\n",
    "    lr_decay=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCorrectionSeq2seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(46, 5)\n",
       "    (gru): GRU(5, 5, batch_first=True)\n",
       "  )\n",
       "  (decoder): AttnDecoderRNN(\n",
       "    (embedding): Embedding(44, 5)\n",
       "    (attn): Linear(in_features=10, out_features=11, bias=True)\n",
       "    (attn_combine): Linear(in_features=10, out_features=5, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (gru): GRU(5, 5)\n",
       "    (out): Linear(in_features=5, out_features=44, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = Path(os.getcwd()) / \"data\" / \"model.rar\"\n",
    "\n",
    "checkpoint = torch.load(model_save_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/chatbot_tutorial.html?highlight=greedy%20decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.max_length = model.max_length\n",
    "        self.encoder = model.encoder\n",
    "        self.decoder = model.decoder\n",
    "\n",
    "        self.device = model.device\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # input is src seq len x batch size\n",
    "        # input voor de encoder (1 stap) moet zijn input seq len x batch size x 1\n",
    "        input_tensor = input.unsqueeze(2)\n",
    "        # print('input tensor size', input_tensor.size())\n",
    "\n",
    "        input_length = input.size(0)\n",
    "\n",
    "        batch_size = input.size(1)\n",
    "        encoder_hidden = self.encoder.initHidden(batch_size, self.device)\n",
    "\n",
    "        # Encoder part\n",
    "        encoder_outputs = torch.zeros(\n",
    "            batch_size, self.max_length, self.encoder.hidden_size, device=self.device\n",
    "        )\n",
    "        # print('encoder outputs size', encoder_outputs.size())\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            # print(f'Index {ei}; input size: {input_tensor[ei].size()}; encoder hidden size: {encoder_hidden.size()}')\n",
    "            encoder_output, encoder_hidden = self.encoder(\n",
    "                input_tensor[ei], encoder_hidden\n",
    "            )\n",
    "            # print('Index', ei)\n",
    "            # print('encoder output size', encoder_output.size())\n",
    "            # print('encoder outputs size', encoder_outputs.size())\n",
    "            # print('output selection size', encoder_output[:, 0].size())\n",
    "            # print('ouput to save', encoder_outputs[:,ei].size())\n",
    "            encoder_outputs[:, ei] = encoder_output[0, 0]\n",
    "\n",
    "        # print('encoder outputs', encoder_outputs)\n",
    "        # print('encoder hidden', encoder_hidden)\n",
    "\n",
    "        # Decoder part\n",
    "        # Target = seq len x batch size\n",
    "        # Decoder input moet zijn: batch_size x 1 (van het eerste token = BOS)\n",
    "        target_length = target.size(0)\n",
    "\n",
    "        decoder_input = torch.tensor(\n",
    "            [[BOS_IDX] for _ in range(batch_size)], device=self.device\n",
    "        )\n",
    "        # print('decoder input size', decoder_input.size())\n",
    "\n",
    "        all_tokens = torch.zeros(\n",
    "            batch_size, self.max_length, device=self.device, dtype=torch.long\n",
    "        )\n",
    "        # print('all_tokens size', all_tokens.size())\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()  # detach from history as input\n",
    "            # print('decoder input size:', decoder_input.size())\n",
    "            # print('decoder input squeezed', decoder_input.clone().squeeze())\n",
    "\n",
    "            # Record token\n",
    "            all_tokens[:, di] = decoder_input.clone().squeeze(1)\n",
    "            # print('all_tokens', all_tokens)\n",
    "\n",
    "        return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 40, 40,  9, 40,  9,  9,  6, 40, 40,  0],\n",
      "        [ 9, 40,  9,  9, 40,  9,  9, 40,  9,  9,  0],\n",
      "        [ 9,  9, 40,  9,  9, 40,  9,  9, 40,  9,  0],\n",
      "        [ 9,  9,  9,  6, 40,  9, 40,  9, 40,  9,  0],\n",
      "        [ 9, 40,  9,  9, 40,  9,  9, 40,  9,  9,  0]])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([5, 11])\n"
     ]
    }
   ],
   "source": [
    "decoder = GreedySearchDecoder(model)\n",
    "\n",
    "max_len = 10\n",
    "\n",
    "test = SimpleCorrectionDataset(token_data.query('dataset == \"test\"'), max_len=max_len)\n",
    "test_dataloader = DataLoader(test, batch_size=5, collate_fn=collate_fn(text_transform))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (src, tgt) in enumerate(test_dataloader):\n",
    "        predicted_indices = decoder(src, tgt)\n",
    "        if i == 0:\n",
    "            print(predicted_indices)\n",
    "        else:\n",
    "            print(predicted_indices.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def indices2string(indices, itos):\n",
    "    output = []\n",
    "    for idxs in indices:\n",
    "        # print(idxs)\n",
    "        string = []\n",
    "        for idx in idxs:\n",
    "            if idx not in (UNK_IDX, PAD_IDX, BOS_IDX):\n",
    "                if idx == EOS_IDX:\n",
    "                    break\n",
    "                else:\n",
    "                    string.append(itos[idx])\n",
    "        word = \"\".join(string)\n",
    "        output.append(word)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'test', '!']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor(\n",
    "    [\n",
    "        [20, 34, 22, 6, 1, 1, 1, 1, 1, 1],\n",
    "        [22, 6, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [21, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [4, 5, 6, 4, 1, 1, 1, 1, 1, 1],\n",
    "        [29, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "indices2string(indices, vocab_transform[\"gs\"].get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def predict_and_convert_to_str(model, dataloader, tgt_vocab, device):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    decoder = GreedySearchDecoder(model)\n",
    "\n",
    "    itos = tgt_vocab.get_itos()\n",
    "    output_strings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(dataloader):\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            predicted_indices = decoder(src, tgt)\n",
    "\n",
    "            strings_batch = indices2string(predicted_indices, itos)\n",
    "            for s in strings_batch:\n",
    "                output_strings.append(s)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:00<00:00, 227.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ISSESEEsSS', 'ESEESEESEE', 'EESEESEESE']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_strings = predict_and_convert_to_str(\n",
    "    model, test_dataloader, vocab_transform[\"gs\"], device\n",
    ")\n",
    "output_strings[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "test_data = (\n",
    "    token_data.query('dataset == \"test\"')\n",
    "    .query(f\"len_ocr <= {max_len}\")\n",
    "    .query(f\"len_gs <= {max_len}\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "test_data[\"pred\"] = output_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measure: mean normalized edit distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean (normalized) edit distance.\n",
    "    - Option: ignore -\n",
    "    - option: ignore case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      1.971429\n",
       "std       1.773758\n",
       "min       1.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       2.000000\n",
       "max       8.000000\n",
       "Name: ed, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"ed\"] = test_data.apply(\n",
    "    lambda row: edlib.align(row.ocr, row.gs)[\"editDistance\"], axis=1\n",
    ")\n",
    "test_data.ed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.390952\n",
       "std       0.326909\n",
       "min       0.100000\n",
       "25%       0.125000\n",
       "50%       0.250000\n",
       "75%       0.583333\n",
       "max       1.000000\n",
       "Name: ed_norm, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"ed_norm\"] = test_data.apply(\n",
    "    lambda row: normalized_ed(row.ed, row.ocr, row.gs), axis=1\n",
    ")\n",
    "test_data.ed_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      9.857143\n",
       "std       1.004193\n",
       "min       7.000000\n",
       "25%       9.000000\n",
       "50%      10.000000\n",
       "75%      11.000000\n",
       "max      11.000000\n",
       "Name: ed_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"ed_pred\"] = test_data.apply(\n",
    "    lambda row: edlib.align(row.pred, row.gs)[\"editDistance\"], axis=1\n",
    ")\n",
    "test_data.ed_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35.000000\n",
       "mean      0.972092\n",
       "std       0.061538\n",
       "min       0.700000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000\n",
       "Name: ed_norm_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"ed_norm_pred\"] = test_data.apply(\n",
    "    lambda row: normalized_ed(row.ed_pred, row.pred, row.gs), axis=1\n",
    ")\n",
    "test_data.ed_norm_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
