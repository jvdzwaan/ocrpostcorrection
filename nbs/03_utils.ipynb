{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Utils\n",
    "output-file: utils.html\n",
    "description: Util functionality\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import codecs\n",
    "import collections\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "from datasets import Dataset\n",
    "\n",
    "from ocrpostcorrection.icdar_data import InputToken, generate_data, generate_sentences, process_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert predictions into ICDAR output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def predictions_to_labels(predictions):\n",
    "    return np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "# b x max seq x # classes\n",
    "predictions = np.zeros((16, 10, 3))\n",
    "\n",
    "# Always predict 1\n",
    "predictions[:, :, 1] = 1\n",
    "\n",
    "output = predictions_to_labels(predictions)\n",
    "\n",
    "assert np.array_equal(np.ones((16, 10)), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "# shape: b x max seq x # classes\n",
    "predictions = np.array([np.identity(5)])\n",
    "\n",
    "result = predictions_to_labels(predictions)\n",
    "\n",
    "assert np.array_equal(np.array([0, 1, 2, 3, 4]) , result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def separate_subtoken_predictions(word_ids, preds):\n",
    "    #print(len(word_ids), word_ids)\n",
    "    result = defaultdict(list)\n",
    "    for word_idx, p_label in zip(word_ids, preds):\n",
    "        #print(word_idx, p_label)\n",
    "        if word_idx is not None:\n",
    "            result[word_idx].append(p_label)\n",
    "    return dict(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 0, 0], 1: [0, 0, 1], 2: [1, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "word_ids = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "preds =    [0, 0, 0, 0, 0, 1, 1, 2, 2]\n",
    "\n",
    "token_preds = separate_subtoken_predictions(word_ids, preds)\n",
    "print(token_preds)\n",
    "\n",
    "assert token_preds == {0: [0, 0, 0], 1: [0, 0, 1], 2: [1, 2, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_subtoken_predictions(subtoken_predictions):\n",
    "    token_level_predictions = []\n",
    "    for word_idx, preds in subtoken_predictions.items():\n",
    "        token_label = 0\n",
    "        c = Counter(preds)\n",
    "        #print(c)\n",
    "        if c[1] > 0 and c[1] >= c[2]:\n",
    "            token_label = 1\n",
    "        elif c[2] > 0 and c[2] >= c[1]:\n",
    "            token_label = 2\n",
    "\n",
    "        token_level_predictions.append(token_label)\n",
    "    return token_level_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "subtoken_predictions = {0: [0, 0, 0],  # 0\n",
    "                        1: [1, 1, 0],  # 1\n",
    "                        2: [1, 2],     # 1\n",
    "                        3: [2, 2, 1],  # 2\n",
    "                        4: [0, 1, 2],  # 1\n",
    "                        5: [0, 1, 0]}  # 1\n",
    "\n",
    "token_preds = merge_subtoken_predictions(subtoken_predictions)\n",
    "print(token_preds)\n",
    "\n",
    "assert [0, 1, 1, 2, 1, 1] == token_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def gather_token_predictions(preds):\n",
    "    \"\"\"Gather potentially overlapping token predictions\"\"\"\n",
    "    labels = defaultdict(list)\n",
    "        \n",
    "    #print(len(text.input_tokens))\n",
    "    #print(preds)\n",
    "    for start, lbls in preds.items():\n",
    "        for i, label in enumerate(lbls):\n",
    "            labels[int(start)+i].append(label)\n",
    "    #print('LABELS')\n",
    "    #print(labels)\n",
    "    return dict(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "token_predictions = {0: [0, 0, 0, 0, 0],\n",
    "                     1: [0, 0, 0, 0, 0],\n",
    "                     2: [0, 0, 0, 0, 0]}\n",
    "actual = gather_token_predictions(token_predictions)\n",
    "expected = {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0], 4: [0, 0, 0], 5: [0, 0], 6: [0]}\n",
    "\n",
    "assert expected == actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def labels2label_str(labels, text_key):\n",
    "    label_str = []\n",
    "    i = 0\n",
    "\n",
    "    for token in labels:\n",
    "        #print(i, token)\n",
    "        while i < token:\n",
    "            logger.warning(f'Missing predictions for token {i} in \"{text_key}\"')\n",
    "            # Predictions are missing (input text was truncated)\n",
    "            # Add 0 to make sure token indices remain correct \n",
    "            label_str.append('0')\n",
    "            i += 1\n",
    "\n",
    "        if 2 in labels[i]:\n",
    "            label_str.append('2')\n",
    "        elif 1 in labels[i]:\n",
    "            label_str.append('1')\n",
    "        else:\n",
    "            label_str.append('0')\n",
    "        i += 1\n",
    "\n",
    "    label_str = ''.join(label_str)\n",
    "    return label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "labels = {0: [0], 1: [1], 2: [2], 3: [0, 0, 1], 4: [0, 1, 2]}\n",
    "\n",
    "label_str = labels2label_str(labels, 'test1')\n",
    "\n",
    "assert label_str == '01212'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 22:43:29.595 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 3 in \"test2\"\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "labels = {0: [0], 1: [1], 2: [2], 4: [0, 0, 1], 5: [0, 1, 2]}\n",
    "\n",
    "label_str = labels2label_str(labels, 'test2')\n",
    "\n",
    "assert label_str == '012012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 22:43:29.903 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 4 in \"test3\"\n",
      "2022-09-25 22:43:29.905 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 5 in \"test3\"\n",
      "2022-09-25 22:43:29.907 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 6 in \"test3\"\n",
      "2022-09-25 22:43:29.909 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 7 in \"test3\"\n",
      "2022-09-25 22:43:29.910 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 8 in \"test3\"\n",
      "2022-09-25 22:43:29.912 | WARNING  | __main__:labels2label_str:9 - Missing predictions for token 9 in \"test3\"\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "labels = {0: [0], 1: [1], 2: [2], 3: [0, 0, 1], 10: [0, 1, 2]}\n",
    "\n",
    "label_str = labels2label_str(labels, 'test3')\n",
    "\n",
    "assert label_str == '01210000002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def extract_icdar_output(label_str, input_tokens):\n",
    "    #print(label_str, input_tokens)\n",
    "    #print(len(label_str), len(input_tokens))\n",
    "    text_output = {}\n",
    "\n",
    "    # Correct use of 2 (always following a 1)\n",
    "    regex = r'12*'\n",
    "\n",
    "    for match in re.finditer(regex, label_str):\n",
    "        #print(match)\n",
    "        #print(match.group())\n",
    "        num_tokens = len(match.group())\n",
    "        #print(match.start(), len(input_tokens))\n",
    "        idx = input_tokens[match.start()].start\n",
    "        text_output[f'{idx}:{num_tokens}'] = {}\n",
    "\n",
    "    # Incorrect use of 2 (following a 0) -> interpret first 2 as 1\n",
    "    regex = r'02+'\n",
    "\n",
    "    for match in re.finditer(regex, label_str):\n",
    "        #print(match)\n",
    "        #print(match.group())\n",
    "        num_tokens = len(match.group()) - 1\n",
    "        idx = input_tokens[match.start()+1].start\n",
    "        text_output[f'{idx}:{num_tokens}'] = {}\n",
    "    \n",
    "    return text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "label_str = '1'\n",
    "input_tokens = [InputToken(ocr='bal', gs='bla', start=0, len_ocr=3, label=1)]\n",
    "output = extract_icdar_output(label_str, input_tokens)\n",
    "assert output == {'0:1': {}}, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "label_str = '01'\n",
    "input_tokens = [InputToken(ocr='one', gs='one', start=0, len_ocr=3, label=0),\n",
    "                InputToken(ocr='tow', gs='two', start=4, len_ocr=3, label=1)]\n",
    "output = extract_icdar_output(label_str, input_tokens)\n",
    "assert output == {'4:1': {}}, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "label_str = '12'\n",
    "input_tokens = [InputToken(ocr='one', gs='one', start=0, len_ocr=3, label=0),\n",
    "                InputToken(ocr='tow', gs='two', start=4, len_ocr=3, label=1)]\n",
    "output = extract_icdar_output(label_str, input_tokens)\n",
    "assert output == {'0:2': {}}, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "label_str = '112'\n",
    "input_tokens = [InputToken(ocr='one', gs='one', start=0, len_ocr=3, label=0),\n",
    "                InputToken(ocr='one', gs='one', start=4, len_ocr=3, label=0),\n",
    "                InputToken(ocr='tow', gs='two', start=8, len_ocr=3, label=1)]\n",
    "output = extract_icdar_output(label_str, input_tokens)\n",
    "assert output == {'0:1': {}, '4:2': {}}, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "label_str = '02'\n",
    "input_tokens = [InputToken(ocr='one', gs='one', start=0, len_ocr=3, label=0),\n",
    "                InputToken(ocr='tow', gs='two', start=4, len_ocr=3, label=1)]\n",
    "output = extract_icdar_output(label_str, input_tokens)\n",
    "assert output == {'4:1': {}}, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def predictions2icdar_output(samples, predictions, tokenizer, data_test):\n",
    "    \"\"\"Convert predictions into icdar output format\"\"\"\n",
    "    #print('samples', len(samples))\n",
    "    #print(samples)\n",
    "    #print(samples[0].keys())\n",
    "    #for sample in samples:\n",
    "    #    print(sample.keys()) \n",
    "\n",
    "    tokenized_samples = tokenizer(samples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    #print(samples)\n",
    "\n",
    "    #for sample in samples:\n",
    "    #    print(sample.keys())\n",
    "    \n",
    "    # convert predictions to labels (label_ids)\n",
    "    #p = np.argmax(predictions, axis=2)\n",
    "    #print(p)\n",
    "\n",
    "    converted = defaultdict(dict)\n",
    "\n",
    "    for i, (sample, preds) in enumerate(zip(samples, predictions)):\n",
    "        #print(sample.keys())\n",
    "        #label = sample['tags']\n",
    "        #print(label)\n",
    "        #print(len(preds), preds)\n",
    "        word_ids = tokenized_samples.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        result = separate_subtoken_predictions(word_ids, preds)\n",
    "        new_tags = merge_subtoken_predictions(result)\n",
    "\n",
    "        #print('pred', len(new_tags), new_tags)\n",
    "        #print('tags', len(label), label)\n",
    "        \n",
    "        #print(sample)\n",
    "        #print(sample['key'], sample['start_token_id'])\n",
    "        converted[sample['key']][sample['start_token_id']] = new_tags\n",
    "    \n",
    "    output = {}\n",
    "    for key, preds in converted.items():\n",
    "        labels = defaultdict(list)\n",
    "        #print(key)\n",
    "        labels = gather_token_predictions(preds)        \n",
    "        label_str = labels2label_str(labels, key)\n",
    "        \n",
    "        try:\n",
    "            text = data_test[key]\n",
    "            output[key] = extract_icdar_output(label_str, text.input_tokens)\n",
    "        except KeyError:\n",
    "            logger.warning(f'No data found for text {key}')\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "bert_base_model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_base_model_name)\n",
    "\n",
    "tokens = ['the' for i in range(1000)]\n",
    "\n",
    "r = tokenizer(tokens, is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 313.58it/s]\n",
      "4it [00:00, 606.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "# Create tokenizer\n",
    "bert_base_model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_base_model_name)\n",
    "\n",
    "# Create data\n",
    "data_dir = Path(os.getcwd())/'data'/'dataset_training_sample'\n",
    "data, md = generate_data(data_dir)\n",
    "sentence_df = generate_sentences(md, data, size=2, step=1)\n",
    "dataset = Dataset.from_pandas(sentence_df)\n",
    "\n",
    "# Create predictions\n",
    "\n",
    "# b x max seq x # classes\n",
    "predictions = np.zeros((len(dataset), 10, 3))\n",
    "\n",
    "# Always predict 1\n",
    "predictions[:, :, 1] = 1\n",
    "predictions = predictions_to_labels(predictions)\n",
    "\n",
    "# Generate icdar output (task 1)\n",
    "actual = predictions2icdar_output(dataset, predictions, tokenizer, data)\n",
    "\n",
    "# Expected output has an entry of lenght 1 for every input token\n",
    "expected = defaultdict(dict)\n",
    "for key, text in data.items():\n",
    "    for token in text.input_tokens:\n",
    "        expected[key][f'{token.start}:1'] = {}\n",
    "        \n",
    "assert expected == actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_perfect_icdar_output(data):\n",
    "    output = {}\n",
    "    for key, text_obj in data.items():\n",
    "        label_str = ''.join([str(t.label) for t in text_obj.input_tokens])\n",
    "        output[key] = extract_icdar_output(label_str, data[key].input_tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "in_file = Path(os.getcwd())/'data'/'example.txt'\n",
    "text = process_text(in_file)\n",
    "\n",
    "test_input = {'key': text}\n",
    "\n",
    "actual = create_perfect_icdar_output(test_input)\n",
    "\n",
    "# Indices (the first number) refer to the ocr input text\n",
    "assert actual == {'key': {'8:1': {}, '10:1': {}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the ICDAR evaluation script\n",
    "\n",
    "This code was taken from the original [evalTool_ICDAR2017.py](https://git.univ-lr.fr/gchiro01/icdar2017/blob/master/evalTool_ICDAR2017.py) (CC0 License) via [Kotwic4/ocr-correction](https://github.com/Kotwic4/ocr-correction/blob/master/ocr_correction/dataset/icdar/evalTool_ICDAR2017.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "maxNbCandidate = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "################# CLASS FOR STORING CURRENT FILE CONTEXT  ################\n",
    "class EvalContext:\n",
    "\n",
    "    # Default symbols used for the alignment and for ignoring some tokens\n",
    "    charExtend = r\"@\"\n",
    "    charIgnore = r\"#\"\n",
    "\n",
    "    # Different texts versions provided\n",
    "    ocrAligned, gsAligned, ocrOriginal = \"\",\"\",\"\"\n",
    "\n",
    "    # Alignment map (ocrOriginal <=> ocrAligned and gsAligned)\n",
    "    aMap = []\n",
    "\n",
    "    def __init__(self, filePath, verbose=False):\n",
    "\n",
    "        assert os.path.exists(filePath), \"[ERROR] : File %s not found !\" % filePath\n",
    "\n",
    "        self.filePath = filePath\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Load file data\n",
    "        with open(filePath, 'r') as f:\n",
    "            text = f.read().strip()\n",
    "            self.ocrOriginal, self.ocrAligned, self.gsAligned = [txt[14:] for txt in re.split(r\"\\r?\\n\", text)]\n",
    "            # text.strip() removes trailing space from gs aligned, but not from the other texts.\n",
    "            # This causes problems when calculating recall. The solution is to also remove\n",
    "            # trailing space from ocr original and ocr aligned.\n",
    "            self.ocrOriginal = self.ocrOriginal.rstrip()\n",
    "            self.ocrAligned = self.ocrAligned.rstrip()\n",
    "\n",
    "            if self.charExtend in self.ocrOriginal:\n",
    "                print(f'{self.charExtend} found in ocrOriginal. Removing...')\n",
    "                self.ocrOriginal = self.ocrOriginal.replace(self.charExtend, '')\n",
    "\n",
    "        # Check file integrity\n",
    "        assert self.ocrOriginal == re.sub(self.charExtend, \"\", self.ocrAligned).rstrip(), \"[ERROR] : [OCR_aligned] without \\\"%s\\\" doesn't correspond to [OCR_toInput] in file %s\" % (self.charExtend, filePath)\n",
    "\n",
    "        # Build the alignment map\n",
    "        self.aMap = [x.start() - i for i, x in enumerate(re.finditer(self.charExtend + r\"|$\", self.ocrAligned))]\n",
    "\n",
    "        #print(\"%s\\n%s\\n%s\" % (self.ocrOriginal, self.ocrAligned, self.gsAligned))\n",
    "\n",
    "    # Get the alignment shift for a position in the orginal OCR to the corresponding postion in the aligned OCR/GS\n",
    "    def get_aligned_shift(self, posOriginal):\n",
    "        return next((i for i, e in enumerate(self.aMap) if e >= posOriginal), 0)\n",
    "\n",
    "    # Get the alignment shift for a position in the orginal OCR to the corresponding postion in the aligned OCR/GS\n",
    "    def get_original_shift(self, posAligned):\n",
    "        return self.ocrAligned.count(self.charExtend, 0, posAligned)\n",
    "\n",
    "    # Get bounds in \"Aligned OCR/GS\" from a token position in the non-aligned OCR.\n",
    "    def get_aligned_token_bounds(self, tokenPos, nbToken=1):\n",
    "\n",
    "        assert (tokenPos == 0) or (self.ocrOriginal[tokenPos-1] == \" \"), \\\n",
    "            \"[ERROR] : %d is not a token start position (%s)\" % (tokenPos, self.filePath)\n",
    "\n",
    "        alignedPos = tokenPos + self.get_aligned_shift(tokenPos)\n",
    "        seqLen = nbToken-1 # Init with number of spaces\n",
    "        iterOcrAlignedSpace = re.finditer(r\"$|\\ \", self.ocrAligned[alignedPos:])\n",
    "        for nbt in range(nbToken):\n",
    "            matchSpace = next(iterOcrAlignedSpace, None)\n",
    "            if matchSpace is None:\n",
    "                print(\"[WARNING] : At pos %d, could not iterate forward over tokens, end of the sequence reached\" % tokenPos)\n",
    "                break\n",
    "            seqLen = matchSpace.start() # Look for last space before next token\n",
    "\n",
    "        return alignedPos, seqLen\n",
    "\n",
    "\n",
    "    # Get statistics (erroneous tokens' posisitions, corrections, ect...) on errors\n",
    "    def get_errors_stats(self):\n",
    "\n",
    "        #results = {}\n",
    "        nbTokens, nbErrTokens, nbErrTokensAlpha = 0, 0, 0\n",
    "\n",
    "        # Iterate over GS tokens\n",
    "        lastTokenPos = 0\n",
    "        for spacePos in re.finditer(r\"$|\\ \", self.gsAligned):\n",
    "\n",
    "            tokenEndPos = spacePos.start()\n",
    "            tokenInOcr = re.sub(self.charExtend, \"\", self.ocrAligned[lastTokenPos:tokenEndPos])\n",
    "            tokenInGs = re.sub(self.charExtend, \"\", self.gsAligned[lastTokenPos:tokenEndPos])\n",
    "\n",
    "            if self.charIgnore in tokenInGs:\n",
    "                lastTokenPos = tokenEndPos + 1\n",
    "                continue\n",
    "\n",
    "            #if (tokenInOcr != tokenInGs):\n",
    "            #    results[lastTokenPos] = [tokenInOcr, tokenInGs]\n",
    "            #    #print(\"_%s_%s_\" % (tokenInOcr, tokenInGs))\n",
    "\n",
    "            lastTokenPos = tokenEndPos + 1\n",
    "\n",
    "            nbTokens += 1\n",
    "            nbErrTokens += (tokenInOcr != tokenInGs)\n",
    "            nbErrTokensAlpha += (tokenInOcr != tokenInGs) and tokenInGs.strip().isalpha()\n",
    "\n",
    "        return nbTokens, nbErrTokens, nbErrTokensAlpha\n",
    "\n",
    "    def collectErrorPos(self):\n",
    "\n",
    "        errorList = []\n",
    "\n",
    "        # Add tolerance to hyphens : work on a new GS where hyphens founds in OCR are considered to be ignored in task1\n",
    "        gsAlignedHyphensIgnored = self.gsAligned\n",
    "        for hToken in re.finditer(r\"[^ ]*((\\ ?-[^ ])|([^ ]-\\ ?))[^ ]*\", self.ocrAligned):\n",
    "            gsAlignedHyphensIgnored = gsAlignedHyphensIgnored[:hToken.start()] + self.charIgnore*(hToken.end()-hToken.start()) + gsAlignedHyphensIgnored[hToken.end():]\n",
    "\n",
    "        gsSpacePos = set([spacePos.start() for spacePos in re.finditer(r\"^|$|\\ \", gsAlignedHyphensIgnored)])\n",
    "        ocrSpacePos = set([spacePos.start() for spacePos in re.finditer(r\"^|$|\\ \", self.ocrAligned)])\n",
    "        commonSpacePos = sorted(gsSpacePos.intersection(ocrSpacePos))\n",
    "        #print(commonSpacePos)\n",
    "\n",
    "        for i in range(len(commonSpacePos)-1):\n",
    "\n",
    "            tokenStartPos = commonSpacePos[i] + 1*(gsAlignedHyphensIgnored[commonSpacePos[i]]==\" \")\n",
    "            tokenEndPos = commonSpacePos[i+1]\n",
    "\n",
    "            tokenInGs = re.sub(self.charExtend, \"\", gsAlignedHyphensIgnored[tokenStartPos:tokenEndPos])\n",
    "            tokenInOcr = re.sub(self.charExtend, \"\", self.ocrAligned[tokenStartPos:tokenEndPos])\n",
    "\n",
    "            # Get not aligned pos\n",
    "            tokenStartPosOriginal = tokenStartPos - self.get_original_shift(tokenStartPos)\n",
    "\n",
    "            # Ignore the \"#\" in GS\n",
    "            if not (self.charIgnore in tokenInGs):\n",
    "                if (tokenInOcr != tokenInGs):\n",
    "                    #print(\"%d:%d|%d=%s=>%s\" % (tokenStartPosOriginal, tokenInOcr.count(\" \")+1, tokenStartPos , tokenInOcr, tokenInGs))\n",
    "                    errorList.append(\"%d:%d\" % (tokenStartPosOriginal, tokenInOcr.count(\" \")+1))\n",
    "                    #errorList.append(\"%d:%d|%d=%s=>%s\" % (tokenStartPosOriginal, tokenInOcr.count(\" \") + 1, tokenStartPos, tokenInOcr, tokenInGs))\n",
    "\n",
    "        return errorList\n",
    "\n",
    "\n",
    "    def task1_eval(self, inputErroneousTokens):\n",
    "\n",
    "        # Add tolerance to hyphens : work on a new GS where hyphens founds in OCR are considered to be ignored in task1\n",
    "        gsAlignedHyphensIgnored = self.gsAligned\n",
    "        for hToken in re.finditer(r\"[^ ]*((\\ ?-[^ ])|([^ ]-\\ ?))[^ ]*\", self.ocrAligned):\n",
    "            gsAlignedHyphensIgnored = gsAlignedHyphensIgnored[:hToken.start()] + self.charIgnore*(hToken.end()-hToken.start()) + gsAlignedHyphensIgnored[hToken.end():]\n",
    "\n",
    "        # 1) Prepare input results : unfold overlapping n tokens in tokenPosErr\n",
    "        detectedErrPosUnfolded = {}\n",
    "        for errPos, val in inputErroneousTokens.items():\n",
    "            tokenStartPos = 0\n",
    "            iterTokens = re.finditer(r\"$|\\ \", self.ocrOriginal[errPos:])\n",
    "            for t in range(val[\"nbToken\"]):\n",
    "\n",
    "                alignedPos, seqLen = self.get_aligned_token_bounds((errPos + tokenStartPos), 1)\n",
    "                rawTokenInAlignedGs = gsAlignedHyphensIgnored[alignedPos:(alignedPos + seqLen + 1)]\n",
    "\n",
    "                if not (self.charIgnore in rawTokenInAlignedGs):\n",
    "\n",
    "                    # Check if there is no overlapping errors/corrections\n",
    "                    assert alignedPos not in detectedErrPosUnfolded, \"[ERROR] : Error at pos %d is overlapping another given error ! Pay attention to the number of overlapping tokens.\" % (errPos + tokenStartPos)\n",
    "                    detectedErrPosUnfolded[alignedPos] = [rawTokenInAlignedGs, val[\"candidates\"]]\n",
    "\n",
    "                tokenEndMatch = next(iterTokens, None)\n",
    "                if tokenEndMatch is None:\n",
    "                    break\n",
    "\n",
    "                tokenStartPos = tokenEndMatch.start() + 1\n",
    "\n",
    "        if self.verbose:\n",
    "            EvalContext.printDicoSortedByKey(detectedErrPosUnfolded, \"1) detectedErrPosUnfolded\")\n",
    "\n",
    "\n",
    "        # 2) Prepare real results\n",
    "        realErrPosUnfolded = {}\n",
    "        iterTokens = re.finditer(r\"$|\\ \", self.ocrAligned)\n",
    "        tokenStartPos = 0\n",
    "        tokenEndMatch = next(iterTokens, None)\n",
    "\n",
    "        while tokenEndMatch is not None:\n",
    "\n",
    "            tokenEndPos = tokenEndMatch.start() + 1  # Include following char\n",
    "\n",
    "            tokenInGs = re.sub(self.charExtend, \"\", gsAlignedHyphensIgnored[max(0,tokenStartPos-1):tokenEndPos])\n",
    "            tokenInOcr = re.sub(self.charExtend, \"\", self.ocrAligned[max(0,tokenStartPos-1):tokenEndPos])\n",
    "\n",
    "            # Ignore the \"#\" in GS\n",
    "            if not (self.charIgnore in tokenInGs):\n",
    "                if (tokenInOcr != tokenInGs):\n",
    "                    realErrPosUnfolded[tokenStartPos] = [tokenInOcr, tokenInGs]\n",
    "\n",
    "            tokenStartPos = tokenEndPos\n",
    "            tokenEndMatch = next(iterTokens, None)\n",
    "\n",
    "        if self.verbose:\n",
    "            EvalContext.printDicoSortedByKey(realErrPosUnfolded, \"2) realErrPosUnfolded\")\n",
    "\n",
    "        realErrPos = set(realErrPosUnfolded.keys())\n",
    "\n",
    "        # 3) Compute classical metrics\n",
    "        setErrPos = set(detectedErrPosUnfolded.keys())\n",
    "        errTP = len(setErrPos.intersection(realErrPos))  # TruePositive\n",
    "        errFP = len(setErrPos.difference(realErrPos))  # TrueNegative\n",
    "        errFN = len(realErrPos.difference(setErrPos))  # FalseNegative\n",
    "\n",
    "\n",
    "        # Possible division per 0\n",
    "        prec = (errTP / float(errTP + errFP)) if (errTP + errFP) > 0 else 0\n",
    "        recall = (errTP / float(errTP + errFN)) if (errTP + errFN) > 0 else 0\n",
    "        fmes = (2.0 * float(prec * recall) / float(prec + recall)) if (prec + recall) > 0 else 0\n",
    "\n",
    "\t\t# Debug test\n",
    "        if self.verbose:\n",
    "            print(\"TASK 1) ErrTP %d / errFP %d / errFN %d /\" % (errTP, errFP, errFN) + \\\n",
    "                  \" prec %0.2f / recall %0.2f / fmes %0.2f\" % (prec, recall, fmes))\n",
    "\n",
    "        return prec, recall, fmes\n",
    "\n",
    "\n",
    "    def task2_eval(self, inputErroneousTokens, useFirstCandidateOnly=False):\n",
    "\n",
    "        # Init list of tokens' levenshtein distances\n",
    "        originalDistance, correctedDistance = [0], [0]\n",
    "        nbSymbolsConsidered = 0\n",
    "\n",
    "        # Get tokens (or sequences including hyphens)\n",
    "        splitRegExp = r\"(?=([^-]\\ [^-]))\" # Now supporting overlapping\n",
    "        spaceOCR = set([sp.start()+1 for sp in re.finditer(splitRegExp, self.ocrAligned)])\n",
    "        spaceGS  = set([sp.start()+1 for sp in re.finditer(splitRegExp, self.gsAligned)])\n",
    "\n",
    "\n",
    "        # Collect running tokens defined in correction...\n",
    "        spaceCorToRemove = []\n",
    "        inputErroneousTokensAligned = {}\n",
    "        for p, details in inputErroneousTokens.items():\n",
    "            posAligned = p + self.get_aligned_shift(p)\n",
    "            inputErroneousTokensAligned[posAligned] =  details\n",
    "            for m in itertools.islice(re.finditer(r\"$|\\ \", self.ocrAligned[posAligned:]), details[\"nbToken\"]-1):\n",
    "                spaceCorToRemove.append(m.start() + posAligned)\n",
    "\n",
    "\n",
    "        #print(\"spaceCommon %s\" % str(sorted(spaceOCR.intersection(spaceGS))))\n",
    "        #print(\"spaceCorToRemove %s\" % str(sorted(spaceCorToRemove)))\n",
    "\n",
    "        spaceCommon = (spaceOCR.intersection(spaceGS)).difference(spaceCorToRemove)\n",
    "        spaceCommon.add(len(self.ocrAligned))\n",
    "\n",
    "        # Iterate over comparable sequences\n",
    "        lastTokenStartPos = 0\n",
    "        for tokenEndPos in sorted(spaceCommon):\n",
    "\n",
    "            tokenInGs = self.gsAligned[lastTokenStartPos:tokenEndPos]\n",
    "            tokenInOcr = self.ocrAligned[lastTokenStartPos:tokenEndPos]\n",
    "\n",
    "            # Get corrections concerned by this sequence :\n",
    "            tokensPosToCorrect = set(range(lastTokenStartPos, tokenEndPos)).intersection(inputErroneousTokensAligned.keys())\n",
    "\n",
    "            listCombinaisons = []\n",
    "            for p in tokensPosToCorrect:\n",
    "                listCombinaisons.append([[p, c] for c, w in inputErroneousTokensAligned[p][\"candidates\"].items()])\n",
    "\n",
    "            tokenProposed = {}\n",
    "            for combi in itertools.product(*iter(listCombinaisons)):\n",
    "\n",
    "                # Default\n",
    "                corToken = list(tokenInOcr)\n",
    "\n",
    "                prodWeight = 1.0\n",
    "                for pc in sorted(combi, key=lambda k: k[0], reverse=True):\n",
    "\n",
    "                    offsetStart = inputErroneousTokensAligned[pc[0]][\"boundsAligned\"][0] - lastTokenStartPos\n",
    "                    offsetEnd = offsetStart + inputErroneousTokensAligned[pc[0]][\"boundsAligned\"][1]\n",
    "\n",
    "                    corToken[offsetStart:offsetEnd] = pc[1]\n",
    "                    prodWeight = prodWeight * inputErroneousTokensAligned[pc[0]][\"candidates\"][pc[1]]\n",
    "\n",
    "                tokenProposed[re.sub(self.charExtend, \"\", \"\".join(corToken))] = prodWeight\n",
    "\n",
    "            # Fix GC 15/06/2017\n",
    "            if len(tokenProposed) == 0:\n",
    "                tokenProposed = {tokenInOcr:1.0}\n",
    "\n",
    "            # In case we want to consider only the highest candidate\n",
    "            if useFirstCandidateOnly and len(tokenProposed)>0:\n",
    "                tokenProposed = {max(tokenProposed, key=tokenProposed.get): 1.0}\n",
    "\n",
    "            # Consider results only if no \"#\" found in the token (or tokens sequence).\n",
    "            if not (self.charIgnore in tokenInGs):\n",
    "\n",
    "                # Update damerau_levenshtein_distance distances' lists\n",
    "                ignoreList = [\" -\", \"- \", \"-\", self.charExtend]\n",
    "                originalDistance.append(EvalContext.damerau_levenshtein(tokenInOcr, tokenInGs, ignoreList=ignoreList))\n",
    "\n",
    "                weightedSum = sum([EvalContext.damerau_levenshtein(token, tokenInGs, ignoreList=ignoreList) * float(w) for token, w in tokenProposed.items()])\n",
    "                correctedDistance.append(weightedSum)\n",
    "                nbSymbolsConsidered += len(tokenInOcr)\n",
    "\n",
    "            else:\n",
    "                # print(\"[IGNORED] Token _%s_%s_ => %s\" % (tokenInOcr, tokenInGs, tokenProposed))\n",
    "                pass\n",
    "\n",
    "            #print(\"(%d=>%d) %s | %s | %s \" % (lastTokenStartPos,tokenEndPos, re.sub(self.charExtend, \"\", tokenInOcr), re.sub(self.charExtend, \"\", tokenInGs), str(tokenProposed) ))\n",
    "            lastTokenStartPos = tokenEndPos+1\n",
    "\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"TASK 2) correctedDistance %d vs originalDistance %d\" % (sum(correctedDistance), sum(originalDistance)))\n",
    "\n",
    "        #print(correctedDistance)\n",
    "\n",
    "        return sum(correctedDistance), sum(originalDistance), nbSymbolsConsidered\n",
    "    \n",
    "    # --- Damerau-Levenshtein distance between 2 strings ---\n",
    "    # Slightly modified version of https://github.com/jamesturk/jellyfish\n",
    "    # under Copyright 2015, James TurkJames Turk, Sunlight Foundation\n",
    "    # with LICENSE BSD 2: https://github.com/jamesturk/jellyfish/blob/master/LICENSE\n",
    "    @staticmethod\n",
    "    def damerau_levenshtein(s1, s2, ignoreList=[\" -\", \"- \", \"-\"]):\n",
    "\n",
    "        # Add tolerence on some characters (e.g. hyphens) cause GS is not always perfect.\n",
    "        s1 = re.sub(\"(\" + \")|(\".join(ignoreList) + \")\", \"\", s1)\n",
    "        s2 = re.sub(\"(\" + \")|(\".join(ignoreList) + \")\", \"\", s2)\n",
    "\n",
    "        if s1==s2:\n",
    "            return 0\n",
    "\n",
    "        len1 = len(s1)\n",
    "        len2 = len(s2)\n",
    "        infinite = len1 + len2\n",
    "\n",
    "        # character array\n",
    "        da = collections.defaultdict(int)\n",
    "\n",
    "        # distance matrix\n",
    "        score = [[0] * (len2 + 2) for x in range(len1 + 2)]\n",
    "\n",
    "        score[0][0] = infinite\n",
    "        for i in range(0, len1 + 1):\n",
    "            score[i + 1][0] = infinite\n",
    "            score[i + 1][1] = i\n",
    "        for i in range(0, len2 + 1):\n",
    "            score[0][i + 1] = infinite\n",
    "            score[1][i + 1] = i\n",
    "\n",
    "        for i in range(1, len1 + 1):\n",
    "            db = 0\n",
    "            for j in range(1, len2 + 1):\n",
    "                i1 = da[s2[j - 1]]\n",
    "                j1 = db\n",
    "                cost = 1\n",
    "                if s1[i - 1] == s2[j - 1]:\n",
    "                    cost = 0\n",
    "                    db = j\n",
    "\n",
    "                score[i + 1][j + 1] = min(score[i][j] + cost,\n",
    "                                          score[i + 1][j] + 1,\n",
    "                                          score[i][j + 1] + 1,\n",
    "                                          score[i1][j1] + (i - i1 - 1) + 1 + (j - j1 - 1))\n",
    "            da[s1[i - 1]] = i\n",
    "\n",
    "        return score[len1 + 1][len2 + 1]\n",
    "\n",
    "\n",
    "    # For debugging\n",
    "    @staticmethod\n",
    "    def printDicoSortedByKey(d, dicoName=\"Dico\"):\n",
    "        sortedKeysDic = list(d.keys())\n",
    "        sortedKeysDic.sort()\n",
    "        print(\"\\n#########---- Print Sorted %s ----######### \" % dicoName)\n",
    "        for k in sortedKeysDic:\n",
    "            print(\"%s:%s\" % (str(k), str(d[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "in_file = Path(os.getcwd())/'data'/'example.txt'\n",
    "\n",
    "eval_context = EvalContext(in_file, verbose=True)\n",
    "\n",
    "n_tokens, n_errors, _ = eval_context.get_errors_stats()\n",
    "\n",
    "assert n_tokens == 4, f'Number of tokens is {n_tokens}, not 4'\n",
    "assert n_errors == 2, f'Number of erroneous tokens is {n_errors}, not 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def reshape_input_errors(tokenPosErr, evalContext, verbose=False):\n",
    "    # Store tokens' positions in mem\n",
    "    tokensPos = [0] + [spacePos.start() + 1 for spacePos in re.finditer(r\"\\ \", evalContext.ocrOriginal)]\n",
    "\n",
    "    # 1) Check JSON result format (ex: positions correspond to tokens)\n",
    "    # 2) Reshape data \"pos\":{\"nbTokens\":..., \"boundsAligned\":..., candidates:... }\"\n",
    "    # 3) Locally normalize candidates' weights id needed\n",
    "    tokenPosErrReshaped = {}\n",
    "    for pos_nbtokens, candidates in tokenPosErr.items():\n",
    "\n",
    "        pos, nbOverlappingToken = [int(i) for i in pos_nbtokens.split(':')]\n",
    "        boundsAligned = evalContext.get_aligned_token_bounds(pos, nbOverlappingToken)\n",
    "\n",
    "        # Check pos targets a existing token (first char)\n",
    "        assert pos in tokensPos,\\\n",
    "            \"[ERROR] : Error at pos %s does not target the first char of a token (space separated sequences).\" % pos\n",
    "\n",
    "        assert evalContext.ocrOriginal[pos:].count(\" \") >= nbOverlappingToken-1,\\\n",
    "            \"[ERROR] : Error at pos %d spreads overs %d tokens which goes ouside the sequence.\" % (pos,nbOverlappingToken)\n",
    "\n",
    "        # Normalize candidates weights if needed\n",
    "        normCandidates = {}\n",
    "\n",
    "        # Limit the number of candiates\n",
    "        for k,v in sorted(candidates.items(), key=lambda kv: kv[1], reverse=True):\n",
    "            normCandidates[k] = v\n",
    "            if len(normCandidates) >= maxNbCandidate:\n",
    "                break\n",
    "\n",
    "        if len(normCandidates) > 0 and sum(normCandidates.values()) != 1:\n",
    "            print(\"[WARNING] : Normalizing weights at %s:%s\" % (pos_nbtokens, str(normCandidates)) )\n",
    "            normCandidates = {cor: float(x)/sum(normCandidates.values()) for cor, x in normCandidates.items()}\n",
    "\n",
    "        tokenPosErrReshaped[pos] = {\n",
    "            \"nbToken\":nbOverlappingToken,\n",
    "            \"boundsAligned\":boundsAligned,\n",
    "            \"ocrSeq\":re.sub(evalContext.charExtend, \"\",evalContext.ocrAligned[boundsAligned[0]:boundsAligned[0]+boundsAligned[1]]),\n",
    "            \"gsSeq\":re.sub(evalContext.charExtend, \"\",evalContext.gsAligned[boundsAligned[0]:boundsAligned[0] + boundsAligned[1]]),\n",
    "            \"candidates\":normCandidates\n",
    "        }\n",
    "\n",
    "    # Debug test\n",
    "    if verbose:\n",
    "        EvalContext.printDicoSortedByKey(tokenPosErrReshaped, \"tokenPosErrReshaped\")\n",
    "\n",
    "    return tokenPosErrReshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "in_file = Path(os.getcwd())/'data'/'example.txt'\n",
    "\n",
    "eval_context = EvalContext(in_file)\n",
    "text = process_text(in_file)\n",
    "test_input = {'key': text}\n",
    "error_input = create_perfect_icdar_output(test_input)\n",
    "\n",
    "actual = reshape_input_errors(error_input['key'], eval_context)\n",
    "\n",
    "expected = {8: {'nbToken': 1,\n",
    "  'boundsAligned': (8, 2),\n",
    "  'ocrSeq': 'a',\n",
    "  'gsSeq': 'an',\n",
    "  'candidates': {}},\n",
    " 10: {'nbToken': 1,\n",
    "  'boundsAligned': (11, 10),\n",
    "  'ocrSeq': 'cxample...',\n",
    "  'gsSeq': 'example.',\n",
    "  'candidates': {}}}\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#########---- Print Sorted 1) detectedErrPosUnfolded ----######### \n",
      "8:['an ', {}]\n",
      "11:['example.', {}]\n",
      "OCR: ' a ', GS: ' an '\n",
      "OCR: ' cxample.', GS: ' example.'\n",
      "\n",
      "#########---- Print Sorted 2) realErrPosUnfolded ----######### \n",
      "8:[' a ', ' an ']\n",
      "11:[' cxample.', ' example.']\n",
      "TASK 1) ErrTP 2 / errFP 0 / errFN 0 / prec 1.00 / recall 1.00 / fmes 1.00\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "# This file contains trailing spaces (on purpose) to test for a specific problem \n",
    "# when calculating task 1 performance.\n",
    "# Be careful when opening this file. Some IDEs remove trailing spaces on save!\n",
    "in_file = Path(os.getcwd())/'data'/'example2.txt'\n",
    "\n",
    "eval_context = EvalContext(in_file, verbose=True)\n",
    "text = process_text(in_file)\n",
    "test_input = {'key': text}\n",
    "error_input = create_perfect_icdar_output(test_input)\n",
    "reshaped_errors = reshape_input_errors(error_input['key'], eval_context)\n",
    "\n",
    "prec, recall, _fmeasure = eval_context.task1_eval(reshaped_errors)\n",
    "\n",
    "assert prec == 1.0, f'Precision is {prec}, not 1.0'\n",
    "assert recall == 1.0, f'Recall is {recall}, not 1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#########---- Print Sorted 1) detectedErrPosUnfolded ----######### \n",
      "8:['x ', {}]\n",
      "\n",
      "#########---- Print Sorted 2) realErrPosUnfolded ----######### \n",
      "8:[' & ', ' x ']\n",
      "10:[' ', ' bla']\n",
      "TASK 1) ErrTP 1 / errFP 0 / errFN 1 / prec 1.00 / recall 0.50 / fmes 0.67\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Recall is 0.5, not 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-dbefb0ad7cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprec\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Precision is {prec}, not 1.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Recall is {recall}, not 1.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Recall is 0.5, not 1.0"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "# ocr aligned has a trailing space after removing the alignment characters\n",
    "in_file = Path(os.getcwd())/'data'/'example3.txt'\n",
    "\n",
    "eval_context = EvalContext(in_file, verbose=True)\n",
    "text = process_text(in_file)\n",
    "test_input = {'key': text}\n",
    "error_input = create_perfect_icdar_output(test_input)\n",
    "reshaped_errors = reshape_input_errors(error_input['key'], eval_context)\n",
    "\n",
    "prec, recall, _fmeasure = eval_context.task1_eval(reshaped_errors)\n",
    "\n",
    "assert prec == 1.0, f'Precision is {prec}, not 1.0'\n",
    "assert recall == 1.0, f'Recall is {recall}, not 1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignedToken(ocr='example', gs='example', ocr_aligned='example', gs_aligned='example', start=0, len_ocr=7)\n",
      "AlignedToken(ocr='&', gs='x', ocr_aligned='&', gs_aligned='x', start=8, len_ocr=1)\n"
     ]
    }
   ],
   "source": [
    "for t in text.tokens:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def runEvaluation(datasetDirPath,  # path to the dataset directory (ex: r\"./dataset_sample\")\n",
    "                  pathInputJsonErrorsCorrections,  # # input path to the JSON result (ex: r\"./inputErrCor_sample.json\"), format given on https://sites.google.com/view/icdar2017-postcorrectionocr/evaluation)\n",
    "                  pathOutputCsv,  # output path to the CSV evaluation results (ex: r\"./outputEval.csv\")\n",
    "                  verbose=False):  # Show verbose output\n",
    "    \"\"\"Main evaluation method\"\"\"\n",
    "\n",
    "    # Load results JSON file\n",
    "    with codecs.open(pathInputJsonErrorsCorrections, \"r\", encoding=\"utf-8\") as data_file:\n",
    "        formatedRes = json.loads(data_file.read())\n",
    "\n",
    "    # CSV header fields\n",
    "    csvHeader = [\"File\", \"NbTokens\", \"NbErroneousTokens\", \"NbSymbolsConsidered\", # NbTokens furtherly used to weight file's metrics \\\n",
    "                 \"T1_Precision\", \"T1_Recall\", \"T1_Fmesure\", # Task 1) Metrics \\\n",
    "                 \"T2_AvgLVDistOriginal\", \"T2_AvgLVDistCorrected\"] # Task 2) Metrics\n",
    "\n",
    "    # Write CSV file's header into a new output file\n",
    "    with open(pathOutputCsv, 'w') as outputFile:\n",
    "        outputFile.write(\";\".join(csvHeader) + \"\\n\")\n",
    "\n",
    "    # Print CSV header into the console file\n",
    "    print(\"\\t\".join(csvHeader))\n",
    "\n",
    "    # Iterate over all the file's paths given in the input results\n",
    "    for filePath, tokenPosErr in formatedRes.items():\n",
    "\n",
    "        # Load the context : [OCR_toInput], [OCR_aligned] and [ GS_aligned]\n",
    "        evalContext = EvalContext(os.path.join(datasetDirPath, filePath), verbose=verbose)\n",
    "\n",
    "        # Compute some intrinsic statistics\n",
    "        nbTokens, nbErrTokens, nbErrTokensAlpha = evalContext.get_errors_stats()\n",
    "\n",
    "        tokenPosErrReshaped = reshape_input_errors(tokenPosErr, evalContext, verbose)\n",
    "\n",
    "        # Task 1) Run the evaluation : Detection of the position of erroneous tokens\n",
    "        prec, recall, fmes = evalContext.task1_eval(tokenPosErrReshaped)\n",
    "\n",
    "        # Task 2) Run the evaluation : Correction of the erroneous tokens\n",
    "        sumCorrectedDistance, sumOriginalDistance, nbSymbolsConsidered = evalContext.task2_eval(tokenPosErrReshaped, useFirstCandidateOnly=False)\n",
    "\n",
    "        # Manage division per zero\n",
    "        avgCorrectedDistance = sumCorrectedDistance / float(nbSymbolsConsidered) if nbSymbolsConsidered > 0 else 0\n",
    "        avgOriginalDistance = sumOriginalDistance / float(nbSymbolsConsidered) if nbSymbolsConsidered > 0 else 0\n",
    "\n",
    "        # Format results in CSV\n",
    "        strRes = \"%s;%d;%d;%d;%0.02f;%0.02f;%0.02f;%0.02f;%0.02f\" % \\\n",
    "                (filePath, nbTokens, nbErrTokens, nbSymbolsConsidered, prec, recall, fmes, avgOriginalDistance, avgCorrectedDistance)\n",
    "\n",
    "        # Write results in output file\n",
    "        with open(pathOutputCsv, 'a') as outputFile:\n",
    "            outputFile.write(strRes + \"\\n\")\n",
    "\n",
    "        # Print results in the console\n",
    "        print(strRes.replace(\";\", \"\\t\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize icdar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def aggregate_results(csv_file):\n",
    "    data = pd.read_csv(csv_file, sep=';')\n",
    "    data['language'] = data.File.apply(lambda x: x[:2])\n",
    "    data['subset'] = data.File.apply(lambda x: x.split('/')[1])\n",
    "\n",
    "    return data.groupby('language').mean()[['T1_Precision', 'T1_Recall', 'T1_Fmesure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def reduce_dataset(dataset, n=5):\n",
    "    \"\"\"Return dataset with the first n samples for each split\"\"\"\n",
    "    for split in dataset.keys():\n",
    "        dataset[split] = dataset[split].select(range(n))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nlp4dutch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
