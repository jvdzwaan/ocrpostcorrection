{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Load BERT Model\n",
    "# Sample indices\n",
    "# For every index:\n",
    "#   - Get BERT output\n",
    "#   - Load BERT output in dataset\n",
    "#   - Compare"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/mntDrive')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers datasets"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "in_dir = Path('/mntDrive/MyDrive/icdar-dataset-20220207')\n",
    "#in_dir = Path('icdar-dataset-20220207')\n",
    "\n",
    "train = pd.read_csv(in_dir/'task2_train.csv', index_col=0)\n",
    "val = pd.read_csv(in_dir/'task2_val.csv', index_col=0)\n",
    "test = pd.read_csv(in_dir/'task2_test.csv', index_col=0)\n",
    "\n",
    "train = train.fillna('')\n",
    "val = val.fillna('')\n",
    "test = test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:', train.shape[0], 'samples')\n",
    "print('val:', val.shape[0], 'samples')\n",
    "print('test:', test.shape[0], 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lens(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data['len_ocr'] = data['ocr'].apply(lambda x: len(x))\n",
    "    data['len_gs'] = data['gs'].apply(lambda x: len(x))\n",
    "\n",
    "    return data\n",
    "\n",
    "train = add_lens(train)\n",
    "val = add_lens(val)\n",
    "test = add_lens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Task2Dataset(Dataset):\n",
    "    def __init__(self, data, task1_data_dir, max_len=11, batch_size=8):\n",
    "        self.ds = data.query(f'len_ocr < {max_len}').query(f'len_gs < {max_len}').copy()\n",
    "        self.ds = self.ds.reset_index(drop=False)\n",
    "\n",
    "        self.task1_data_dir = task1_data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ds.loc[idx]\n",
    "        original_idx = sample['index']\n",
    "        print('original idx', original_idx)\n",
    "\n",
    "        file_index = original_idx // self.batch_size\n",
    "        index_in_file = original_idx % self.batch_size\n",
    "        in_file = self.task1_data_dir/f'task2_task1_output_{file_index}.pt'\n",
    "        task1_output_batch = torch.load(in_file)\n",
    "        # Copy the task1_ouput slice, so we have a new tensor\n",
    "        task1_output = task1_output_batch[index_in_file].clone().detach().requires_grad_(True)\n",
    "\n",
    "        return sample.ocr, sample.gs, task1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path('/mntDrive/MyDrive/icdar-dataset-20220207')\n",
    "\n",
    "#out_dir = Path('icdar-dataset-20220207')\n",
    "data_dir = out_dir/'task1_output'/'test'\n",
    "\n",
    "ds = Task2Dataset(test, data_dir, max_len=11, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ocr, gs, hidden_input in ds:\n",
    "    print(ocr, gs, hidden_input[:3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/mntDrive/MyDrive/results-0.3-20220207-no-checkpoints'\n",
    "#model_dir = '/Users/janneke/models/results-0.3-20220207'\n",
    "model_name = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_indices(dataset_size, num=10):\n",
    "    return np.random.choice(dataset_size, size=num, replace=False)\n",
    "\n",
    "indices = get_indices(len(ds))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for idx in indices:\n",
    "        sample = ds[idx]\n",
    "        ocr = sample[0]\n",
    "        tokenized_ocr = tokenizer(ocr, return_tensors=\"pt\")\n",
    "        output = model(tokenized_ocr['input_ids'])\n",
    "        print(ocr, tokenized_ocr)\n",
    "        expected = output['pooler_output'].detach().cpu()[0].numpy()\n",
    "\n",
    "        actual = sample[2].requires_grad_(False).numpy()\n",
    "\n",
    "        num = 5\n",
    "        print('expected:', expected[:num])\n",
    "        print('actual:', actual[:num])\n",
    "        # print('np equal', np.equal(expected, actual))\n",
    "        print('np allclose', np.allclose(expected, actual))\n",
    "\n",
    "        # output = model(tokenized_ocr['input_ids'])\n",
    "        # print(ocr, tokenized_ocr)\n",
    "        # expected2 = output['pooler_output'].detach().cpu()[0]\n",
    "\n",
    "        # print(expected.size())\n",
    "        # print(actual.size())\n",
    "        print(expected[:10])\n",
    "        print(actual[:10])\n",
    "\n",
    "        # print(torch.equal(expected, expected2))\n",
    "        # print(torch.allclose(expected, expected2))\n",
    "        # print(torch.sum(torch.eq(expected, expected2)).item())\n",
    "        # print(torch.eq(expected, expected2))\n",
    "\n",
    "        # print(torch.equal(expected, actual))\n",
    "        # print(torch.allclose(expected, actual))\n",
    "        # print(torch.sum(torch.eq(expected, actual)).item())\n",
    "        # print(torch.eq(expected, actual))\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
