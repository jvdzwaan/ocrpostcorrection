{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlp4dutch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1fa962b3271c92d5bbb9f388fd57cca0da7673b4fedc1b84f54d72b9319215d1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOGURU_LEVEL'] = 'INFO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Get corresponding Loguru level if it exists\n",
    "        try:\n",
    "            level = logger.level(record.levelname).name\n",
    "        except ValueError:\n",
    "            level = record.levelno\n",
    "\n",
    "        # Find caller from where originated the logged message\n",
    "        frame, depth = logging.currentframe(), 2\n",
    "        while frame.f_code.co_filename == logging.__file__:\n",
    "            frame = frame.f_back\n",
    "            depth += 1\n",
    "\n",
    "        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n",
    "\n",
    "logging.basicConfig(handlers=[InterceptHandler()], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-03-05 15:36:38,447 Reading data from .\n",
      "2021-03-05 15:36:38,451 Train: train.txt\n",
      "2021-03-05 15:36:38,474 Dev: dev.txt\n",
      "2021-03-05 15:36:38,487 Test: test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'ocr_mistake'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '.'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              column_delimiter='\\t',\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Corpus: 118812 train + 13060 dev + 35361 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample for testing\n",
    "corpus = corpus.downsample(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sentence: \"Quant aux ossements rapportés du cimetière des Pestiférés, ils surent sur-le-champ déposés chez M. Gérard Pâté; et le procès-ver bal de l’enlèvemcnt, rédigé sur les lieux et signé de tous les témoins, lut remis entre les mains des vicaires généraux, MM.\"   [− Tokens: 41  − Token-Labels: \"Quant <0> aux <0> ossements <0> rapportés <0> du <0> cimetière <0> des <0> Pestiférés, <0> ils <0> surent <1> sur-le-champ <0> déposés <0> chez <0> M. <0> Gérard <0> Pâté; <0> et <0> le <0> procès-ver <1> bal <0> de <0> l’enlèvemcnt, <1> rédigé <0> sur <0> les <0> lieux <0> et <0> signé <0> de <0> tous <0> les <0> témoins, <0> lut <1> remis <0> entre <0> les <0> mains <0> des <0> vicaires <0> généraux, <0> MM. <0>\"]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "corpus.train[15309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dictionary with 6 tags: <unk>, O, 1, 0, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ocr_mistake'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-03-05 15:50:40,935 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-forward-v0.1.pt not found in cache, downloading to /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmpucbimb0s\n",
      "100%|██████████| 172513724/172513724 [00:14<00:00, 11526998.21B/s]2021-03-05 15:50:56,258 copying /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmpucbimb0s to cache at /Users/janneke/.flair/embeddings/lm-jw300-forward-v0.1.pt\n",
      "\n",
      "2021-03-05 15:50:57,353 removing temp file /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmpucbimb0s\n",
      "2021-03-05 15:50:58,852 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-backward-v0.1.pt not found in cache, downloading to /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmp_1_0042y\n",
      "100%|██████████| 172513724/172513724 [00:15<00:00, 10889906.83B/s]2021-03-05 15:51:14,906 copying /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmp_1_0042y to cache at /Users/janneke/.flair/embeddings/lm-jw300-backward-v0.1.pt\n",
      "\n",
      "2021-03-05 15:51:16,242 removing temp file /var/folders/wf/s_2kht555m52w66184wpyzl80000gn/T/tmp_1_0042y\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types = [\n",
    "\n",
    "    # WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    FlairEmbeddings('multi-forward'),\n",
    "    FlairEmbeddings('multi-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  }
 ]
}