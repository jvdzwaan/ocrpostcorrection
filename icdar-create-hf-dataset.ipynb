{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOGURU_LEVEL'] = 'INFO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Get corresponding Loguru level if it exists\n",
    "        try:\n",
    "            level = logger.level(record.levelname).name\n",
    "        except ValueError:\n",
    "            level = record.levelno\n",
    "\n",
    "        # Find caller from where originated the logged message\n",
    "        frame, depth = logging.currentframe(), 2\n",
    "        while frame.f_code.co_filename == logging.__file__:\n",
    "            frame = frame.f_back\n",
    "            depth += 1\n",
    "\n",
    "        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n",
    "\n",
    "logging.basicConfig(handlers=[InterceptHandler()], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "in_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import remove_label_and_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import normalized_ed, AlignedToken, InputToken, \\\n",
    "    get_input_tokens, tokenize_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AlignedToken('Long ow.', 'Longhow.', 'Long ow.', 'Longhow.', 24, 8)\n",
    "print(t)\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "gs = []\n",
    "\n",
    "for inp_tok in get_input_tokens(t):\n",
    "    print(inp_tok)\n",
    "    tokens.append(inp_tok.ocr)\n",
    "    labels.append(inp_tok.label)\n",
    "    gs.append(inp_tok.gs)\n",
    "\n",
    "assert tokens == ['Long', 'ow.']\n",
    "assert labels == [1, 2]\n",
    "assert ''.join(gs) == t.gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AlignedToken('INEVR', 'I NEVER', 'I@NEV@R', 'I NEVER', 0, 5)\n",
    "print(t)\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "gs = []\n",
    "\n",
    "for inp_tok in get_input_tokens(t):\n",
    "    print(inp_tok)\n",
    "    tokens.append(inp_tok.ocr)\n",
    "    labels.append(inp_tok.label)\n",
    "    gs.append(inp_tok.gs)\n",
    "\n",
    "assert tokens == ['INEVR']\n",
    "assert labels == [1]\n",
    "assert ''.join(gs) == t.gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AlignedToken('Major', 'Major', 'Major', 'Major', 19, 5)\n",
    "print(t)\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "gs = []\n",
    "\n",
    "for inp_tok in get_input_tokens(t):\n",
    "    print(inp_tok)\n",
    "    tokens.append(inp_tok.ocr)\n",
    "    labels.append(inp_tok.label)\n",
    "    gs.append(inp_tok.gs)\n",
    "\n",
    "assert tokens == ['Major']\n",
    "assert labels == [0]\n",
    "assert ''.join(gs) == t.gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import process_text\n",
    "\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "\n",
    "text = process_text(in_dir/'NL'/'NL1'/'17.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.tokens[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.input_tokens[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and val data\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "data, md = generate_data(in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test data\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_evaluation_4M_without_Finnish')\n",
    "data_test, md_test = generate_data(in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.num_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.num_tokens.hist(bins=2000, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.num_input_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.num_input_tokens.hist(bins=2000, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.score.hist(bins=50, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.query('score <= 0.3').num_tokens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, _, _ = train_test_split(md, md['file_name'], test_size=0.1, \n",
    "                                        shuffle=True, stratify=md['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('icdar-dataset-20220207')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(out_dir/'train.csv')\n",
    "X_val.to_csv(out_dir/'val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = md_test\n",
    "\n",
    "X_test.to_csv(out_dir/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(out_dir/'train.csv')\n",
    "X_val = pd.read_csv(out_dir/'val.csv')\n",
    "X_test = pd.read_csv(out_dir/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 'sentences' for train and val sets\n",
    "\n",
    "from datautils import generate_sentences\n",
    "\n",
    "train_data = generate_sentences(X_train, data, size=35, step=30)\n",
    "val_data = generate_sentences(X_val, data, size=35, step=30)\n",
    "test_data = generate_sentences(X_test, data_test, size=35, step=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_json(out_dir/'icdar_train.jsonl', orient='records', lines=True)\n",
    "val_data.to_json(out_dir/'icdar_val.jsonl', orient='records', lines=True)\n",
    "test_data.to_json(out_dir/'icdar_test.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "out_dir = Path('icdar-dataset-20220207')\n",
    "\n",
    "data_files = {'train': str(out_dir/'icdar_train.jsonl'),\n",
    "              'val': str(out_dir/'icdar_val.jsonl'),\n",
    "              'test': str(out_dir/'icdar_test.jsonl')}\n",
    "\n",
    "icdar_dataset = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.score.hist(bins=50, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.score.hist(bins=50, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdar_dataset = icdar_dataset.filter(lambda sample: sample['score'] <= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdar_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdar_dataset.save_to_disk('icdar-0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "icdar_dataset = load_from_disk('icdar-0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdar_dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
