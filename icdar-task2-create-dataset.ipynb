{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOGURU_LEVEL'] = 'INFO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Get corresponding Loguru level if it exists\n",
    "        try:\n",
    "            level = logger.level(record.levelname).name\n",
    "        except ValueError:\n",
    "            level = record.levelno\n",
    "\n",
    "        # Find caller from where originated the logged message\n",
    "        frame, depth = logging.currentframe(), 2\n",
    "        while frame.f_code.co_filename == logging.__file__:\n",
    "            frame = frame.f_back\n",
    "            depth += 1\n",
    "\n",
    "        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n",
    "\n",
    "logging.basicConfig(handlers=[InterceptHandler()], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train and val data\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_training_18M_without_Finnish')\n",
    "data, md = generate_data(in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_evaluation_4M_without_Finnish')\n",
    "data_test, md_test = generate_data(in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('icdar-dataset-20220207')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(out_dir/'train.csv', index_col=0)\n",
    "X_val = pd.read_csv(out_dir/'val.csv', index_col=0)\n",
    "X_test = pd.read_csv(out_dir/'test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "tokens = []\n",
    "val_files = set(X_val.file_name)\n",
    "\n",
    "# Train and val\n",
    "for key, d in tqdm(data.items()):\n",
    "    for token in d.tokens:\n",
    "        if token.ocr.strip() != token.gs.strip():\n",
    "            r = dataclasses.asdict(token)\n",
    "            r['language'] = key[:2]\n",
    "            r['subset'] = key.split('/')[1]\n",
    "\n",
    "            if key in val_files:\n",
    "                r['dataset'] = 'val'\n",
    "            else:\n",
    "                r['dataset'] = 'train'\n",
    "\n",
    "            tokens.append(r)\n",
    "# Test\n",
    "for key, d in tqdm(data_test.items()):\n",
    "    for token in d.tokens:\n",
    "        if token.ocr.strip() != token.gs.strip():\n",
    "            r = dataclasses.asdict(token)\n",
    "            r['language'] = key[:2]\n",
    "            r['subset'] = key.split('/')[1]\n",
    "            r['dataset'] = 'test'\n",
    "\n",
    "            tokens.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = pd.DataFrame(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('token data:', tdata.shape[0], 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(tdata):\n",
    "    tdata['ocr'] = tdata['ocr'].apply(lambda x: x.strip())\n",
    "    tdata['gs'] = tdata['gs'].apply(lambda x: x.strip())\n",
    "    tdata['len_ocr'] = tdata.apply(lambda row: len(row.ocr), axis=1)\n",
    "    tdata['len_gs'] = tdata.apply(lambda row: len(row.gs), axis=1)\n",
    "    tdata['diff'] = tdata.len_ocr - tdata.len_gs\n",
    "    return tdata\n",
    "\n",
    "tdata = update_data(tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.len_ocr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.len_gs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata['diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.len_ocr.hist(bins=1000, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.len_ocr.hist(bins=1000, figsize=(10,5))\n",
    "plt.ylim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.len_ocr.hist(bins=1000, figsize=(10,5))\n",
    "plt.xlim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sep = '<SEPSEPSEP>'\n",
    "\n",
    "cs = {'train': Counter(), 'val': Counter(), 'test': Counter()}\n",
    "\n",
    "for ocr, gs, ds in tqdm(zip(tdata.ocr.to_list(), \n",
    "                            tdata.gs.to_list(), \n",
    "                            tdata.dataset.to_list()), \n",
    "                            total=tdata.shape[0]):\n",
    "    cs[ds][f'{ocr}{sep}{gs}'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cs['train'].most_common(25):\n",
    "    ocr, gs = k.split(sep)\n",
    "    print(repr(ocr), repr(gs), v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cs['train'].items():\n",
    "    if k.endswith(sep):\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save unique ocr/gs pairs (for train and val)\n",
    "\n",
    "def task2_dataset(c: Counter, sep: str) -> pd.DataFrame:\n",
    "    samples = []\n",
    "    for k, _ in c.items():\n",
    "        ocr, gs = k.split(sep)\n",
    "        samples.append({'ocr': ocr, 'gs': gs})\n",
    "    return pd.DataFrame(samples)\n",
    "\n",
    "train = task2_dataset(cs['train'], sep)\n",
    "val = task2_dataset(cs['val'], sep)\n",
    "test = task2_dataset(cs['test'], sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(out_dir/'task2_train.csv')\n",
    "val.to_csv(out_dir/'task2_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(out_dir/'task2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(out_dir/'task2_train.csv', index_col=0)\n",
    "val = pd.read_csv(out_dir/'task2_val.csv', index_col=0)\n",
    "test = pd.read_csv(out_dir/'task2_test.csv', index_col=0)\n",
    "\n",
    "train = train.fillna('')\n",
    "val = val.fillna('')\n",
    "test = test.fillna('')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
