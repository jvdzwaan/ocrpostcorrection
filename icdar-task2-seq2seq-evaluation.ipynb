{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOGURU_LEVEL'] = 'INFO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad data\n",
    "# Gem. ed tussen src en tgt\n",
    "# Laad model\n",
    "# Doe predictions\n",
    "# Gem. ed tussen src en tgt\n",
    "# Genereer icdar output en doe voorspelling en voeg suggesties in voor alle tokens van max 10 tekens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = Path('icdar-dataset-20220207')\n",
    "\n",
    "train = pd.read_csv(in_dir/'task2_train.csv', index_col=0)\n",
    "val = pd.read_csv(in_dir/'task2_val.csv', index_col=0)\n",
    "test = pd.read_csv(in_dir/'task2_test.csv', index_col=0)\n",
    "\n",
    "train = train.fillna('')\n",
    "val = val.fillna('')\n",
    "test = test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:', train.shape[0], 'samples')\n",
    "print('val:', val.shape[0], 'samples')\n",
    "print('test:', test.shape[0], 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lens(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data['len_ocr'] = data['ocr'].apply(lambda x: len(x))\n",
    "    data['len_gs'] = data['gs'].apply(lambda x: len(x))\n",
    "\n",
    "    return data\n",
    "\n",
    "train = add_lens(train)\n",
    "val = add_lens(val)\n",
    "test = add_lens(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Task2Dataset(Dataset):\n",
    "    def __init__(self, data, max_len=11):\n",
    "        self.ds = data.query(f'len_ocr < {max_len}').query(f'len_gs < {max_len}').copy()\n",
    "        self.ds = self.ds.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.ds.iloc[idx]\n",
    "        return [char for char in sample.ocr], [char for char in sample.gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab_transform = {}\n",
    "\n",
    "def yield_tokens(data, col):\n",
    "    for token in data[col].to_list():\n",
    "        for char in token:\n",
    "            yield char\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for name in ('ocr', 'gs'):\n",
    "    \n",
    "    vocab_transform[name] = build_vocab_from_iterator(yield_tokens(train, name),\n",
    "                                                      min_freq=1,\n",
    "                                                      specials=special_symbols,\n",
    "                                                      special_first=True)\n",
    "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
    "for name in ('ocr', 'gs'):\n",
    "  vocab_transform[name].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for name in ('ocr', 'gs'):\n",
    "    text_transform[name] = sequential_transforms(vocab_transform[name],  # Numericalization (char -> idx)\n",
    "                                                 tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform['ocr'](src_sample))\n",
    "        tgt_batch.append(text_transform['gs'](tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch.to(torch.int64), tgt_batch.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # print('Encoder')\n",
    "        # print('input size', input.size())\n",
    "        # print('hidden size', hidden.size())\n",
    "        embedded = self.embedding(input) \n",
    "        # print('embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "        # print('embedded size met view', embedded.view(1, 1, -1).size())\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # print('embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "        embedded = torch.permute(embedded, (1, 0, 2))\n",
    "        # print('permuted embedded size', embedded.size())\n",
    "        # print(embedded)\n",
    "\n",
    "        # print('hidden size', hidden.size())\n",
    "        # print(hidden)\n",
    "\n",
    "        # print('permuted embedded[0] size', embedded[0].size())\n",
    "        # print('hidden[0] size', hidden[0].size())\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "\n",
    "        # print('attn_weights', attn_weights.size())\n",
    "        # print('attn_weights unsqueeze(1)', attn_weights.unsqueeze(1).size())\n",
    "        # print('encoder outputs', encoder_outputs.size())\n",
    "\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs)\n",
    "\n",
    "        # print('attn_applied', attn_applied.size())\n",
    "        # print('attn_applied squeeze', attn_applied.squeeze().size())\n",
    "        output = torch.cat((embedded[0], attn_applied.squeeze()), 1)\n",
    "        # print('output', output.size())\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # print('output', output.size())\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "\n",
    "        # print(f'output: {output.size()}; hidden: {hidden.size()}; attn_weigts: {attn_weights.size()}')\n",
    "\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICDARTask2Seq2seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, max_length):\n",
    "        super(ICDARTask2Seq2seq, self).__init__()\n",
    "\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size)\n",
    "        self.decoder = AttnDecoderRNN(hidden_size, output_size, \n",
    "                                      dropout_p=dropout, max_length=max_length)\n",
    "    \n",
    "    def forward(self, input, encoder_hidden, target, max_length):\n",
    "        # input is src seq len x batch size\n",
    "        # input voor de encoder (1 stap) moet zijn input seq len x batch size x 1\n",
    "        input_tensor = input.unsqueeze(2)\n",
    "        # print('input tensor size', input_tensor.size())\n",
    "\n",
    "        input_length = input.size(0)\n",
    "\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        # Encoder part\n",
    "        encoder_outputs = torch.zeros(batch_size, max_length, self.encoder.hidden_size, \n",
    "                                      device=device)\n",
    "        # print('encoder outputs size', encoder_outputs.size())\n",
    "    \n",
    "        for ei in range(input_length):\n",
    "            # print(f'Index {ei}; input size: {input_tensor[ei].size()}; encoder hidden size: {encoder_hidden.size()}')\n",
    "            encoder_output, encoder_hidden = self.encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            # print('Index', ei)\n",
    "            # print('encoder output size', encoder_output.size())\n",
    "            # print('encoder outputs size', encoder_outputs.size())\n",
    "            # print('output selection size', encoder_output[:, 0].size())\n",
    "            # print('ouput to save', encoder_outputs[:,ei].size())\n",
    "            encoder_outputs[:, ei] = encoder_output[0, 0]\n",
    "        \n",
    "        # print('encoder outputs', encoder_outputs)\n",
    "        # print('encoder hidden', encoder_hidden)\n",
    "\n",
    "        # Decoder part\n",
    "        # Target = seq len x batch size\n",
    "        # Decoder input moet zijn: batch_size x 1 (van het eerste token = BOS)\n",
    "        target_length = target.size(0)\n",
    "\n",
    "        decoder_input = torch.tensor([[BOS_IDX] for _ in range(batch_size)], device=device)\n",
    "        # print('decoder input size', decoder_input.size())\n",
    "\n",
    "        decoder_outputs = torch.zeros(batch_size, max_length, self.decoder.output_size, \n",
    "                                      device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()  # detach from history as input\n",
    "\n",
    "            # print(f'Index {di}; decoder output size: {decoder_output.size()}; decoder input size: {decoder_input.size()}')\n",
    "            decoder_outputs[:, di] = decoder_output\n",
    "\n",
    "        # Zero out probabilities for padded chars\n",
    "        target_masks = (target != PAD_IDX).float()\n",
    "\n",
    "        # Compute log probability of generating true target words\n",
    "        # print('P (decoder_outputs)', decoder_outputs.size())\n",
    "        # print(target.transpose(0, 1))\n",
    "        # print('Index', target.size(), target.transpose(0, 1).unsqueeze(-1))\n",
    "        target_gold_std_log_prob = torch.gather(decoder_outputs, index=target.transpose(0, 1).unsqueeze(-1), dim=-1).squeeze(-1) * target_masks.transpose(0, 1)\n",
    "        #print(target_gold_std_log_prob)\n",
    "        scores = target_gold_std_log_prob.sum(dim=1)\n",
    "\n",
    "        #print(scores)\n",
    "\n",
    "        return scores, decoder_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import edlib\n",
    "\n",
    "def calculate_ed(src_strings, tgt_strings):\n",
    "    dist = []\n",
    "\n",
    "    for src, tgt in zip(src_strings, tgt_strings):\n",
    "        #print(repr(src), repr(tgt))\n",
    "        ed = edlib.align(src, tgt)\n",
    "        dist.append(ed['editDistance'])\n",
    "\n",
    "    return np.mean(dist), np.std(dist)\n",
    "\n",
    "\n",
    "def indices2string(indices, itos):\n",
    "    output = []\n",
    "    for idxs in indices:\n",
    "        #print(idxs)\n",
    "        string = []\n",
    "        for idx in idxs:\n",
    "            if idx not in (UNK_IDX, PAD_IDX, BOS_IDX):\n",
    "                if idx == EOS_IDX:\n",
    "                    break\n",
    "                else:\n",
    "                    string.append(itos[idx])\n",
    "        word = ''.join(string)\n",
    "        output.append(word)\n",
    "    return output\n",
    "\n",
    "\n",
    "def ed_predicted_strings(model, dataloader, tgt_vocab, tgt_strings, DEVICE):\n",
    "    itos = tgt_vocab.get_itos()\n",
    "    output_strings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            tgt = tgt.to(DEVICE)\n",
    "            \n",
    "            batch_size = src.size(1)\n",
    "\n",
    "            encoder_hidden = model.encoder.initHidden(batch_size=batch_size)\n",
    "\n",
    "            example_losses, decoder_ouputs = model(src, encoder_hidden, tgt, MAX_LENGTH)\n",
    "            example_losses = -example_losses\n",
    "            batch_loss = example_losses.sum()\n",
    "            # Generate string outputs\n",
    "            output_idxs = decoder_ouputs.argmax(-1)\n",
    "            #print(output_idxs.size())\n",
    "            #print(output_idxs)\n",
    "\n",
    "            strings_batch = indices2string(output_idxs, itos)\n",
    "            for s in strings_batch:\n",
    "                output_strings.append(s)\n",
    "\n",
    "    m, std = calculate_ed(output_strings, tgt_strings)\n",
    "\n",
    "    return m, std, output_strings\n",
    "\n",
    "\n",
    "def get_gold_tgt_words(dataset):\n",
    "    src_strings = []\n",
    "    tgt_strings = []\n",
    "\n",
    "    for src, tgt in dataset:\n",
    "        src_strings.append(''.join(src))\n",
    "        tgt_strings.append(''.join(tgt))\n",
    "    return src_strings, tgt_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 11\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "dataset = Task2Dataset(val)\n",
    "src_strings, tgt_strings = get_gold_tgt_words(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, std = calculate_ed(src_strings, tgt_strings)\n",
    "print(f'src -> tgt: m ed {m}, std {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_calculate_ed(model, dataloader, tgt_vocab, tgt_strings, MAX_LENGTH, DEVICE):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    itos = tgt_vocab.get_itos()\n",
    "    output_strings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            tgt = tgt.to(DEVICE)\n",
    "            \n",
    "            batch_size = src.size(1)\n",
    "\n",
    "            encoder_hidden = model.encoder.initHidden(batch_size=batch_size)\n",
    "\n",
    "            example_losses, decoder_ouputs = model(src, encoder_hidden, tgt, MAX_LENGTH)\n",
    "\n",
    "            # Generate string outputs\n",
    "            output_idxs = decoder_ouputs.argmax(-1)\n",
    "            #print(output_idxs.size())\n",
    "            #print(output_idxs)\n",
    "\n",
    "            strings_batch = indices2string(output_idxs, itos)\n",
    "            for s in strings_batch:\n",
    "                output_strings.append(s)\n",
    "\n",
    "            m, std = calculate_ed(output_strings, tgt_strings)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return m, std, output_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "PATH = '/Users/janneke/Google Drive/model.pt'\n",
    "\n",
    "model = ICDARTask2Seq2seq(len(vocab_transform['ocr']), hidden_size, len(vocab_transform['gs']), 0.1, MAX_LENGTH)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "m, ed, pred_strings = predict_and_calculate_ed(model, dataloader, vocab_transform['gs'], tgt_strings, MAX_LENGTH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, std = calculate_ed(pred_strings, tgt_strings)\n",
    "print(f'pred -> tgt: m ed {m}, std {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in random.choices(range(len(src_strings)), k=5):\n",
    "    print(f'> {src_strings[i]}\\n= {tgt_strings[i]}\\n< {pred_strings[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, dataloader, MAX_LENGTH, DEVICE):\n",
    "    cum_loss = 0\n",
    "    cum_examples = 0\n",
    "\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            tgt = tgt.to(DEVICE)\n",
    "            \n",
    "            batch_size = src.size(1)\n",
    "\n",
    "            encoder_hidden = model.encoder.initHidden(batch_size=batch_size)\n",
    "\n",
    "            example_losses, decoder_ouputs = model(src, encoder_hidden, tgt, MAX_LENGTH)\n",
    "            example_losses = -example_losses\n",
    "            batch_loss = example_losses.sum()\n",
    "\n",
    "            bl = batch_loss.item()\n",
    "            cum_loss += bl\n",
    "            cum_examples += batch_size\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    return cum_loss/cum_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(model, dataloader, MAX_LENGTH, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create icdar results\n",
    "\n",
    "* Create icdar results data structure with all strings that need to be corrected\n",
    "* The corrections will be added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import generate_data\n",
    "\n",
    "in_dir = Path('../../data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_evaluation_4M_without_Finnish')\n",
    "data_test, X_test = generate_data(in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "to_predict = defaultdict(list)\n",
    "result = {}\n",
    "\n",
    "for key, text in data_test.items():\n",
    "    print(key, len(text.tokens))\n",
    "    result[key] = {}\n",
    "    for token in text.tokens:\n",
    "        if token.ocr != token.gs:\n",
    "            num_tokens = len(token.ocr.strip().split(' '))\n",
    "            token_key = f'{token.start}:{num_tokens}'\n",
    "            result[key][token_key] = {}\n",
    "            to_predict[token.ocr.strip()].append({'text': key, 'token_key': token_key})\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_strings = ['Zha I']\n",
    "pred_strings = ['Zha']\n",
    "\n",
    "for ocr, pred in zip(ocr_strings, pred_strings):\n",
    "    for position in to_predict[ocr]:\n",
    "        result[position['text']][position['token_key']][pred] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
