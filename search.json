[
  {
    "objectID": "error_correction_t5.html",
    "href": "error_correction_t5.html",
    "title": "Error correction using T5",
    "section": "",
    "text": "import os\nfrom pathlib import Path\n\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer\n\nfrom ocrpostcorrection.error_correction import get_tokens_with_OCR_mistakes, get_context_for_dataset\nfrom ocrpostcorrection.icdar_data import generate_data\n\n/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n\n\n\n\nfilter_len_ocr_mistake_in_context\n\n filter_len_ocr_mistake_in_context (data:pandas.core.frame.DataFrame,\n                                    context_offset:int)\n\n\ncontext_offset=5\n\ndata_context = filter_len_ocr_mistake_in_context(tdata, context_offset=context_offset)\n\nassert tdata.len_mistake_in_context.max() &gt; 10*context_offset\nassert data_context.len_mistake_in_context.max() &lt;= 10*context_offset\n\n2024-08-10 22:09:57.075 | INFO     | __main__:filter_len_ocr_mistake_in_context:7 - Max length of input samples: 50\n\n\n\ndataset = DatasetDict(\n        {\n            \"train\": Dataset.from_pandas(tdata.query('dataset == \"train\"')),\n            \"val\": Dataset.from_pandas(tdata.query('dataset == \"val\"')),\n            \"test\": Dataset.from_pandas(tdata.query('dataset == \"test\"')),\n        }\n    )\ndataset['train'][1]\n\n{'ocr': 'troe',\n 'gs': 'tree',\n 'ocr_aligned': 'troe',\n 'gs_aligned': 'tree',\n 'start': 13,\n 'len_ocr': 4,\n 'key': 'en/eng_sample/1.txt',\n 'language': 'en',\n 'subset': 'eng_sample',\n 'dataset': 'train',\n 'len_gs': 4,\n 'diff': 0,\n 'context_before': 'In botany, a ',\n 'context_after': ' is a peremial plant',\n 'len_mistake_in_context': 37,\n '__index_level_0__': 14}\n\n\n\n\n\nfilter_max_len\n\n filter_max_len (example:Dict, max_len:int)\n\n\nmax_len = 5\ndataset_max_len = dataset.filter(\n        filter_max_len, fn_kwargs={\"max_len\": max_len}, batched=False\n    )\n\nfor subset, expected in {'train': 9, 'val': 2, 'test': 11}.items():\n    assert len(dataset_max_len[subset]) == expected, f\"Expected len of {expected} for '{subset}', got {len(dataset_max_len[subset])}\"\n\n\n\n\n\n\n\n\n\n\n\nmodel_name = \"google/byt5-small\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n\n\n\npreprocess_function\n\n preprocess_function (examples, tokenizer, add_task_prefix:bool=False,\n                      context_marker:str='')\n\n\ntokenized_dataset = dataset.map(\n    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer}, batched=True\n)\n\n\n\n\n\n\n\n\n\n\n\ntokenizer.decode(tokenized_dataset['train'][1]['input_ids'])\n\n'troe&lt;/s&gt;'\n\n\n\ntokenized_dataset = dataset.map(\n    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer, \"add_task_prefix\": True}, batched=True\n)\n\n\n\n\n\n\n\n\n\n\n\ntokenizer.decode(tokenized_dataset['train'][1]['input_ids'])\n\n'en: troe&lt;/s&gt;'\n\n\n\ntokenized_dataset = dataset.map(\n    preprocess_function, fn_kwargs={\"tokenizer\": tokenizer, \"add_task_prefix\": True, \"context_marker\": \"mistake\"}, batched=True\n)\n\n\n\n\n\n\n\n\n\n\n\ntokenizer.decode(tokenized_dataset['train'][1]['input_ids'])\n\n'en: In botany, a &lt;mistake&gt;troe&lt;/mistake&gt; is a peremial plant&lt;/s&gt;'",
    "crumbs": [
      "Error correction using T5"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ocrpostcorrection",
    "section": "",
    "text": "In 2017 and 2019 a competion on Post-OCR Text Correction was organized. This repository contains my efforts in reproducing the best results and possibly improving them.",
    "crumbs": [
      "ocrpostcorrection"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "ocrpostcorrection",
    "section": "Install",
    "text": "Install\ngit clone https://github.com/jvdzwaan/ocrpostcorrection.git\ncd ocrpostcorrection\npip install -e .",
    "crumbs": [
      "ocrpostcorrection"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "ocrpostcorrection",
    "section": "How to use",
    "text": "How to use\nSee the ocrpostcorrection-notebooks repository and my blog for usage examples.",
    "crumbs": [
      "ocrpostcorrection"
    ]
  },
  {
    "objectID": "simple_correction_data.html",
    "href": "simple_correction_data.html",
    "title": "Simple Correction Data",
    "section": "",
    "text": "set_seed(23)\ndata_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\ndata, md = generate_data(data_dir)\nval_files = [\"en/eng_sample/2.txt\"]\n\ntoken_data = get_tokens_with_OCR_mistakes(data, data, val_files)\nvocab_transform = generate_vocabs(token_data.query('dataset == \"train\"'))\n\n2it [00:00, 798.15it/s]",
    "crumbs": [
      "Simple Correction Data"
    ]
  },
  {
    "objectID": "simple_correction_data.html#training",
    "href": "simple_correction_data.html#training",
    "title": "Simple Correction Data",
    "section": "Training",
    "text": "Training\n\n\nvalidate_model\n\n validate_model (model, dataloader, device)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 2\nhidden_size = 5\ndropout = 0.1\nmax_token_len = 10\n\nmodel = SimpleCorrectionSeq2seq(\n    len(vocab_transform[\"ocr\"]),\n    hidden_size,\n    len(vocab_transform[\"gs\"]),\n    dropout,\n    max_token_len,\n    teacher_forcing_ratio=0.5,\n    device=device,\n)\n\nencoder_hidden = model.encoder.initHidden(batch_size=batch_size, device=device)\n\n\nval = SimpleCorrectionDataset(token_data.query('dataset == \"val\"'), max_len=10)\nval_dataloader = DataLoader(val, batch_size=5, collate_fn=collate_fn(text_transform))\n\nloss = validate_model(model, val_dataloader, device)\nloss\n\n25.545663621690537\n\n\n\n\n\ntrain_model\n\n train_model (train_dl, val_dl, model=None, optimizer=None, num_epochs=5,\n              valid_niter=5000, model_save_path='model.rar',\n              max_num_patience=5, max_num_trial=5, lr_decay=0.5,\n              device='cpu')\n\n\ntrain = SimpleCorrectionDataset(token_data.query('dataset == \"train\"'), max_len=10)\ntrain_dataloader = DataLoader(\n    train, batch_size=2, collate_fn=collate_fn(text_transform), shuffle=True\n)\n\nval = SimpleCorrectionDataset(token_data.query('dataset == \"val\"'), max_len=10)\nval_dataloader = DataLoader(val, batch_size=3, collate_fn=collate_fn(text_transform))\n\nhidden_size = 5\nmodel = SimpleCorrectionSeq2seq(\n    len(vocab_transform[\"ocr\"]),\n    hidden_size,\n    len(vocab_transform[\"gs\"]),\n    0.1,\n    10,\n    teacher_forcing_ratio=0.0,\n)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters())\n\nmsp = Path(os.getcwd()) / \"data\" / \"model.rar\"\n\ntrain_model(\n    train_dl=train_dataloader,\n    val_dl=val_dataloader,\n    model=model,\n    optimizer=optimizer,\n    model_save_path=msp,\n    num_epochs=2,\n    valid_niter=5,\n    max_num_patience=5,\n    max_num_trial=5,\n    lr_decay=0.5,\n)\n\nEpoch 1, iter 5, avg. train loss 25.21373109817505, avg. val loss 25.264954460991753\nSaving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\nEpoch 1, iter 10, avg. train loss 27.308312225341798, avg. val loss 25.19587156507704\nSaving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\nEpoch 2, iter 15, avg. train loss 25.64889602661133, avg. val loss 25.134972466362846\nSaving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\nEpoch 2, iter 20, avg. train loss 26.240159034729004, avg. val loss 25.078634050157333\nSaving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar\nEpoch 2, iter 25, avg. train loss 22.31423110961914, avg. val loss 25.014130486382378\nSaving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model.rar",
    "crumbs": [
      "Simple Correction Data"
    ]
  },
  {
    "objectID": "simple_correction_data.html#inference-prediction",
    "href": "simple_correction_data.html#inference-prediction",
    "title": "Simple Correction Data",
    "section": "Inference / prediction",
    "text": "Inference / prediction\nhttps://pytorch.org/tutorials/beginner/chatbot_tutorial.html?highlight=greedy%20decoding\n\n\nGreedySearchDecoder\n\n GreedySearchDecoder (model)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\ndecoder = GreedySearchDecoder(model)\n\nmax_len = 10\n\ntest = SimpleCorrectionDataset(token_data.query('dataset == \"test\"'), max_len=max_len)\ntest_dataloader = DataLoader(test, batch_size=5, collate_fn=collate_fn(text_transform))\n\nwith torch.no_grad():\n    for i, (src, tgt) in enumerate(test_dataloader):\n        predicted_indices = decoder(src, tgt)\n        if i == 0:\n            print(predicted_indices)\n        else:\n            print(predicted_indices.size())\n\ntorch.Size([1, 5, 5])\ntensor([[27, 27, 27, 17,  7, 17,  7,  7, 17, 27,  0],\n        [18, 27, 27, 27, 27, 27, 17, 17, 27, 17,  0],\n        [18,  3, 18, 27, 17, 26, 27, 27, 27, 27,  0],\n        [18, 26, 27, 18, 27, 27, 27, 27, 27, 27,  0],\n        [ 6, 27, 27, 27, 27, 17, 17,  7, 17,  7,  0]])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\ntorch.Size([1, 5, 5])\ntorch.Size([5, 11])\n\n\n\n\n\npredict_and_convert_to_str\n\n predict_and_convert_to_str (model, dataloader, tgt_vocab, device)\n\n\noutput_strings = predict_and_convert_to_str(\n    model, test_dataloader, vocab_transform[\"gs\"], device\n)\noutput_strings[0:3]\n\n100%|██████████| 7/7 [00:00&lt;00:00, 352.93it/s]\n\n\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\n\n\n\n\n\n['mmmmmmmmmm', 'Fmmmmmmmmm', 'Fmmmmmmmmm']\n\n\n\nmax_len = 10\ntest_data = (\n    token_data.query('dataset == \"test\"')\n    .query(f\"len_ocr &lt;= {max_len}\")\n    .query(f\"len_gs &lt;= {max_len}\")\n    .copy()\n)\n\ntest_data[\"pred\"] = output_strings",
    "crumbs": [
      "Simple Correction Data"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Results",
    "section": "",
    "text": "Results for the 2019 ICDAR competition on Post-OCR Text correction can be found in this paper. The best results are repeated in the tables below.",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "results.html#task-1-token-classification",
    "href": "results.html#task-1-token-classification",
    "title": "Results",
    "section": "Task 1: Token Classification",
    "text": "Task 1: Token Classification\n\nSummarized results (F-measure)\nBest results in bold.\n\n\n\nMethod\nBG\nCZ\nDE\nEN\nES\nFI\nFR\nNL\nPL\nSL\n\n\n\n\nCCC (2019 competition winner)\n0.77\n0.70\n0.95\n0.67\n0.69\n0.84\n0.67\n0.71\n0.82\n0.69\n\n\nExperiment 1\n0.74\n0.64\n0.93\n0.62\n0.59\n0.82\n0.59\n0.66\n0.77\n0.63\n\n\nExperiment 2 (long sequences)\n0.74\n0.69\n0.96\n0.67\n0.63\n0.83\n0.65\n0.69\n0.8\n0.69\n\n\nExperiment 1 reproduced with DVC\n0.75\n0.68\n0.96\n0.66\n0.64\n0.83\n0.69\n0.69\n0.81\n0.67\n\n\nExperiment 1 reproduced with DVC - evaluation with old eval script\n0.75\n0.68\n0.96\n0.66\n0.64\n0.83\n0.66\n0.69\n0.81\n0.67\n\n\nExperiment 1 reproduced with DVC - stratified on subset\n0.75\n0.69\n0.96\n0.67\n0.63\n0.83\n0.69\n0.69\n0.81\n0.68\n\n\nExperiment 1 (code refactor, training batch size 32)\n0.74\n0.68\n0.96\n0.66\n0.63\n0.83\n0.67\n0.69\n0.80\n0.68\n\n\nExperiment 1 (code refactor, training batch size 16)\n0.75\n0.69\n0.96\n0.67\n0.63\n0.83\n0.69\n0.69\n0.81\n0.68\n\n\n\n\n\nExperiment 1: token classification with Huggingface BERT 07-02-2022\n\nValidation set: 10% of texts (stratified on language)\nDataset 07-02-2022\n\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) lenght: 35, step: 30 (overlap of 5 tokens)\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.253900\nVal: 0.290570\nTest:\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.875714\n0.665102\n0.73898\n\n\nCZ\n0.81\n0.548696\n0.635217\n\n\nDE\n0.975809\n0.88539\n0.927579\n\n\nEN\n0.850833\n0.535625\n0.623125\n\n\nES\n0.9068\n0.464\n0.591\n\n\nFI\n0.895\n0.770125\n0.8235\n\n\nFR\n0.806301\n0.48875\n0.592939\n\n\nNL\n0.870816\n0.596939\n0.662449\n\n\nPL\n0.8894\n0.6982\n0.7738\n\n\nSL\n0.805\n0.575833\n0.63875\n\n\n\n\n\nExperiment 2: token classification with Huggingface BERT long sequences\n\nValidation set: 10% of texts (stratified on language)\nDataset 07-02-2022\n\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) lenght: 150, step: 150\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.224500\nVal: 0.285791\nTest: 0.4178357720375061\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.85\n0.693673\n0.744286\n\n\nCZ\n0.808043\n0.623261\n0.685652\n\n\nDE\n0.971874\n0.954152\n0.962806\n\n\nEN\n0.823333\n0.618125\n0.668333\n\n\nES\n0.8722\n0.52\n0.6254\n\n\nFI\n0.896625\n0.785625\n0.833375\n\n\nFR\n0.797703\n0.571588\n0.651368\n\n\nNL\n0.875102\n0.634286\n0.690204\n\n\nPL\n0.8872\n0.7466\n0.8026\n\n\nSL\n0.806667\n0.653333\n0.692917\n\n\n\n\nRemarks\nFor some texts the sequences of length 150 have to be truncated to fit into the 512 input tokens for BERT. Consequently, we are missing predictions for these truncated tokens. Maybe it is a good idea to decrease the ‘step’ size, so we’ll have predictions for every token. However, this would also mean that we’ll have more repetition in the training set. This might impact the results in a negative way.\n\n\n\nExperiment 1 reproduced with DVC\n\nocrpostcorrection-notebooks commit: 430d228\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) length: size: 35, step: 30\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.2398\nVal: 0.2871749699115753\nTest: 0.4474944472312927\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.85\n0.71\n0.75\n\n\nCZ\n0.82\n0.6\n0.68\n\n\nDE\n0.97\n0.96\n0.96\n\n\nEN\n0.81\n0.6\n0.66\n\n\nES\n0.87\n0.54\n0.64\n\n\nFI\n0.91\n0.78\n0.83\n\n\nFR\n0.8\n0.63\n0.69\n\n\nNL\n0.86\n0.63\n0.69\n\n\nPL\n0.89\n0.75\n0.81\n\n\nSL\n0.81\n0.62\n0.67\n\n\n\n\n\nExperiment 1 reproduced with DVC, stratified on subset\n\nocrpostcorrection-notebooks commit: 6231bca\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) length: size: 35, step: 30\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.2439\nVal: 0.2839458584785461\nTest: 0.4422231018543243\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.86\n0.7\n0.75\n\n\nCZ\n0.85\n0.6\n0.69\n\n\nDE\n0.97\n0.95\n0.96\n\n\nEN\n0.82\n0.61\n0.67\n\n\nES\n0.89\n0.53\n0.63\n\n\nFI\n0.89\n0.79\n0.83\n\n\nFR\n0.81\n0.62\n0.69\n\n\nNL\n0.87\n0.64\n0.69\n\n\nPL\n0.89\n0.75\n0.81\n\n\nSL\n0.81\n0.64\n0.68\n\n\n\n\n\nExperiment 1 with training batch size 32 (2023-07-28)\n\nocrpostcorrection-notebooks commit: 8f7329e\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) length: size: 35, step: 30\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.2625\nVal: 0.2949527204036712\nTest: 0.4553228318691253\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.86\n0.69\n0.74\n\n\nCZ\n0.85\n0.59\n0.68\n\n\nDE\n0.97\n0.95\n0.96\n\n\nEN\n0.83\n0.59\n0.66\n\n\nES\n0.88\n0.53\n0.63\n\n\nFI\n0.89\n0.79\n0.83\n\n\nFR\n0.8\n0.61\n0.67\n\n\nNL\n0.86\n0.64\n0.69\n\n\nPL\n0.89\n0.75\n0.8\n\n\nSL\n0.82\n0.63\n0.68\n\n\n\n\nRemarks\nTraining batch size was set to 32 (instead of 16). Trained on Google Colab T4 High RAM.\n\n\n\nExperiment 1 with training batch size 16 (2023-07-28)\n\nocrpostcorrection-notebooks commit: 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nNormalized editdistance threshold for ‘sentences’: 0.3 (only for train and val)\nSequence (sentence) length: size: 35, step: 30\n\nPretrained model: bert-base-multilingual-cased\nLoss\n\nTrain: 0.2439\nVal: 0.2839458584785461\nTest: 0.4422231018543243\n\n\n\n\n\nlanguage\nT1_Precision\nT1_Recall\nT1_Fmesure\n\n\n\n\nBG\n0.86\n0.7\n0.75\n\n\nCZ\n0.85\n0.6\n0.69\n\n\nDE\n0.97\n0.95\n0.96\n\n\nEN\n0.82\n0.61\n0.67\n\n\nES\n0.89\n0.53\n0.63\n\n\nFI\n0.89\n0.79\n0.83\n\n\nFR\n0.81\n0.62\n0.69\n\n\nNL\n0.87\n0.64\n0.69\n\n\nPL\n0.89\n0.75\n0.81\n\n\nSL\n0.81\n0.64\n0.68\n\n\n\n\nRemarks\nTraining batch size was set to 16 again. Trained on Google Colab T4 High RAM.\nResults are back to what they were for Experiment 1 reproduced with DVC - stratified on subset (as expected). It seems that batch size has a small impact on performance.",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "results.html#task-2-error-correction",
    "href": "results.html#task-2-error-correction",
    "title": "Results",
    "section": "Task 2: Error Correction",
    "text": "Task 2: Error Correction\n\nTask 1 Perfect\nSummarized results (average % of improvement in edit distance between original and corrected). The input is the ‘perfect’ results for error detection.\n\n\n\nMethod\nBG\nCZ\nDE\nEN\nES\nFI\nFR\nNL\nPL\nSL\n\n\n\n\nCCC (2019 competition winner)\nn/a\nn/a\nn/a\nn/a\nn/a\nn/a\nn/a\nn/a\nn/a\nn/a\n\n\nExperiment 1\n-38\n-64\n47\n-13\n-1\n14\n-8\n-4\n-14\n-34\n\n\nExperiment 1 reproduced with DVC\n14\n-64\n21\n-2\n17\n15\nnan\n8\n-5\n-25\n\n\nBaseline 2 (hidden size 768)\n17\n-67\n25\n-4\n17\n21\n-3\n10\n-7\n-32\n\n\nbyt5-small experiment 1\n16\n-18\n56\n2\n7\n38\n11\n6\n9\n-14\n\n\nbyt5-small experiment 2\n21\n-14\n65\n2\n10\n42\n13\n14\n17\n-8\n\n\nbyt5-small experiment 3\n25\n8\n66\n17\n19\n48\n10\n24\n27\n18\n\n\nbyt5-small experiment 4\n23\n10\n72\n18\n22\n50\n25\n28\n28\n15\n\n\nbyt5-small experiment 5\n22\n1\n72\n12\n23\n49\n24\n27\n28\n14\n\n\n\n\n\nTask 1 Results\nSummarized results (average % of improvement in edit distance between original and corrected). The input is the errors detected by a model. The experiment notes specify which error detection model was used.\n\n\n\nMethod\nBG\nCZ\nDE\nEN\nES\nFI\nFR\nNL\nPL\nSL\n\n\n\n\nCCC (2019 competition winner)\n9\n6\n24\n11\n11\n8\n5\n12\n17\n14\n\n\nExperiment 1 reproduced with DVC\n-5\n-45\n25\n-16\n-6\n12\n-13\n-9\n-15\n-37\n\n\nBaseline 2 (hidden size 768)\n-4\n-48\n28\n-20\n-7\n18\n-13\n-7\n-15\n-47\n\n\nbyt5-small experiment 1\n10\n-21\n52\n-9\n1\n34\n2\n-0\n5\n-24\n\n\nbyt5-small experiment 2\n13\n-15\n59\n-7\n3\n37\n1\n6\n11\n-19\n\n\nbyt5-small experiment 3\n16\n-4\n60\n-7\n10\n42\n-2\n15\n19\n11\n\n\nbyt5-small experiment 4\n14\n-2\n65\n-4\n11\n43\n7\n17\n21\n1\n\n\nbyt5-small experiment 5\n13\n-21\n65\n-5\n12\n42\n7\n18\n22\n2\n\n\n\n\n\nError Correction Experiment Notes\n\nCorrection experiment 1 reproduced with DVC (2023-07-29)\n\nocrpostcorrection-notebooks commit: dc2af99\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: SimpleCorrectionSeq2seq\nDecoder: GreedySearchDecoder\nLoss\n\nTrain: 8.595188051536567\nVal: 9.212168355464936\nTest: 9.366749288250466\n\n\nTrained on Google Colab T4 High RAM.\n\n\nCorrection experiment baseline 2 (2023-08-05)\n\nocrpostcorrection-notebooks commit: 45fa416\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: SimpleCorrectionSeq2seq\nDecoder: GreedySearchDecoder\nLoss (Updated run from commit 765a7df)\n\nTrain: 7.310251626014709\nVal: 7.631718857658534\nTest: 8.613492756178495 (Updated run from commit 3955d38)\n\n\nSet hidden size to 768 to create baseline for an experiment with BERT hidden vectors as additional input.\nTrained on Google Colab T4 High RAM.\nResults in table have been recalculated after the problem with nan and -inf for two French texts had been fixed. The results are tracked in DVC in commit 765a7df.\n\n\nExperiment byt5-small 1 (2024-03-01)\n\nocrpostcorrection-notebooks commit: b677b6b\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: byt5-small\n\nNumber of epochs: 1\nOptimizer: AdamW (default)\n\nLoss\n\nTrain: 0.6192\nVal: 0.4882390201091766\nTest: 0.5294567942619324\n\n\nTrained on Google Colab T4.\n\n\nExperiment byt5-small 2: AdaFactor optimizer (2024-03-08)\n\nocrpostcorrection-notebooks commit: 7665d86\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: byt5-small\n\nNumber of epochs: 1\nOptimizer: AdaFactor\n\nLoss\n\nTrain: 0.4592\nVal: 0.3836239278316498\nTest: 0.4266203045845032\n\n\nTrained on Google Colab T4.\n\n\nExperiment byt5-small 3: language as task prefix (2024-03-17)\n\nocrpostcorrection-notebooks commit: 855b2cf\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: google/byt5-small\n\nNumber of epochs: 1\nOptimizer: AdaFactor\n\nLoss\n\nTrain: 0.4285\nVal: 0.356132298707962\nTest: 0.3938777148723602\n\n\nTrained on Google Colab T4.\n\n\nExperiment byt5-small 4: marked errors in context without task prefix (2024-07-27)\n\nocrpostcorrection-notebooks commit: 2fb58d4\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: google/byt5-small\n\nNumber of epochs: 1\nOptimizer: Adafactor\n\nLoss\n\nTrain: 0.2885\nVal: 0.2521135210990906\nTest: 0.2787809669971466\n\n\nTrained on Google Colab A100.\nOcrpostcorrection version used: e2176bb. This is the commit before the filter_len_ocr_mistake_in_context was added, so filtering on input length did not happen. (There was a bug in this function.) It probably worked, because the A100 GPU has much more memory than the V100 that I used for the previous attempt of this experiment.\n\n\n\nExperiment byt5-small 5: marked errors in context with language as task prefix (2024-10-06)\n\nocrpostcorrection-notebooks commit: f12e734\nDetection model from experiment 9099e78\nDataset\n\nSplit seed: 8232\nValidation set: 10.0%\nMax token length: 22\n\nModel: google/byt5-small\n\nNumber of epochs: 1\n\nLoss\n\nTrain: 0.2877\nVal: 0.2515017390251159\nTest: 0.277634710073471\n\n\nTrained on Google Colab A100.",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "error_detection.html",
    "href": "error_detection.html",
    "title": "Token Classification",
    "section": "",
    "text": "tokenize_and_align_labels_with_tokenizer (tokenizer, examples,\n                                           return_tensors=None)\n\nTokenize function, to be used as partial with instatiated tokenizer\n\n\n\n\n\n tokenize_and_align_labels (tokenizer, return_tensors=None)\n\nFunction to tokenize samples and align the labels",
    "crumbs": [
      "Token Classification"
    ]
  },
  {
    "objectID": "error_detection.html#tokenization",
    "href": "error_detection.html#tokenization",
    "title": "Token Classification",
    "section": "",
    "text": "tokenize_and_align_labels_with_tokenizer (tokenizer, examples,\n                                           return_tensors=None)\n\nTokenize function, to be used as partial with instatiated tokenizer\n\n\n\n\n\n tokenize_and_align_labels (tokenizer, return_tensors=None)\n\nFunction to tokenize samples and align the labels",
    "crumbs": [
      "Token Classification"
    ]
  },
  {
    "objectID": "bert_vectors_correction_dataset.html",
    "href": "bert_vectors_correction_dataset.html",
    "title": "BERT Vectors Correction Data",
    "section": "",
    "text": "set_seed(23)",
    "crumbs": [
      "BERT Vectors Correction Data"
    ]
  },
  {
    "objectID": "bert_vectors_correction_dataset.html#training",
    "href": "bert_vectors_correction_dataset.html#training",
    "title": "BERT Vectors Correction Data",
    "section": "Training",
    "text": "Training\n\n\nvalidate_model\n\n validate_model (model, dataloader, device)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 2\nhidden_size = 768\ndropout = 0.1\nmax_token_len = 10\n\nmodel = SimpleCorrectionSeq2seq(\n    len(vocab_transform[\"ocr\"]),\n    hidden_size,\n    len(vocab_transform[\"gs\"]),\n    dropout,\n    max_token_len,\n    teacher_forcing_ratio=0.5,\n    device=device,\n)\nmodel.to(device)\n\nSimpleCorrectionSeq2seq(\n  (encoder): EncoderRNN(\n    (embedding): Embedding(46, 768)\n    (gru): GRU(768, 768, batch_first=True)\n  )\n  (decoder): AttnDecoderRNN(\n    (embedding): Embedding(44, 768)\n    (attn): Linear(in_features=1536, out_features=11, bias=True)\n    (attn_combine): Linear(in_features=1536, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (gru): GRU(768, 768)\n    (out): Linear(in_features=768, out_features=44, bias=True)\n  )\n)\n\n\n\nsplit_name = \"val\"\ndata_csv = Path(os.getcwd()) / \"data\" / \"correction\" / \"dataset.csv\"\ndata = pd.read_csv(data_csv, index_col=0)\ndata.fillna(\"\", inplace=True)\nbert_vectors_file = Path(os.getcwd()) / \"data\" / \"correction\" / \"bert-vectors.hdf5\"\n\nval = BertVectorsCorrectionDataset(\n    data=data.query(f\"dataset == '{split_name}'\"),\n    bert_vectors_file=bert_vectors_file,\n    split_name=split_name,\n    max_len=11,\n    hidden_size=768,\n    look_up_bert_vectors=True\n)\nval_dataloader = DataLoader(val, batch_size=5, collate_fn=collate_fn(text_transform))\n\nloss = validate_model(model, val_dataloader, device)\nloss\n\n24.875640021430122\n\n\n\ndata\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nlanguage\nsubset\ndataset\nlen_gs\ndiff\n\n\n\n\n0\ntest- AAA\ntest-.AAA\ntest- AAA\ntest-.AAA\n0\n9\nfr\nfr_sample\ntrain\n9\n0\n\n\n1\ntest-BBB\ntest- BBB\ntest@-BBB\ntest- BBB\n10\n8\nfr\nfr_sample\ntrain\n9\n-1\n\n\n2\ntest-CCC\ntest- CCC\ntest-@CCC\ntest- CCC\n19\n8\nfr\nfr_sample\ntrain\n9\n-1\n\n\n3\n-DDD\nDDD\n-DDD\nDDD\n33\n4\nfr\nfr_sample\ntrain\n3\n1\n\n\n4\ntest- EEE\ntest-EEE\ntest- EEE\ntest-@EEE\n38\n9\nfr\nfr_sample\ntrain\n8\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n75\nspecies!\nspecies.\nspecies!\nspecies.\n111\n8\nen\neng_sample\ntest\n8\n0\n\n\n76\nTest -hyhen\nTesthyhen\nTest -hyhen\nTest@@hyhen\n120\n11\nen\neng_sample\ntest\n9\n2\n\n\n77\nerror\nerrors\nerror@\nerrors\n137\n5\nen\neng_sample\ntest\n6\n-1\n\n\n78\nC\nCCC\nC@@\nCCC\n151\n1\nen\neng_sample\ntest\n3\n-2\n\n\n79\n34\n3 4\n3@4\n3 4\n153\n2\nen\neng_sample\ntest\n3\n-1\n\n\n\n\n80 rows × 11 columns\n\n\n\n\n\n\ntrain_model\n\n train_model (train_dl:torch.utils.data.dataloader.DataLoader[int],\n              val_dl:torch.utils.data.dataloader.DataLoader[int], model:oc\n              rpostcorrection.error_correction.SimpleCorrectionSeq2seq,\n              optimizer:torch.optim.optimizer.Optimizer, num_epochs:int=5,\n              valid_niter:int=5000,\n              model_save_path:pathlib.Path=Path('model.rar'),\n              max_num_patience:int=5, max_num_trial:int=5,\n              lr_decay:float=0.5, device:torch.device=device(type='cpu'))\n\n\nsplit_name = \"train\"\ntrain = BertVectorsCorrectionDataset(\n    data=data.query(f\"dataset == '{split_name}'\"),\n    bert_vectors_file=bert_vectors_file,\n    split_name=split_name,\n)\ntrain_dataloader = DataLoader(\n    train, batch_size=2, collate_fn=collate_fn(text_transform), shuffle=True\n)\n\nsplit_name = \"val\"\nval = BertVectorsCorrectionDataset(\n    data=data.query(f\"dataset == '{split_name}'\"),\n    bert_vectors_file=bert_vectors_file,\n    split_name=split_name,\n)\nval_dataloader = DataLoader(val, batch_size=3, collate_fn=collate_fn(text_transform))\n\nhidden_size = 768\nmodel = SimpleCorrectionSeq2seq(\n    len(vocab_transform[\"ocr\"]),\n    hidden_size,\n    len(vocab_transform[\"gs\"]),\n    0.1,\n    10,\n    teacher_forcing_ratio=0.0,\n)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters())\n\nmsp = Path(os.getcwd()) / \"data\" / \"model_bert_vectors.rar\"\n\ntrain_log = train_model(\n    train_dl=train_dataloader,\n    val_dl=val_dataloader,\n    model=model,\n    optimizer=optimizer,\n    model_save_path=msp,\n    num_epochs=2,\n    valid_niter=5,\n    max_num_patience=5,\n    max_num_trial=5,\n    lr_decay=0.5,\n)\nos.remove(msp)\ntrain_log\n\n 31%|███       | 4/13 [00:00&lt;00:01,  8.61it/s]2023-09-03 19:00:06.994 | INFO     | __main__:train_model:58 - Epoch 1, iter 5, avg. train loss 27.373350143432617, avg. val loss 24.627723693847656\n2023-09-03 19:00:06.995 | INFO     | __main__:train_model:68 - Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model_bert_vectors.rar\n 69%|██████▉   | 9/13 [00:01&lt;00:00,  8.23it/s]2023-09-03 19:00:07.644 | INFO     | __main__:train_model:58 - Epoch 1, iter 10, avg. train loss 24.103273010253908, avg. val loss 24.043284098307293\n2023-09-03 19:00:07.644 | INFO     | __main__:train_model:68 - Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model_bert_vectors.rar\n100%|██████████| 13/13 [00:01&lt;00:00,  7.17it/s]\n  8%|▊         | 1/13 [00:00&lt;00:01,  8.18it/s]2023-09-03 19:00:08.502 | INFO     | __main__:train_model:58 - Epoch 2, iter 15, avg. train loss 19.344550323486327, avg. val loss 19.952612982855904\n2023-09-03 19:00:08.502 | INFO     | __main__:train_model:68 - Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model_bert_vectors.rar\n 38%|███▊      | 5/13 [00:00&lt;00:01,  6.30it/s]2023-09-03 19:00:09.292 | INFO     | __main__:train_model:58 - Epoch 2, iter 20, avg. train loss 22.214738655090333, avg. val loss 18.82603581746419\n2023-09-03 19:00:09.293 | INFO     | __main__:train_model:68 - Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model_bert_vectors.rar\n 77%|███████▋  | 10/13 [00:01&lt;00:00,  6.35it/s]2023-09-03 19:00:10.207 | INFO     | __main__:train_model:58 - Epoch 2, iter 25, avg. train loss 21.808086776733397, avg. val loss 18.29765616522895\n2023-09-03 19:00:10.208 | INFO     | __main__:train_model:68 - Saving model and optimizer to /Users/janneke/code/ocrpostcorrection/nbs/data/model_bert_vectors.rar\n100%|██████████| 13/13 [00:02&lt;00:00,  5.57it/s]\n\n\n\n\n\n\n\n\n\ntrain_loss\nval_loss\n\n\n\n\n0\n27.373350\n24.627724\n\n\n1\n24.103273\n24.043284\n\n\n2\n19.344550\n19.952613\n\n\n3\n22.214739\n18.826036\n\n\n4\n21.808087\n18.297656",
    "crumbs": [
      "BERT Vectors Correction Data"
    ]
  },
  {
    "objectID": "bert_vectors_correction_dataset.html#inference-prediction",
    "href": "bert_vectors_correction_dataset.html#inference-prediction",
    "title": "BERT Vectors Correction Data",
    "section": "Inference / prediction",
    "text": "Inference / prediction\nhttps://pytorch.org/tutorials/beginner/chatbot_tutorial.html?highlight=greedy%20decoding\n\n\nGreedySearchDecoder\n\n GreedySearchDecoder (model)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\ndecoder = GreedySearchDecoder(model)\n\ntest_dataloader = DataLoader(dataset, batch_size=5, collate_fn=collate_fn(text_transform))\n\nwith torch.no_grad():\n    for i, (src, tgt, encoder_hidden) in enumerate(test_dataloader):\n        predicted_indices = decoder(src, encoder_hidden, tgt)\n        if i == 0:\n            print(predicted_indices)\n        else:\n            print(predicted_indices.size())\n\ntensor([[ 4,  5,  6,  4,  8,  3,  3,  3,  3,  3,  0],\n        [ 4,  5,  6,  4,  8,  4,  3,  3,  3,  3,  0],\n        [ 4,  4,  5,  6,  4,  3,  3,  3,  3,  3,  0],\n        [14, 13,  3,  3,  3,  3,  3,  3,  3,  3,  0],\n        [ 4,  5,  6,  4,  8,  3,  3,  3,  3,  3,  0]])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\n\n\n\ndecoder = GreedySearchDecoder(model)\n\ntest_dataloader = DataLoader(dataset_no_look_up, batch_size=5, collate_fn=collate_fn(text_transform))\n\nwith torch.no_grad():\n    for i, (src, tgt, encoder_hidden) in enumerate(test_dataloader):\n        predicted_indices = decoder(src, encoder_hidden, tgt)\n        if i == 0:\n            print(predicted_indices)\n        else:\n            print(predicted_indices.size())\n\ntensor([[ 4,  5,  6,  4,  8,  6,  4,  3,  3,  3,  0],\n        [ 4,  5,  6,  4,  8,  4,  3,  3,  3,  3,  0],\n        [ 4,  4,  5,  6,  4,  3,  4,  3,  3,  3,  0],\n        [14, 13,  3,  3,  3,  3,  3,  3,  3,  3,  0],\n        [ 4,  5,  6,  4,  8,  3,  3,  3,  3,  3,  0]])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\ntorch.Size([5, 11])\n\n\n\n\n\npredict_and_convert_to_str\n\n predict_and_convert_to_str (model, dataloader, bert_model,\n                             dataloader_bert_vectors, tgt_vocab, device)\n\n\nmodel_name = \"bert-base-multilingual-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbert_model = BertModel.from_pretrained(model_name)\nbert_model.eval()\n\ndataset_bert_vectors = HFDataset.from_pandas(test_dataloader.dataset.ds.ocr.to_frame())\ntokenized_dataset = dataset_bert_vectors.map(\n    lambda sample: tokenizer(sample[\"ocr\"], truncation=True),\n    batched=True,\n)\ntokenized_dataset = tokenized_dataset.remove_columns(\n    [\"ocr\"]\n)\n\ncollator = DataCollatorWithPadding(tokenizer)\ntest_dataloader_bert_vectors = DataLoader(\n    tokenized_dataset, batch_size=5, collate_fn=collator\n)\n\npredictions = predict_and_convert_to_str(\n    model=model,\n    dataloader=test_dataloader,\n    bert_model=bert_model,\n    dataloader_bert_vectors=test_dataloader_bert_vectors,\n    tgt_vocab=vocab_transform[\"gs\"],\n    device=device,\n)\npredictions[:3]\n\nSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\n\n\n0it [00:00, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n7it [00:00, 11.23it/s]\n\n\n['test-', 'test-t', 'ttest']",
    "crumbs": [
      "BERT Vectors Correction Data"
    ]
  },
  {
    "objectID": "error_correction.html",
    "href": "error_correction.html",
    "title": "Error Correction",
    "section": "",
    "text": "A dataset for token correction consists of the OCR text and gold standard of AlignedTokens. These can be extracted from the Text objects using the get_tokens_with_OCR_mistakes function. This function also adds data properties that can be used for calculating statistics about the data.\n\n\n\n\n get_tokens_with_OCR_mistakes\n                               (data:Dict[str,ocrpostcorrection.icdar_data\n                               .Text], data_test:Dict[str,ocrpostcorrectio\n                               n.icdar_data.Text], val_files:List[str])\n\nReturn pandas dataframe with all OCR mistakes from train, val, and test\nThe following code example shows how use this function. For simplicity, in the example below, the data dictionary (which contain &lt;file name&gt;: Text pairs) is used both as train/val and test set.\n\ndata_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\ndata, md = generate_data(data_dir)\nval_files = [\"en/eng_sample/2.txt\"]\n\ntoken_data = get_tokens_with_OCR_mistakes(data, data, val_files)\nprint(token_data.shape)\ntoken_data.head()\n\n2it [00:00, 1508.20it/s]\n\n\n(80, 12)\n\n\n\n\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\n\n\n\n\n0\nIn\n\nIn\n##\n0\n2\nen/eng_sample/1.txt\nen\neng_sample\ntest\n0\n2\n\n\n1\ntroe\ntree\ntroe\ntree\n13\n4\nen/eng_sample/1.txt\nen\neng_sample\ntest\n4\n0\n\n\n2\nperemial\nperennial\nperem@ial\nperennial\n23\n8\nen/eng_sample/1.txt\nen\neng_sample\ntest\n9\n-1\n\n\n3\neLngated\nelongated\neL@ngated\nelongated\n46\n8\nen/eng_sample/1.txt\nen\neng_sample\ntest\n9\n-1\n\n\n4\nstein,\nstem,\nstein,\nstem@,\n55\n6\nen/eng_sample/1.txt\nen\neng_sample\ntest\n5\n1\n\n\n\n\n\n\n\nGet the context of an ocr mistake.\n\n\n\n\n\n get_OCR_mistakes_in_context\n                              (data:Dict[str,ocrpostcorrection.icdar_data.\n                              Text], data_test:Dict[str,ocrpostcorrection.\n                              icdar_data.Text],\n                              ocr_mistakes:pandas.core.frame.DataFrame,\n                              offset:int)\n\n\n\n\n\n\n get_context_for_dataset\n                          (data:Dict[str,ocrpostcorrection.icdar_data.Text\n                          ], ocr_mistakes:pandas.core.frame.DataFrame,\n                          offset:int)\n\n\n\n\n\n\n get_closest_value (lst:List, value:int)\n\n\ntoken_data2 = get_OCR_mistakes_in_context(data, data, token_data, offset=20)\nprint(token_data2.shape)\ntoken_data2.head()\n\n100%|██████████| 4/4 [00:00&lt;00:00, 873.54it/s]\n100%|██████████| 4/4 [00:00&lt;00:00, 913.24it/s]\n\n\n(80, 15)\n\n\n\n\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\ncontext_before\ncontext_after\nlen_mistake_in_context\n\n\n\n\n0\nIn\n\nIn\n##\n0\n2\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n0\n2\n\nbotany, a troe is a\n22\n\n\n1\ntroe\ntree\ntroe\ntree\n13\n4\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n4\n0\nIn botany, a\nis a peremial plant\n37\n\n\n2\nperemial\nperennial\nperem@ial\nperennial\n23\n8\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n9\n-1\nbotany, a troe is a\nplant with an eLngated\n51\n\n\n3\neLngated\nelongated\neL@ngated\nelongated\n46\n8\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n9\n-1\nperemial plant with an\nstein, or trunk,\n48\n\n\n4\nstein,\nstem,\nstein,\nstem@,\n55\n6\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n5\n1\nplant with an eLngated\nor trunk, suppor ing\n50\n\n\n\n\n\n\n\n\ntoken_data2.tail()\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\ncontext_before\ncontext_after\nlen_mistake_in_context\n\n\n\n\n35\ntest-FFF\ntest- FFF\ntest-@FFF\ntest- FFF\n48\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n9\n-1\ntest -DDD test- EEE\ntest-GGG test - HHH\n48\n\n\n36\ntest-GGG\ntest -GGG\ntest@-GGG\ntest -GGG\n57\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n9\n-1\ntest- EEE test-FFF\ntest - HHH test-III\n47\n\n\n37\ntest - HHH\ntest-HHH\ntest - HHH\ntest@-@HHH\n66\n10\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n8\n2\nEEE test-FFF test-GGG\ntest-III test - JJJ\n52\n\n\n38\ntest-III\ntest - III\ntest@-@III\ntest - III\n77\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n10\n-2\ntest-GGG test - HHH\ntest - JJJ blablabla\n49\n\n\n39\n?\n!\n?\n!\n107\n1\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n1\n0\ntest - JJJ blablabla\n\n22\n\n\n\n\n\n\n\n\n\n\nhttps://pytorch.org/tutorials/beginner/translation_transformer.html\nDefine special symbols and indices and make sure the tokens are in order of their indices to properly insert them in vocababulary.\n\n\n\n\n\n yield_tokens (data, col)\n\nHelper function to create vocabulary containing characters\n\n\n\n\n\n generate_vocabs (train)\n\nGenerate ocr and gs vocabularies from the train set\nUse the trainset to create the ocr and gs vocabularies:\n\nvocab_transform = generate_vocabs(token_data.query('dataset == \"train\"'))\n\n\nlen(vocab_transform[\"ocr\"]), len(vocab_transform[\"gs\"])\n\n(46, 44)\n\n\n\n\n\nThe character sequences need to be transformed into vectors.\nSource: https://pytorch.org/tutorials/beginner/translation_transformer.html\n\n\n\n\n\n get_text_transform (vocab_transform)\n\nReturns text transforms to convert raw strings into tensors indices\n\n\n\n\n\n tensor_transform (token_ids:List[int])\n\nFunction to add BOS/EOS and create tensor for input sequence indices\n\n\n\n\n\n sequential_transforms (*transforms)\n\nHelper function to club together sequential operations\n\ntext_transform = get_text_transform(vocab_transform)\n\ntext_transform[\"ocr\"]([\"t\", \"e\", \"s\", \"t\", \"-\", \" \", \"A\", \"A\", \"A\"])\n\ntensor([ 4,  5,  6,  4,  7, 10, 13, 13, 13,  3])\n\n\n\ntext_transform = get_text_transform(vocab_transform)\n\nprint(text_transform[\"ocr\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))\nprint(text_transform[\"gs\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))\n\ntensor([ 5,  0, 21, 34, 22, 33,  5,  3])\ntensor([ 5,  0, 21, 27, 23, 26,  5,  3])",
    "crumbs": [
      "Error Correction"
    ]
  },
  {
    "objectID": "error_correction.html#dataset-creation",
    "href": "error_correction.html#dataset-creation",
    "title": "Error Correction",
    "section": "",
    "text": "A dataset for token correction consists of the OCR text and gold standard of AlignedTokens. These can be extracted from the Text objects using the get_tokens_with_OCR_mistakes function. This function also adds data properties that can be used for calculating statistics about the data.\n\n\n\n\n get_tokens_with_OCR_mistakes\n                               (data:Dict[str,ocrpostcorrection.icdar_data\n                               .Text], data_test:Dict[str,ocrpostcorrectio\n                               n.icdar_data.Text], val_files:List[str])\n\nReturn pandas dataframe with all OCR mistakes from train, val, and test\nThe following code example shows how use this function. For simplicity, in the example below, the data dictionary (which contain &lt;file name&gt;: Text pairs) is used both as train/val and test set.\n\ndata_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\ndata, md = generate_data(data_dir)\nval_files = [\"en/eng_sample/2.txt\"]\n\ntoken_data = get_tokens_with_OCR_mistakes(data, data, val_files)\nprint(token_data.shape)\ntoken_data.head()\n\n2it [00:00, 1508.20it/s]\n\n\n(80, 12)\n\n\n\n\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\n\n\n\n\n0\nIn\n\nIn\n##\n0\n2\nen/eng_sample/1.txt\nen\neng_sample\ntest\n0\n2\n\n\n1\ntroe\ntree\ntroe\ntree\n13\n4\nen/eng_sample/1.txt\nen\neng_sample\ntest\n4\n0\n\n\n2\nperemial\nperennial\nperem@ial\nperennial\n23\n8\nen/eng_sample/1.txt\nen\neng_sample\ntest\n9\n-1\n\n\n3\neLngated\nelongated\neL@ngated\nelongated\n46\n8\nen/eng_sample/1.txt\nen\neng_sample\ntest\n9\n-1\n\n\n4\nstein,\nstem,\nstein,\nstem@,\n55\n6\nen/eng_sample/1.txt\nen\neng_sample\ntest\n5\n1\n\n\n\n\n\n\n\nGet the context of an ocr mistake.\n\n\n\n\n\n get_OCR_mistakes_in_context\n                              (data:Dict[str,ocrpostcorrection.icdar_data.\n                              Text], data_test:Dict[str,ocrpostcorrection.\n                              icdar_data.Text],\n                              ocr_mistakes:pandas.core.frame.DataFrame,\n                              offset:int)\n\n\n\n\n\n\n get_context_for_dataset\n                          (data:Dict[str,ocrpostcorrection.icdar_data.Text\n                          ], ocr_mistakes:pandas.core.frame.DataFrame,\n                          offset:int)\n\n\n\n\n\n\n get_closest_value (lst:List, value:int)\n\n\ntoken_data2 = get_OCR_mistakes_in_context(data, data, token_data, offset=20)\nprint(token_data2.shape)\ntoken_data2.head()\n\n100%|██████████| 4/4 [00:00&lt;00:00, 873.54it/s]\n100%|██████████| 4/4 [00:00&lt;00:00, 913.24it/s]\n\n\n(80, 15)\n\n\n\n\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\ncontext_before\ncontext_after\nlen_mistake_in_context\n\n\n\n\n0\nIn\n\nIn\n##\n0\n2\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n0\n2\n\nbotany, a troe is a\n22\n\n\n1\ntroe\ntree\ntroe\ntree\n13\n4\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n4\n0\nIn botany, a\nis a peremial plant\n37\n\n\n2\nperemial\nperennial\nperem@ial\nperennial\n23\n8\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n9\n-1\nbotany, a troe is a\nplant with an eLngated\n51\n\n\n3\neLngated\nelongated\neL@ngated\nelongated\n46\n8\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n9\n-1\nperemial plant with an\nstein, or trunk,\n48\n\n\n4\nstein,\nstem,\nstein,\nstem@,\n55\n6\nen/eng_sample/1.txt\nen\neng_sample\ntrain\n5\n1\nplant with an eLngated\nor trunk, suppor ing\n50\n\n\n\n\n\n\n\n\ntoken_data2.tail()\n\n\n\n\n\n\n\n\nocr\ngs\nocr_aligned\ngs_aligned\nstart\nlen_ocr\nkey\nlanguage\nsubset\ndataset\nlen_gs\ndiff\ncontext_before\ncontext_after\nlen_mistake_in_context\n\n\n\n\n35\ntest-FFF\ntest- FFF\ntest-@FFF\ntest- FFF\n48\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n9\n-1\ntest -DDD test- EEE\ntest-GGG test - HHH\n48\n\n\n36\ntest-GGG\ntest -GGG\ntest@-GGG\ntest -GGG\n57\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n9\n-1\ntest- EEE test-FFF\ntest - HHH test-III\n47\n\n\n37\ntest - HHH\ntest-HHH\ntest - HHH\ntest@-@HHH\n66\n10\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n8\n2\nEEE test-FFF test-GGG\ntest-III test - JJJ\n52\n\n\n38\ntest-III\ntest - III\ntest@-@III\ntest - III\n77\n8\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n10\n-2\ntest-GGG test - HHH\ntest - JJJ blablabla\n49\n\n\n39\n?\n!\n?\n!\n107\n1\nfr/fr_sample/2.txt\nfr\nfr_sample\ntest\n1\n0\ntest - JJJ blablabla\n\n22\n\n\n\n\n\n\n\n\n\n\nhttps://pytorch.org/tutorials/beginner/translation_transformer.html\nDefine special symbols and indices and make sure the tokens are in order of their indices to properly insert them in vocababulary.\n\n\n\n\n\n yield_tokens (data, col)\n\nHelper function to create vocabulary containing characters\n\n\n\n\n\n generate_vocabs (train)\n\nGenerate ocr and gs vocabularies from the train set\nUse the trainset to create the ocr and gs vocabularies:\n\nvocab_transform = generate_vocabs(token_data.query('dataset == \"train\"'))\n\n\nlen(vocab_transform[\"ocr\"]), len(vocab_transform[\"gs\"])\n\n(46, 44)\n\n\n\n\n\nThe character sequences need to be transformed into vectors.\nSource: https://pytorch.org/tutorials/beginner/translation_transformer.html\n\n\n\n\n\n get_text_transform (vocab_transform)\n\nReturns text transforms to convert raw strings into tensors indices\n\n\n\n\n\n tensor_transform (token_ids:List[int])\n\nFunction to add BOS/EOS and create tensor for input sequence indices\n\n\n\n\n\n sequential_transforms (*transforms)\n\nHelper function to club together sequential operations\n\ntext_transform = get_text_transform(vocab_transform)\n\ntext_transform[\"ocr\"]([\"t\", \"e\", \"s\", \"t\", \"-\", \" \", \"A\", \"A\", \"A\"])\n\ntensor([ 4,  5,  6,  4,  7, 10, 13, 13, 13,  3])\n\n\n\ntext_transform = get_text_transform(vocab_transform)\n\nprint(text_transform[\"ocr\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))\nprint(text_transform[\"gs\"]([\"e\", \"x\", \"a\", \"m\", \"p\", \"l\", \"e\"]))\n\ntensor([ 5,  0, 21, 34, 22, 33,  5,  3])\ntensor([ 5,  0, 21, 27, 23, 26,  5,  3])",
    "crumbs": [
      "Error Correction"
    ]
  },
  {
    "objectID": "error_correction.html#neural-network",
    "href": "error_correction.html#neural-network",
    "title": "Error Correction",
    "section": "Neural network",
    "text": "Neural network\nNetwork: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n\n\nEncoderRNN\n\n EncoderRNN (input_size, hidden_size)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\n\n\nAttnDecoderRNN\n\n AttnDecoderRNN (hidden_size, output_size, dropout_p=0.1, max_length=11)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\n\n\nSimpleCorrectionSeq2seq\n\n SimpleCorrectionSeq2seq (input_size, hidden_size, output_size, dropout,\n                          max_length, teacher_forcing_ratio, device='cpu')\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 2\nhidden_size = 5\ndropout = 0.1\nmax_token_len = 10\n\nmodel = SimpleCorrectionSeq2seq(\n    len(vocab_transform[\"ocr\"]),\n    hidden_size,\n    len(vocab_transform[\"gs\"]),\n    dropout,\n    max_token_len,\n    teacher_forcing_ratio=0.5,\n    device=device,\n)\n\ninput = torch.tensor([[6, 4], [22, 30], [0, 6], [18, 4], [11, 3], [3, 1]])\nencoder_hidden = model.encoder.initHidden(batch_size=batch_size, device=device)\n\ntarget = torch.tensor([[6, 4], [23, 5], [16, 6], [16, 4], [11, 4], [3, 1]])\n\nlosses, _ = model(input, encoder_hidden, target)\nlosses\n\ntensor([-23.0017, -19.0353], grad_fn=&lt;SumBackward1&gt;)",
    "crumbs": [
      "Error Correction"
    ]
  },
  {
    "objectID": "error_correction.html#evaluation",
    "href": "error_correction.html#evaluation",
    "title": "Error Correction",
    "section": "Evaluation",
    "text": "Evaluation\n\nmodel_save_path = Path(os.getcwd()) / \"data\" / \"model.rar\"\n\ncheckpoint = torch.load(model_save_path)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\noptimizer = torch.optim.Adam(model.parameters())\noptimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\nmodel.eval()\n\nSimpleCorrectionSeq2seq(\n  (encoder): EncoderRNN(\n    (embedding): Embedding(46, 5)\n    (gru): GRU(5, 5, batch_first=True)\n  )\n  (decoder): AttnDecoderRNN(\n    (embedding): Embedding(44, 5)\n    (attn): Linear(in_features=10, out_features=11, bias=True)\n    (attn_combine): Linear(in_features=10, out_features=5, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (gru): GRU(5, 5)\n    (out): Linear(in_features=5, out_features=44, bias=True)\n  )\n)\n\n\n\n\nindices2string\n\n indices2string (indices, itos)\n\n\nindices = torch.tensor(\n    [\n        [20, 34, 22, 6, 1, 1, 1, 1, 1, 1],\n        [22, 6, 1, 1, 1, 1, 1, 1, 1, 1],\n        [21, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [4, 5, 6, 4, 1, 1, 1, 1, 1, 1],\n        [29, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    ]\n)\nindices2string(indices, vocab_transform[\"gs\"].get_itos())\n\n['This', 'is', 'a', 'test', '!']\n\n\n\ndecoder = GreedySearchDecoder(model)\n\nmax_len = 10\n\ntest = SimpleCorrectionDataset(token_data.query('dataset == \"test\"'), max_len=max_len)\ntest_dataloader = DataLoader(test, batch_size=5, collate_fn=collate_fn(text_transform))\n\n\noutput_strings = predict_and_convert_to_str(\n    model, test_dataloader, vocab_transform[\"gs\"], device\n)\n\n100%|██████████| 7/7 [00:00&lt;00:00, 163.36it/s]\n\n\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\ntorch.Size([1, 5, 5])\n\n\n\n\n\n\nmax_len = 10\ntest_data = (\n    token_data.query('dataset == \"test\"')\n    .query(f\"len_ocr &lt;= {max_len}\")\n    .query(f\"len_gs &lt;= {max_len}\")\n    .copy()\n)\n\ntest_data[\"pred\"] = output_strings\n\n\n\nPerformance measure: mean normalized edit distance\n\nMean (normalized) edit distance.\n\nOption: ignore -\noption: ignore case\n\n\n\ntest_data[\"ed\"] = test_data.apply(\n    lambda row: edlib.align(row.ocr, row.gs)[\"editDistance\"], axis=1\n)\ntest_data.ed.describe()\n\ncount    35.000000\nmean      1.971429\nstd       1.773758\nmin       1.000000\n25%       1.000000\n50%       1.000000\n75%       2.000000\nmax       8.000000\nName: ed, dtype: float64\n\n\n\ntest_data[\"ed_norm\"] = test_data.apply(\n    lambda row: normalized_ed(row.ed, row.ocr, row.gs), axis=1\n)\ntest_data.ed_norm.describe()\n\ncount    35.000000\nmean      0.390952\nstd       0.326909\nmin       0.100000\n25%       0.125000\n50%       0.250000\n75%       0.583333\nmax       1.000000\nName: ed_norm, dtype: float64\n\n\n\ntest_data[\"ed_pred\"] = test_data.apply(\n    lambda row: edlib.align(row.pred, row.gs)[\"editDistance\"], axis=1\n)\ntest_data.ed_pred.describe()\n\ncount    35.000000\nmean      8.057143\nstd       3.253440\nmin       1.000000\n25%       7.000000\n50%      10.000000\n75%      10.000000\nmax      11.000000\nName: ed_pred, dtype: float64\n\n\n\ntest_data[\"ed_norm_pred\"] = test_data.apply(\n    lambda row: normalized_ed(row.ed_pred, row.pred, row.gs), axis=1\n)\ntest_data.ed_norm_pred.describe()\n\ncount    35.000000\nmean      0.989351\nstd       0.030110\nmin       0.900000\n25%       1.000000\n50%       1.000000\n75%       1.000000\nmax       1.000000\nName: ed_norm_pred, dtype: float64",
    "crumbs": [
      "Error Correction"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "set_seed (seed:int)\n\n*Set the random seed in Python std library and pytorch\nArgs: seed (int): Value of the random seed*\n\nset_seed(23)",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#set-random-seed",
    "href": "utils.html#set-random-seed",
    "title": "Utils",
    "section": "",
    "text": "set_seed (seed:int)\n\n*Set the random seed in Python std library and pytorch\nArgs: seed (int): Value of the random seed*\n\nset_seed(23)",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#convert-predictions-into-icdar-output-format",
    "href": "utils.html#convert-predictions-into-icdar-output-format",
    "title": "Utils",
    "section": "Convert predictions into ICDAR output format",
    "text": "Convert predictions into ICDAR output format\n\n\npredictions_to_labels\n\n predictions_to_labels (predictions)\n\n\n\n\nseparate_subtoken_predictions\n\n separate_subtoken_predictions (word_ids, preds)\n\n\n\n\nmerge_subtoken_predictions\n\n merge_subtoken_predictions (subtoken_predictions)\n\n\n\n\ngather_token_predictions\n\n gather_token_predictions (preds)\n\nGather potentially overlapping token predictions\n\n\n\nlabels2label_str\n\n labels2label_str (labels, text_key)\n\n\n\n\nextract_icdar_output\n\n extract_icdar_output (label_str, input_tokens)\n\n\n\n\npredictions2icdar_output\n\n predictions2icdar_output (samples, predictions, tokenizer, data_test)\n\nConvert predictions into icdar output format\n\nbert_base_model_name = \"bert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(bert_base_model_name)\n\ntokens = [\"the\" for i in range(1000)]\n\nr = tokenizer(tokens, is_split_into_words=True)\n\nToken indices sequence length is longer than the specified maximum sequence length for this model (1002 &gt; 512). Running this sequence through the model will result in indexing errors\n\n\n\nlen(r.input_ids)\n\n1002",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#convert-predictions-into-entities-output-format",
    "href": "utils.html#convert-predictions-into-entities-output-format",
    "title": "Utils",
    "section": "Convert predictions into entities output format",
    "text": "Convert predictions into entities output format\n\n\ncreate_entity\n\n create_entity (entity_tokens)\n\nIn the entitiy output format, an entity looks as follows:\n\ninput_tokens = [\n    InputToken(\n        ocr=\"one\",\n        gs=\"one\",\n        start=0,\n        len_ocr=3,\n        label=0,\n    ),\n    InputToken(\n        ocr=\"tow\",\n        gs=\"two\",\n        start=4,\n        len_ocr=3,\n        label=1,\n    ),\n]\ncreate_entity(input_tokens)\n\n{'entity': 'OCR mistake', 'word': 'one tow', 'start': 0, 'end': 7}\n\n\nThe entity output format consists of a list of such entities.\n\n\n\nextract_entity_output\n\n extract_entity_output (label_str:str, input_tokens)\n\nConvert label string to the entity output format\n\n\n\npredictions2entity_output\n\n predictions2entity_output (samples, predictions, tokenizer, data_test)\n\nConvert predictions into entity output format\n\n\n\ncreate_perfect_icdar_output\n\n create_perfect_icdar_output (data)",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#running-the-icdar-evaluation-script",
    "href": "utils.html#running-the-icdar-evaluation-script",
    "title": "Utils",
    "section": "Running the ICDAR evaluation script",
    "text": "Running the ICDAR evaluation script\nThis code was taken from the original evalTool_ICDAR2017.py (CC0 License) via Kotwic4/ocr-correction.\n\n\nEvalContext\n\n EvalContext (filePath, verbose=False)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nreshape_input_errors\n\n reshape_input_errors (tokenPosErr, evalContext, verbose=False)\n\n\n\n\nrunEvaluation\n\n runEvaluation (datasetDirPath, pathInputJsonErrorsCorrections,\n                pathOutputCsv, verbose=False)\n\nMain evaluation method\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndatasetDirPath\n\n\npath to the dataset directory (ex: r”./dataset_sample”)\n\n\npathInputJsonErrorsCorrections\n\n\n# input path to the JSON result (ex: r”./inputErrCor_sample.json”), format given on https://sites.google.com/view/icdar2017-postcorrectionocr/evaluation)\n\n\npathOutputCsv\n\n\noutput path to the CSV evaluation results (ex: r”./outputEval.csv”)\n\n\nverbose\nbool\nFalse\n\n\n\n\n\n\n\nread_results\n\n read_results (csv_file)\n\nRead csv with evaluation results",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#convert-icdar-output-format-to-simplecorrectiondataset",
    "href": "utils.html#convert-icdar-output-format-to-simplecorrectiondataset",
    "title": "Utils",
    "section": "Convert ICDAR output format to SimpleCorrectionDataset",
    "text": "Convert ICDAR output format to SimpleCorrectionDataset\n\n\nicdar_output2simple_correction_dataset_df\n\n icdar_output2simple_correction_dataset_df\n                                            (output:Dict[str,Dict[str,Dict\n                                            ]], data:Dict[str,ocrpostcorre\n                                            ction.icdar_data.Text],\n                                            dataset:str='test')\n\n*Convert the icdar data error detection output to input for SimpleCorrectionDataset\nBecause gold standard for input_tokens is not available, the dataset dataframe cannot be used for evaluation anymore.*\n\ndata_dir = Path(os.getcwd()) / \"data\" / \"dataset_training_sample\"\ndata, md = generate_data(data_dir)\n\ndetection_output = create_perfect_icdar_output(data)\n\ndf = icdar_output2simple_correction_dataset_df(detection_output, data)\nprint(f\"DataFrame contains {df.shape[0]} samples\")\n\ndataset = SimpleCorrectionDataset(df, max_len=10)\nprint(f\"Dataset contains {len(dataset)} samples\")\n\n2it [00:00, 1710.91it/s]\n\n\nDataFrame contains 40 samples\nDataset contains 35 samples",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#summarize-icdar-results",
    "href": "utils.html#summarize-icdar-results",
    "title": "Utils",
    "section": "Summarize icdar results",
    "text": "Summarize icdar results\n\n\naggregate_ed_results\n\n aggregate_ed_results (csv_file)\n\n\n\n\naggregate_results\n\n aggregate_results (csv_file)\n\n\n\n\nread_results\n\n read_results (csv_file)",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "utils.html#development",
    "href": "utils.html#development",
    "title": "Utils",
    "section": "Development",
    "text": "Development\n\n\nreduce_dataset\n\n reduce_dataset (dataset, n=5)\n\nReturn dataset with the first n samples for each split",
    "crumbs": [
      "Utils"
    ]
  },
  {
    "objectID": "icdar_data.html",
    "href": "icdar_data.html",
    "title": "ICDAR Data",
    "section": "",
    "text": "The ICDAR 2019 Competition on Post-OCR Text Correction dataset (zenodo record) contains text files in the following format:\nThe first line contains the ocr input text. The second line contains the aligned ocr and the third line contains the aligned gold standard. @ is the aligment character and # represents characters in the OCR that do not occur in the gold standard.\nFor working with this data, the first 14 characters have to be removed. We also remove leading and trailing whitespace.",
    "crumbs": [
      "ICDAR Data"
    ]
  },
  {
    "objectID": "icdar_data.html#tokenization",
    "href": "icdar_data.html#tokenization",
    "title": "ICDAR Data",
    "section": "Tokenization",
    "text": "Tokenization\nTask 1 of the competition is about finding tokens with OCR mistakes. In this context a token refers to a string between two whitespaces.\n\n\nAlignedToken\n\n AlignedToken (ocr:str, gs:str, ocr_aligned:str, gs_aligned:str,\n               start:int, len_ocr:int)\n\nDataclass for storing aligned tokens\n\n\n\ntokenize_aligned\n\n tokenize_aligned (ocr_aligned:str, gs_aligned:str)\n\nGet a list of AlignedTokens from the aligned OCR and GS strings\n\ntokenize_aligned(\"This is a@ cxample...\", \"This is an example.##\")\n\n[AlignedToken(ocr='This', gs='This', ocr_aligned='This', gs_aligned='This', start=0, len_ocr=4),\n AlignedToken(ocr='is', gs='is', ocr_aligned='is', gs_aligned='is', start=5, len_ocr=2),\n AlignedToken(ocr='a', gs='an', ocr_aligned='a@', gs_aligned='an', start=8, len_ocr=1),\n AlignedToken(ocr='cxample...', gs='example.', ocr_aligned='cxample...', gs_aligned='example.##', start=10, len_ocr=10)]\n\n\nThe OCR text of an AlignedToken may still consist of multiple tokens. This is the case when the OCR text contains one or more spaces. To make sure the (sub)tokenization of a token is the same, no matter if it was not yet tokenized completely, another round of tokenization is added.\n\n\n\nInputToken\n\n InputToken (ocr:str, gs:str, start:int, len_ocr:int, label:int)\n\nDataclass for the tokenization within AlignedTokens\n\n\n\nleading_whitespace_offset\n\n leading_whitespace_offset (string:str)\n\n*Return the leading whitespace offset for an aligned ocr string\nIf an aligned ocr string contains leading whitespace, the offset needs to be added to the start index of the respective input tokens.\nArgs: string (str): aligned ocr string to determine the leading whitespace offset for\nReturns: int: leading whitespace offset for input tokens*\n\n\n\nget_input_tokens\n\n get_input_tokens (aligned_token:__main__.AlignedToken)\n\nTokenize an AlignedToken into subtokens and assign task 1 labels\n\nt = AlignedToken(\"Major\", \"Major\", \"Major\", \"Major\", 19, 5)\nprint(t)\n\nfor inp_tok in get_input_tokens(t):\n    print(inp_tok)\n\nAlignedToken(ocr='Major', gs='Major', ocr_aligned='Major', gs_aligned='Major', start=19, len_ocr=5)\nInputToken(ocr='Major', gs='Major', start=19, len_ocr=5, label=0)\n\n\n\nt = AlignedToken(\"INEVR\", \"I NEVER\", \"I@NEV@R\", \"I NEVER\", 0, 5)\nprint(t)\n\nfor inp_tok in get_input_tokens(t):\n    print(inp_tok)\n\nAlignedToken(ocr='INEVR', gs='I NEVER', ocr_aligned='I@NEV@R', gs_aligned='I NEVER', start=0, len_ocr=5)\nInputToken(ocr='INEVR', gs='I NEVER', start=0, len_ocr=5, label=1)\n\n\n\nt = AlignedToken(\"Long ow.\", \"Longhow.\", \"Long ow.\", \"Longhow.\", 24, 8)\nprint(t)\n\nfor inp_tok in get_input_tokens(t):\n    print(inp_tok)\n\nAlignedToken(ocr='Long ow.', gs='Longhow.', ocr_aligned='Long ow.', gs_aligned='Longhow.', start=24, len_ocr=8)\nInputToken(ocr='Long', gs='Longhow.', start=24, len_ocr=4, label=1)\nInputToken(ocr='ow.', gs='', start=29, len_ocr=3, label=2)",
    "crumbs": [
      "ICDAR Data"
    ]
  },
  {
    "objectID": "icdar_data.html#process-a-text-file",
    "href": "icdar_data.html#process-a-text-file",
    "title": "ICDAR Data",
    "section": "Process a text file",
    "text": "Process a text file\nNext, we need functions for processing a text in the ICDAR data format.\n\n\nText\n\n Text (ocr_text:str, tokens:list, input_tokens:list, score:float)\n\nDataclass for storing a text in the ICDAR data format\n\n\n\nclean\n\n clean (string:str)\n\nRemove alignment characters from a text\n\n\n\nnormalized_ed\n\n normalized_ed (ed:int, ocr:str, gs:str)\n\nReturns the normalized editdistance\n\n\n\nprocess_text\n\n process_text (in_file:pathlib.Path)\n\n*Process a text from the ICDAR dataset\nExtract AlignedTokens, InputTokens, and calculate normalized editdistance.*\nProcessing the example text:\n\nin_file = Path(os.getcwd()) / \"data\" / \"example.txt\"\ntext = process_text(in_file)\ntext\n\nText(ocr_text='This is a cxample...', tokens=[AlignedToken(ocr='This', gs='This', ocr_aligned='This', gs_aligned='This', start=0, len_ocr=4), AlignedToken(ocr='is', gs='is', ocr_aligned='is', gs_aligned='is', start=5, len_ocr=2), AlignedToken(ocr='a', gs='an', ocr_aligned='a@', gs_aligned='an', start=8, len_ocr=1), AlignedToken(ocr='cxample...', gs='example.', ocr_aligned='cxample...', gs_aligned='example.@@', start=10, len_ocr=10)], input_tokens=[InputToken(ocr='This', gs='This', start=0, len_ocr=4, label=0), InputToken(ocr='is', gs='is', start=5, len_ocr=2, label=0), InputToken(ocr='a', gs='an', start=8, len_ocr=1, label=1), InputToken(ocr='cxample...', gs='example.', start=10, len_ocr=10, label=1)], score=0.2)",
    "crumbs": [
      "ICDAR Data"
    ]
  },
  {
    "objectID": "icdar_data.html#process-the-entire-dataset",
    "href": "icdar_data.html#process-the-entire-dataset",
    "title": "ICDAR Data",
    "section": "Process the entire dataset",
    "text": "Process the entire dataset\nFile structure of the ICDAR dataset\n.\n├── &lt;data_dir&gt;\n│   ├── &lt;language&gt;\n│   │   ├── &lt;language (set)&gt;1\n│   │   ...\n│   │   └── &lt;language (set)&gt;n\n│   ...\n...\n\n\ngenerate_data\n\n generate_data (in_dir:pathlib.Path)\n\nProcess all texts in the dataset and return a dataframe with metadata\n\n\n\nget_intermediate_data\n\n get_intermediate_data (zip_file:str)\n\nGet the data and metadata for the train and test sets from the zip file.\n\n\n\nextract_icdar_data\n\n extract_icdar_data (out_dir:str, zip_file:str)",
    "crumbs": [
      "ICDAR Data"
    ]
  },
  {
    "objectID": "icdar_data.html#generate-input-sentences",
    "href": "icdar_data.html#generate-input-sentences",
    "title": "ICDAR Data",
    "section": "Generate input ‘sentences’",
    "text": "Generate input ‘sentences’\nThe following functions can be used to generate sequences of a certain length with possible overlap.\n\n\nwindow\n\n window (iterable, size=2)\n\nGiven an iterable, return all subsequences of a certain size\n\n\n\ngenerate_sentences\n\n generate_sentences (df:pandas.core.frame.DataFrame,\n                     data:Dict[str,__main__.Text], size:int=15,\n                     step:int=10)\n\nGenerate sequences of a certain length and possible overlap\n\n\n\nprocess_input_ocr\n\n process_input_ocr (text:str)\n\nGenerate Text object for OCR input text (without aligned gold standard)\n\ntext = process_input_ocr(\"This is a cxample...\")\ndata = {\"ocr_input\": text}\nmd = pd.DataFrame(\n    {\n        \"language\": [\"?\"],\n        \"file_name\": [\"ocr_input\"],\n        \"score\": [text.score],\n        \"num_tokens\": [len(text.tokens)],\n        \"num_input_tokens\": [len(text.input_tokens)],\n    }\n)\n\ndf = generate_sentences(md, data, size=2, step=2)\n\nassert 2 == df.shape[0]\nassert [0, 2] == list(df.start_token_id)\ndf\n\n1it [00:00, 2198.27it/s]\n\n\n\n\n\n\n\n\n\nkey\nstart_token_id\nscore\ntokens\ntags\nlanguage\n\n\n\n\n0\nocr_input\n0\n0.0\n[This, is]\n[0, 0]\noc\n\n\n1\nocr_input\n2\n0.0\n[a, cxample...]\n[0, 0]\noc",
    "crumbs": [
      "ICDAR Data"
    ]
  }
]